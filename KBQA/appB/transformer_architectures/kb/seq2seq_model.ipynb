{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers import BertConfig\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaModel\n",
    "from transformers import RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Vocabulary\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'*labels', '*tags'}\n",
      " \tNamespace: entity_wiki, Size: 470116 \n",
      " \tNamespace: entity_wordnet, Size: 117663 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29fd83c1e794640902a2da3a6a68e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded wiki embedding\n",
      "Init Bert Encoder\n",
      "Loaded wiki soldered KG\n",
      "25\n",
      "tensor([0, 8, 3,  ..., 2, 6, 7])\n",
      "Loaded wordnet embedding\n",
      "Init Bert Encoder\n",
      "Loaded wordnet soldered KG\n"
     ]
    }
   ],
   "source": [
    "from KBQA.appB.transformer_architectures.kb.knowbert import KnowBert\n",
    "\n",
    "encoder = KnowBert.load_pretrained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at razent/spbert-mlm-wso-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at razent/spbert-mlm-wso-base and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "triple_encoder_config = BertConfig.from_pretrained(\"razent/spbert-mlm-wso-base\")\n",
    "triple_encoder = BertModel.from_pretrained(\n",
    "    \"razent/spbert-mlm-wso-base\", config=triple_encoder_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at razent/spbert-mlm-wso-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at razent/spbert-mlm-wso-base and are newly initialized: ['bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.pooler.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.pooler.dense.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "decoder_config = BertConfig.from_pretrained(\n",
    "    \"razent/spbert-mlm-wso-base\"\n",
    ")\n",
    "decoder_config.is_decoder = True\n",
    "decoder_config.add_cross_attention = True\n",
    "decoder = BertModel.from_pretrained(\n",
    "    \"razent/spbert-mlm-wso-base\", config=decoder_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KBQA.appB.transformer_architectures.kb.model import BertSeq2Seq\n",
    "\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "device = torch.device(\"cuda:0\")\n",
    "tokenizer_uncased = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "model = BertSeq2Seq(encoder=encoder,\n",
    "                    triple_encoder=triple_encoder,\n",
    "                    decoder=decoder,\n",
    "                    config=config,\n",
    "                    beam_size=2,\n",
    "                    max_length=4,\n",
    "                    sos_id=tokenizer_uncased.cls_token_id,\n",
    "                    eos_id=tokenizer_uncased.sep_token_id,\n",
    "                    device=device\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Generators\n",
      "duplicate_mentions_cnt:  6777\n",
      "end of p_e_m reading. wall time: 0.9509945193926493  minutes\n",
      "p_e_m_errors:  0\n",
      "incompatible_ent_ids:  0\n",
      "Build Generators\n",
      "{'_tokenizer_kwargs': {'use_fast': True}, '_model_name': 'bert-base-uncased', 'tokenizer': PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), '_add_special_tokens': True, '_max_length': None, '_tokenizer_lowercases': True, 'sequence_pair_start_tokens': [[CLS]], 'sequence_pair_mid_tokens': [[SEP]], 'sequence_pair_end_tokens': [[SEP]], 'sequence_pair_first_token_type_id': 0, 'sequence_pair_second_token_type_id': 1, 'single_sequence_start_tokens': [[CLS]], 'single_sequence_end_tokens': [[SEP]], 'single_sequence_token_type_id': 0}\n",
      "Done building\n"
     ]
    }
   ],
   "source": [
    "from KBQA.appB.transformer_architectures.kb.knowbert_utils import KnowBertBatchifier\n",
    "\n",
    "archive_file = 'https://allennlp.s3-us-west-2.amazonaws.com/knowbert/models/knowbert_wiki_wordnet_model.tar.gz'\n",
    "batcher = KnowBertBatchifier(archive_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"Batchifier.pkl\", \"wb\") as pickle_file:\n",
    "    pickle.dump(batcher, pickle_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_cased = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example:\n",
    "    \"\"\"A single training/test example.\"\"\"\n",
    "\n",
    "    def __init__(self, idx, source, triples, target):\n",
    "        self.idx = idx\n",
    "        self.source = source\n",
    "        self.triples = triples\n",
    "        self.target = target\n",
    "\n",
    "\n",
    "def read_examples(source_file, triples_file, target_file):\n",
    "    \"\"\"Read examples from filename.\"\"\"\n",
    "    examples = []\n",
    "    with open(source_file, encoding=\"utf-8\") as source_f:\n",
    "        with open(triples_file, encoding=\"utf-8\") as triples_f:\n",
    "            with open(target_file, encoding=\"utf-8\") as target_f:\n",
    "                for idx, (source, triples, target) in enumerate(\n",
    "                    zip(source_f, triples_f, target_f)\n",
    "                ):\n",
    "                    examples.append(\n",
    "                        Example(\n",
    "                            idx=idx,\n",
    "                            source=source.strip(),\n",
    "                            triples=triples.strip(),\n",
    "                            target=target.strip(),\n",
    "                        )\n",
    "                    )\n",
    "    return examples\n",
    "\n",
    "class InputFeatures:\n",
    "    \"\"\"A single training/test features for a example.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        example_id,\n",
    "        triples_ids,\n",
    "        target_ids,\n",
    "        triples_mask,\n",
    "        target_mask,\n",
    "    ):\n",
    "        self.example_id = example_id\n",
    "        self.triples_ids = triples_ids\n",
    "        self.target_ids = target_ids\n",
    "        self.triples_mask = triples_mask\n",
    "        self.target_mask = target_mask\n",
    "\n",
    "def replace_mask(text):\n",
    "    return text.replace('[MASK]', ' [MASK] ')\n",
    "def convert_examples_to_features(examples, \n",
    "                                 tokenizer, \n",
    "                                 max_triple_length, \n",
    "                                 max_target_length, \n",
    "                                 stage=None):\n",
    "    features = []\n",
    "    for example_index, example in enumerate(examples):\n",
    "        # source handled elsewhere\n",
    "        \n",
    "\n",
    "        # triples\n",
    "        triples_tokens = tokenizer.tokenize(example.triples)[: max_triple_length]\n",
    "        triples_ids = tokenizer.convert_tokens_to_ids(triples_tokens)\n",
    "        triples_mask = [1] * (len(triples_tokens))\n",
    "        padding_length = max_triple_length - len(triples_ids)\n",
    "        triples_ids += [tokenizer.pad_token_id] * padding_length\n",
    "        triples_mask += [0] * padding_length\n",
    "\n",
    "        # target\n",
    "        if stage == \"test\" or stage == \"predict\":\n",
    "            target_tokens = tokenizer.tokenize(\"None\")\n",
    "        else:\n",
    "            target_tokens = tokenizer.tokenize(example.target)[\n",
    "                : max_target_length - 2\n",
    "            ]\n",
    "        target_tokens = [tokenizer.cls_token] + target_tokens + [tokenizer.sep_token]\n",
    "        target_ids = tokenizer.convert_tokens_to_ids(target_tokens)\n",
    "        target_mask = [1] * len(target_ids)\n",
    "        padding_length = max_target_length - len(target_ids)\n",
    "        target_ids += [tokenizer.pad_token_id] * padding_length\n",
    "        target_mask += [0] * padding_length\n",
    "\n",
    "        if example_index < 5:\n",
    "            if stage == \"train\":\n",
    "                logger.info(\"*** Example ***\")\n",
    "                logger.info(\"idx: {}\".format(example.idx))\n",
    "\n",
    "                logger.info(\n",
    "                    \"triples_tokens: {}\".format(\n",
    "                        [x.replace(\"\\u0120\", \"_\") for x in triples_tokens]\n",
    "                    )\n",
    "                )\n",
    "                logger.info(\"triples_ids: {}\".format(\" \".join(map(str, triples_ids))))\n",
    "                logger.info(\"triples_mask: {}\".format(\" \".join(map(str, triples_mask))))\n",
    "\n",
    "                logger.info(\n",
    "                    \"target_tokens: {}\".format(\n",
    "                        [x.replace(\"\\u0120\", \"_\") for x in target_tokens]\n",
    "                    )\n",
    "                )\n",
    "                logger.info(\"target_ids: {}\".format(\" \".join(map(str, target_ids))))\n",
    "                logger.info(\"target_mask: {}\".format(\" \".join(map(str, target_mask))))\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                example_index,\n",
    "                triples_ids,\n",
    "                target_ids,\n",
    "                triples_mask,\n",
    "                target_mask,\n",
    "            )\n",
    "        )\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = \"../bert_spbert_spbert_base/data/qald-9-small/preprocessed_data_files/qtq-qald-9-train-small\"\n",
    "\n",
    "train_examples = read_examples(\n",
    "            train_filename + \".\" + \"en\",\n",
    "            train_filename + \".triple\",\n",
    "            train_filename + \".\" + \"sparql\",\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all boardgames by GMT .\n"
     ]
    }
   ],
   "source": [
    "print(train_examples[0].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/07/2022 07:47:59 - INFO - __main__ -   *** Example ***\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   idx: 0\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_tokens: ['d', '##b', '##r', ':', 'Greenwich', '_', 'Mean', '_', 'Time', 'a', 'ya', '##go', ':', 'Time', '##P', '##eri', '##od', '##11', '##51', '##13', '##22', '##9', '.', 'd', '##b', '##r', ':', 'Greenwich', '_', 'Mean', '_', 'Time']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_ids: 173 1830 1197 131 14323 168 25030 168 2614 170 11078 2758 131 2614 2101 9866 5412 14541 24050 17668 20581 1580 119 173 1830 1197 131 14323 168 25030 168 2614\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_tokens: ['[CLS]', 'select', 'variable', ':', 'u', '##ri', 'where', 'bracket', 'open', 'variable', ':', 'u', '##ri', 'd', '##bo', ':', 'publisher', 'd', '##b', '##r', ':', 'GM', '##T', '_', 'Games', 'bracket', 'close', '[SEP]']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_ids: 101 8247 7898 131 190 2047 1187 26083 1501 7898 131 190 2047 173 4043 131 6654 173 1830 1197 131 14748 1942 168 2957 26083 1601 102 0 0 0 0\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   *** Example ***\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   idx: 1\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_tokens: ['d', '##b', '##r', ':', 'Sky', '##pe', 'd', '##bo', ':', 'developer', 'd', '##b', '##r', ':', 'Sky', '##pe', '_', 'Technologies', '.', 'd', '##b', '##r', ':', 'Sky', '##pe', 'a', 'ya', '##go', ':', 'Act', '##ivity', '##100']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_ids: 173 1830 1197 131 5751 3186 173 4043 131 9991 173 1830 1197 131 5751 3186 168 14164 119 173 1830 1197 131 5751 3186 170 11078 2758 131 2173 6366 20150\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_tokens: ['[CLS]', 'select', 'distinct', 'variable', ':', 'u', '##ri', 'where', 'bracket', 'open', 'd', '##b', '##r', ':', 'Sky', '##pe', 'd', '##bo', ':', 'author', 'variable', ':', 'u', '##ri', '.', 'bracket', 'close', '[SEP]']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_ids: 101 8247 4966 7898 131 190 2047 1187 26083 1501 173 1830 1197 131 5751 3186 173 4043 131 2351 7898 131 190 2047 119 26083 1601 102 0 0 0 0\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   *** Example ***\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   idx: 2\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_tokens: ['d', '##b', '##r', ':', 'Cyril', '_', 'Luca', '##ris', 'd', '##bo', ':', 'birth', '##P', '##lace', 'd', '##b', '##r', ':', 'Her', '##ak', '##lion', '.', 'd', '##b', '##r', ':', 'O', '##dy', '##sse', '##as', '_', 'Ely']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_ids: 173 1830 1197 131 17007 168 16730 4889 173 4043 131 3485 2101 17510 173 1830 1197 131 1430 3715 12489 119 173 1830 1197 131 152 3810 11553 2225 168 22925\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_tokens: ['[CLS]', 'select', 'distinct', 'variable', ':', 'u', '##ri', 'where', 'bracket', 'open', 'variable', ':', 'u', '##ri', 'd', '##bo', ':', 'birth', '##P', '##lace', 'd', '##b', '##r', ':', 'Her', '##ak', '##lion', '.', 'bracket', 'close', '[SEP]']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_ids: 101 8247 4966 7898 131 190 2047 1187 26083 1501 7898 131 190 2047 173 4043 131 3485 2101 17510 173 1830 1197 131 1430 3715 12489 119 26083 1601 102 0\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   *** Example ***\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   idx: 3\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_tokens: ['d', '##b', '##r', ':', 'Area', '_', '51', 'a', 'ya', '##go', ':', 'Geographic', '##al', '##A', '##rea', '##10', '##8', '##5', '##7', '##43', '##14', '.', 'd', '##b', '##r', ':', 'Area', '_', '51', 'a', 'ya', '##go']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_ids: 173 1830 1197 131 3894 168 4062 170 11078 2758 131 15472 1348 1592 11811 10424 1604 1571 1559 25631 17175 119 173 1830 1197 131 3894 168 4062 170 11078 2758\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_tokens: ['[CLS]', 'select', 'distinct', 'variable', ':', 'u', '##ri', 'where', 'bracket', 'open', 'd', '##b', '##r', ':', 'Area', '_', '51', 'd', '##b', '##p', ':', 'nearest', '##T', '##own', 'variable', ':', 'u', '##ri', '.', 'bracket', 'close', '[SEP]']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_ids: 101 8247 4966 7898 131 190 2047 1187 26083 1501 173 1830 1197 131 3894 168 4062 173 1830 1643 131 6830 1942 13798 7898 131 190 2047 119 26083 1601 102\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   *** Example ***\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   idx: 4\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_tokens: ['d', '##b', '##r', ':', 'New', '_', 'York', '_', 'City', 'a', '<', 'http', ':', '/', '/', 'www', '.', 'w', '##iki', '##data', '.', 'org', '/', 'entity', '/', 'Q', '##48', '##6', '##9', '##7', '##2', '>']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_ids: 173 1830 1197 131 1203 168 1365 168 1392 170 133 8413 131 120 120 7001 119 192 12635 27922 119 8916 120 9127 120 154 19203 1545 1580 1559 1477 135\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_tokens: ['[CLS]', 'select', 'distinct', 'variable', ':', 'u', '##ri', 'where', 'bracket', 'open', 'd', '##b', '##r', ':', 'New', '_', 'York', '_', 'City', 'd', '##b', '##p', ':', 'leader', '##N', '##ame', 'variable', ':', 'u', '##ri', 'bracket', '[SEP]']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_ids: 101 8247 4966 7898 131 190 2047 1187 26083 1501 173 1830 1197 131 1203 168 1365 168 1392 173 1830 1643 131 2301 2249 16470 7898 131 190 2047 26083 102\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "train_features = convert_examples_to_features(train_examples, \n",
    "                                            tokenizer_cased, \n",
    "                                            max_triple_length=32, \n",
    "                                            max_target_length=32, \n",
    "                                            stage=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offsets: [1, 2, 4, 5, 7, 8]\n",
      "word_piece_tokens: [['list'], ['all'], ['board', '##games'], ['by'], ['gm', '##t'], ['.']]\n",
      "tokens: ['List', 'all', 'boardgames', 'by', 'GMT', '.']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'list', 'all', 'board', '##games', 'by', 'gm', '##t', '.', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['List', 'all', 'boardgames', 'by', 'GMT', '.'], 'candidate_spans': [[1, 1], [3, 4], [6, 7], [8, 8]], 'candidate_entities': [['List_(abstract_data_type)', 'List,_Schleswig-Holstein', 'President_of_Iran', 'Sniper_rifle', 'Angle_of_list', 'Prime_Minister_of_Poland', 'Robert_List', 'Prime_Minister_of_Iraq', 'Friedrich_List', 'Party-list_proportional_representation', 'Vice_President_of_Iran', 'President_of_Israel', 'President_of_Rhodesia', 'President_of_Croatia', 'Premier_of_the_Eastern_Cape', 'List_MP', 'Premier_of_the_Northern_Cape', 'Wilhelm_List', 'Civic_and_Municipal_Affairs_Bureau', 'Emanuel_List', 'Premier_of_KwaZulu-Natal', 'Premier_of_Gauteng', 'Joel_Abraham_List', 'Hans_List', 'Spencer_List', 'Eugene_List', 'Administrative_divisions_of_the_Republic_of_China', 'Liesbeth_List', 'Sumerian_King_List', 'International_Best_Dressed_List'], ['Board_game'], ['Greenwich_Mean_Time', 'GMT_(programme)', 'Western_European_Time', 'Coordinated_Universal_Time', 'Giant_Magellan_Telescope', 'GMT_Games', 'Guy_McCoy_Tormé', 'Grosmont_railway_station', 'Transport_for_Greater_Manchester', 'GMT_Records', 'Generic_Mapping_Tools', 'Time_zone', 'Royal_Observatory,_Greenwich', 'Pacific_Time_Zone', 'GM_GMT_platform', 'Rolex_GMT_Master_II'], ['Full_stop', 'Names_of_Burma', 'University_of_Yangon', 'Ne_Win', 'Administrative_divisions_of_Burma', 'Wa_people', 'Yangon_River', 'U_Nu', 'Yangon_Technological_University', 'U_Thant', 'Yangon', 'Naypyidaw', 'Greater_Tokyo_Area', 'Allies_of_World_War_II', 'Shiva', '1991_Bangladesh_cyclone', 'Bhopal', 'Ba_Win', 'Doctor_of_Philosophy', 'Walter_Chit_Tun', 'Big_Brother_(UK)', 'Harlem', 'Combining_character', '8888_Uprising', 'Union_Solidarity_and_Development_Association', 'Uncanny', 'Yangon_Region', 'Derby', 'A_Coruña', 'Shwe_Mann']], 'candidate_entity_priors': [[0.10822699359784338, 0.06431557858978235, 0.04270284395278969, 0.04028570184225395, 0.03833130090152822, 0.03404141805670433, 0.0334970166804577, 0.032832847001436946, 0.031079874569922946, 0.03067701755150048, 0.03021427638169046, 0.029811419363267998, 0.02900570532642308, 0.028602848308000618, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489], [1.0], [0.5219893136046035, 0.05442291775754556, 0.05293087625064248, 0.05287457279754914, 0.05242414517282329, 0.05222708308700442, 0.05219893136046036, 0.05219893136046036, 0.05219893136046036, 0.05219893136046036, 0.0033500554589012987, 0.00033782071854466644, 0.00022521381236311445, 0.0001407586327269439, 0.0001407586327269439, 0.0001407586327269439], [0.4705882352941141, 0.11764705882353167, 0.08403361344537887, 0.025210084033613033, 0.025210084033613033, 0.025210084033613033, 0.025210084033613033, 0.016806722689075772, 0.016806722689075772, 0.016806722689075772, 0.016806722689075772, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886]], 'candidate_segment_ids': [0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['List', 'all', 'boardgames', 'by', 'GMT', '.'], 'candidate_spans': [[1, 1], [2, 2], [5, 5], [6, 7]], 'candidate_entities': [['tilt.n.04', 'list.n.01', 'list.v.01', 'number.v.03', 'list.v.04', 'list.v.03', 'list.v.02'], ['all.s.02', 'all.a.01', 'wholly.r.01'], ['aside.r.06', 'by.r.01'], ['greenwich_mean_time.n.01']], 'candidate_entity_priors': [[0.017543859649122806, 0.5701754385964912, 0.21052631578947367, 0.008771929824561403, 0.008771929824561403, 0.008771929824561403, 0.17543859649122806], [0.014336917562724014, 0.8888888888888888, 0.0967741935483871], [0.25, 0.75], [1.0]], 'candidate_segment_ids': [0, 0, 0, 0]}}, 'offsets_a': [2, 3, 5, 6, 8, 9], 'offsets_b': None}\n",
      "List all boardgames by GMT .\n",
      "['[CLS]', 'list', 'all', 'board', '##games', 'by', 'gm', '##t', '.', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e90164e40>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 10 with text: \n",
      " \t\t[[CLS], list, all, board, ##games, by, gm, ##t, ., [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([  101,  2862,  2035,  2604, 26393,  2011, 13938,  2102,  1012,   102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e90164e40>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7f9e9100b6d0>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e9100b8e0>}\n",
      "TextField of length 10 with text: \n",
      " \t\t[[CLS], list, all, board, ##games, by, gm, ##t, ., [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 10 with text: \n",
      " \t\t[[CLS], list, all, board, ##games, by, gm, ##t, ., [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([10]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "offsets: [1, 2, 4, 5]\n",
      "word_piece_tokens: [['who'], ['developed'], ['sky', '##pe'], ['?']]\n",
      "tokens: ['Who', 'developed', 'Skype', '?']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'who', 'developed', 'sky', '##pe', '?', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['Who', 'developed', 'Skype', '?'], 'candidate_spans': [[1, 1], [2, 2], [3, 4], [5, 5]], 'candidate_entities': [['The_Who', 'Doctor_Who', 'Who_(magazine)', 'Who_(pronoun)', 'Jim_Neidhart', 'Who?_(album)', 'William_Coventry', 'Who?_(song)', 'Bobby_Who', 'Doctor_Who_(film)', 'Who?_(novel)', 'Who_(Unix)', 'Who_Dat_(Young_Jeezy_song)', 'Guess_Who_(rapper)', 'Speak_Your_Language', 'Who_See', 'Horton_Hears_a_Who!', 'Alfred_Russel_Wallace', 'Casimir_Pulaski', 'Harold_Dieterle', 'Measuring_poverty', 'Ace_Young', 'Victor_Lustig', 'Saint_Patrick', 'Section_28', 'The_Girl_in_the_Fireplace', 'New_York_City_Hall', 'Ken_Jennings', 'Zen_and_the_Art_of_Motorcycle_Maintenance', 'Diana,_Princess_of_Wales'], ['Video_game_developer', 'Developed_country', 'Software_developer', 'Software_development', 'Photographic_processing', 'Subdivision_(land)', 'Musical_development', 'Suburbanization', 'Timeline_of_jet_power', 'Rolls-Royce_Thrust_Measuring_Rig', 'Power_Jets', 'Photographic_developer', 'Video_game_development', 'Economic_development', 'Research_and_development', 'Agricultural_subsidy', 'Developed_market', 'Drug_development', 'Visual_arts', 'History_of_Sesame_Street', 'Adobe_Photoshop', 'Research', 'Construction', 'Philips', 'Ice-minus_bacteria', 'Nile', 'Custom_software', 'Tropical_cyclogenesis', 'Director_of_National_Intelligence', 'Selective_breeding'], ['Skype', 'Skype_Technologies', 'Skype_security', 'Skype_protocol', 'Niklas_Zennström', 'FastTrack', 'Janus_Friis', 'Features_of_Skype'], ['Question_mark', '?_(Lost)', 'Rugby_league_positions', '?_(Neal_Morse_album)', 'Chess_annotation_symbols', \"The_Emperor's_New_School\", 'Michigan', 'Pinyin', '?_(EP)', 'Latin_alphabet', '?_(film)', 'Jyutping', 'Yale_romanization_of_Cantonese', 'January_2006_in_Malaysia_and_Singapore', 'Traditional_Chinese_characters', 'Pe̍h-ōe-jī', '?_(bistro)']], 'candidate_entity_priors': [[0.27126923076923193, 0.10634615384615292, 0.08480769230769412, 0.038038461538461195, 0.03342307692307671, 0.03342307692307671, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.01999999999999996, 0.01476923076923056, 0.011692307692307571, 0.008307692307692387, 0.007692307692307473, 0.006769230769230894, 0.0049230769230768886, 0.00461538461538459, 0.003999999999999991, 0.003999999999999991, 0.003999999999999991, 0.0036923076923076927, 0.0036923076923076927, 0.0033846153846153943], [0.18887262079062966, 0.1670262772597676, 0.08002620020035567, 0.059451336980810364, 0.05798720813747547, 0.05267010865377228, 0.05243893041535152, 0.051591276874468545, 0.051591276874468545, 0.051591276874468545, 0.05151421746166334, 0.03498497341450292, 0.016567773753564052, 0.0114818525082842, 0.011404793095476935, 0.008938891885644016, 0.006704168914232883, 0.005162980658087629, 0.004623564768436481, 0.004084148878785591, 0.0036217924019419125, 0.0035447329891346497, 0.0033906141635201242, 0.0033906141635201242, 0.00331355475071281, 0.003082376512291022, 0.0029282576866764454, 0.00277413886106192, 0.0026970794482546055, 0.0025429606226400805], [0.6570337153296778, 0.32964623816641897, 0.008071748878923955, 0.004417870785583811, 0.0002657365886065451, 0.00019930244145490556, 0.00019930244145490556, 0.00016608536787908904], [0.9163961038961033, 0.01785714285714306, 0.008928571428571432, 0.00811688311688313, 0.007305194805194826, 0.007305194805194826, 0.006493506493506523, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129]], 'candidate_segment_ids': [0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['Who', 'developed', 'Skype', '?'], 'candidate_spans': [[1, 1], [2, 2]], 'candidate_entities': [['world_health_organization.n.01'], ['grow.v.08', 'build_up.v.05', 'develop.v.21', 'develop.v.10', 'develop.v.12', 'break.v.53', 'develop.v.09', 'develop.v.19', 'modernize.v.02', 'develop.v.14', 'develop.v.03', 'train.v.01', 'explicate.v.02', 'develop.v.18', 'develop.v.17', 'develop.v.16', 'develop.v.13', 'evolve.v.01', 'develop.v.01', 'develop.v.15', 'originate.v.01']], 'candidate_entity_priors': [[1.0], [0.08968609865470852, 0.05829596412556054, 0.004484304932735426, 0.02242152466367713, 0.017937219730941704, 0.004484304932735426, 0.02242152466367713, 0.004484304932735426, 0.017937219730941704, 0.008968609865470852, 0.18834080717488788, 0.026905829596412557, 0.03139013452914798, 0.004484304932735426, 0.004484304932735426, 0.004484304932735426, 0.008968609865470852, 0.20179372197309417, 0.20179372197309417, 0.004484304932735426, 0.07174887892376682]], 'candidate_segment_ids': [0, 0]}}, 'offsets_a': [2, 3, 5, 6], 'offsets_b': None}\n",
      "Who developed Skype ?\n",
      "['[CLS]', 'who', 'developed', 'sky', '##pe', '?', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e90175780>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 7 with text: \n",
      " \t\t[[CLS], who, developed, sky, ##pe, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([ 101, 2040, 2764, 3712, 5051, 1029,  102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e90175780>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7f9e9100be80>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e7e6f3220>}\n",
      "TextField of length 7 with text: \n",
      " \t\t[[CLS], who, developed, sky, ##pe, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 7 with text: \n",
      " \t\t[[CLS], who, developed, sky, ##pe, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([7]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "offsets: [1, 2, 3, 4, 5, 8, 9]\n",
      "word_piece_tokens: [['which'], ['people'], ['were'], ['born'], ['in'], ['her', '##ak', '##lion'], ['?']]\n",
      "tokens: ['Which', 'people', 'were', 'born', 'in', 'Heraklion', '?']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'which', 'people', 'were', 'born', 'in', 'her', '##ak', '##lion', '?', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['Which', 'people', 'were', 'born', 'in', 'Heraklion', '?'], 'candidate_spans': [[1, 1], [2, 2], [4, 4], [6, 8], [9, 9]], 'candidate_entities': [['Wilhelm_Canaris', 'Gluten-sensitive_enteropathy_associated_conditions'], ['People_(magazine)', 'People', 'People_(1964_song)', 'People_(Australian_magazine)', 'People_(Hothouse_Flowers_album)', 'People_(King_Crimson_song)', 'People_(Barbra_Streisand_album)', 'People!', 'People_(Howard_Jones_album)', 'The_Sunday_People', 'People,_Places,_Pieces', 'Blues_People', 'People_Capability_Maturity_Model', 'Village_People', 'Bright_young_things', 'Go_Down_Moses', 'People_Like_Us_(musician)', 'The_Autumn_People', 'People_(The_Golden_Republic_EP)', 'Epic_Games_Poland', 'Malayali', 'Dead_Famous_People', 'The_Sky_People', 'People,_People', 'People_Telecom', 'The_People_(Common_song)', 'The_Forest_People', 'Brazilian_people', 'Tamil_people', 'Cumbria'], ['Nativity_of_Jesus', 'Michael_Savage', 'Richard_Nixon', 'Franklin_D._Roosevelt', 'Troy,_New_York', 'Ingvar_Kamprad', 'Anna_Jarvis', 'Bernadette_Soubirous', 'Thomas_A._Watson', 'William_McKinley', 'Leonard_Nimoy', 'Sirhan_Sirhan', 'James_Watson', 'Charles_Darwin', 'Ethel_Merman', 'Wacław_Sierpiński', 'Thomas_Jefferson', 'George_Plimpton', 'Warren_Beatty', 'Ulysses_S._Grant', 'Millard_Fillmore', 'Abraham_Lincoln', 'George_Washington', 'Neil_Diamond', 'William_Henry_Harrison', 'Dian_Fossey', 'Helge_von_Koch', 'Charles_Dickens', 'A._J._Foyt', 'Frank_Zamboni'], ['Heraklion'], ['Question_mark', '?_(Lost)', 'Rugby_league_positions', '?_(Neal_Morse_album)', 'Chess_annotation_symbols', \"The_Emperor's_New_School\", 'Michigan', 'Pinyin', '?_(EP)', 'Latin_alphabet', '?_(film)', 'Jyutping', 'Yale_romanization_of_Cantonese', 'January_2006_in_Malaysia_and_Singapore', 'Traditional_Chinese_characters', 'Pe̍h-ōe-jī', '?_(bistro)']], 'candidate_entity_priors': [[0.84444444444444, 0.15555555555556], [0.3179649761604218, 0.05377729553777278, 0.030802355788792823, 0.030395465784723984, 0.029717315777942198, 0.027343790754207384, 0.026258750743356755, 0.025004173230811114, 0.02391913321996049, 0.022935815710127216, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021226095212260866, 0.009629730096297447, 0.00725620507256206], [0.7025110495895812, 0.015930836854630655, 0.014716596240711189, 0.014279469619699505, 0.009762494535917038, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009665355286803564], [1.0], [0.9163961038961033, 0.01785714285714306, 0.008928571428571432, 0.00811688311688313, 0.007305194805194826, 0.007305194805194826, 0.006493506493506523, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129]], 'candidate_segment_ids': [0, 0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['Which', 'people', 'were', 'born', 'in', 'Heraklion', '?'], 'candidate_spans': [[2, 2], [3, 3], [4, 4], [5, 5]], 'candidate_entities': [['people.n.01', 'people.n.03', 'citizenry.n.01', 'multitude.n.03', 'people.v.01', 'people.v.02'], ['beryllium.n.01', 'be.v.10', 'be.v.08', 'exist.v.01', 'be.v.01', 'be.v.11', 'be.v.02', 'constitute.v.01', 'be.v.03', 'equal.v.01', 'embody.v.02', 'cost.v.01', 'be.v.12', 'be.v.05'], ['bear.n.01', 'bear.n.02', 'wear.v.02', 'give_birth.v.01', 'have_a_bun_in_the_oven.v.01', 'digest.v.03', 'bear.v.04', 'hold.v.14', 'bear.v.05', 'yield.v.10', 'bear.v.06', 'bear.v.11', 'behave.v.02', 'bear.v.01', 'hold.v.11'], ['in.s.03', 'in.s.02', 'in.s.01', 'in.r.01', 'indiana.n.01', 'inch.n.01', 'indium.n.01']], 'candidate_entity_priors': [[0.8716216216216216, 0.013513513513513514, 0.09797297297297297, 0.006756756756756757, 0.006756756756756757, 0.0033783783783783786], [5.994844433786943e-05, 0.0001798453330136083, 0.0052155146573946405, 0.04208380792518434, 0.6440261375217313, 0.00011989688867573886, 0.1810443019003657, 0.011390204424195192, 0.054073496792758226, 0.016246028415562615, 0.0035369582159342967, 5.994844433786943e-05, 5.994844433786943e-05, 0.04190396259217073], [0.020202020202020204, 0.010101010101010102, 0.020202020202020204, 0.18181818181818182, 0.010101010101010102, 0.1414141414141414, 0.1111111111111111, 0.010101010101010102, 0.0707070707070707, 0.050505050505050504, 0.06060606060606061, 0.010101010101010102, 0.010101010101010102, 0.24242424242424243, 0.050505050505050504], [0.034482758620689655, 0.034482758620689655, 0.034482758620689655, 0.6896551724137931, 0.034482758620689655, 0.13793103448275862, 0.034482758620689655]], 'candidate_segment_ids': [0, 0, 0, 0]}}, 'offsets_a': [2, 3, 4, 5, 6, 9, 10], 'offsets_b': None}\n",
      "Which people were born in Heraklion ?\n",
      "['[CLS]', 'which', 'people', 'were', 'born', 'in', 'her', '##ak', '##lion', '?', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7fa0451f6e40>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 11 with text: \n",
      " \t\t[[CLS], which, people, were, born, in, her, ##ak, ##lion, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([  101,  2029,  2111,  2020,  2141,  1999,  2014,  4817, 18964,  1029,\n",
      "          102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7fa0451f6e40>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7f9e7e6f3430>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e7e6f3280>}\n",
      "TextField of length 11 with text: \n",
      " \t\t[[CLS], which, people, were, born, in, her, ##ak, ##lion, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 11 with text: \n",
      " \t\t[[CLS], which, people, were, born, in, her, ##ak, ##lion, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([11]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "offsets: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "word_piece_tokens: [['in'], ['which'], ['u'], ['.'], ['s'], ['.'], ['state'], ['is'], ['area'], ['51'], ['located'], ['?']]\n",
      "tokens: ['In', 'which', 'U', '.', 'S', '.', 'state', 'is', 'Area', '51', 'located', '?']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'in', 'which', 'u', '.', 's', '.', 'state', 'is', 'area', '51', 'located', '?', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['In', 'which', 'U', '.', 'S', '.', 'state', 'is', 'Area', '51', 'located', '?'], 'candidate_spans': [[1, 1], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [9, 9], [9, 10], [10, 10], [11, 11], [12, 12]], 'candidate_entities': [['Indium', 'Cause_of_action', 'The_Vengeance_Trilogy', 'In_scale', 'In_The_Wings', 'In_the_City_(Joe_Walsh_song)', 'Song_In', 'In_My_Head_(Queens_of_the_Stone_Age_song)', 'Tak_Jae-in', 'In_Your_Arms_(Love_song_from_Neighbours)', 'In_Arabian_Nights', 'In_Flames', 'Kim_In', 'In_Private', 'Han_Ga-in', 'In_Tam', 'In_Case_of_Fire', 'In_the_Hunt', 'In_Reality', 'In_This_Moment', 'In_Your_Eyes_(George_Benson_song)', 'Preap_In', 'In_Excess_(horse)', 'Sitre_In', 'Han_Jong-In', 'In_R_Voice', 'In_Extremo', 'In_the_Fishtank', 'Ultimate_fate_of_the_universe', 'Troll_(Internet)'], ['U', 'Uranium', 'U_Khandi', 'U_Ottama', 'U_Thant', 'U_Razak', 'U_Saw', 'U_L_Washington', 'U_Pandita', 'U_Nu', 'U_Brown', 'U_(Super_Junior_song)', 'Soyuz-U', 'UK_railway_stations_–_U', 'Uniform_polyhedron', 'Haplogroup_U_(mtDNA)', 'U_engine', 'Index_of_World_War_II_articles_(U)', 'Neuromedin_U_receptor', 'University_of_Liverpool', 'Indoctrinate_U', 'Neuromedin_U', 'British_U-class_submarine', 'Rack_unit', 'Airline_codes-U', 'SJ_U', 'United_Kingdom', 'U_and_non-U_English', 'U_(album)', 'United_States'], ['Full_stop', 'Names_of_Burma', 'University_of_Yangon', 'Ne_Win', 'Administrative_divisions_of_Burma', 'Wa_people', 'Yangon_River', 'U_Nu', 'Yangon_Technological_University', 'U_Thant', 'Yangon', 'Naypyidaw', 'Greater_Tokyo_Area', 'Allies_of_World_War_II', 'Shiva', '1991_Bangladesh_cyclone', 'Bhopal', 'Ba_Win', 'Doctor_of_Philosophy', 'Walter_Chit_Tun', 'Big_Brother_(UK)', 'Harlem', 'Combining_character', '8888_Uprising', 'Union_Solidarity_and_Development_Association', 'Uncanny', 'Yangon_Region', 'Derby', 'A_Coruña', 'Shwe_Mann'], ['Sulfur', 'S', 'Silurian', 'Ś', 'Sat_Parashar', 'S_V_S_Rama_Rao', 'S_E_A_Holdings', 'S_G_Thakur_Singh', 'Š', 'S_John_Massoud', 'Ŝ', 'S._U._Hastings', 'S_Club', 'S._K._Venkataranga', 'S._B._Tambe', 'Sivaramakrishnan_Murali', 'S_(programming_language)', 'UK_railway_stations_–_S', 'Southern_Hemisphere', 'ATC_code_S', 'Simplified_Chinese_characters', 'Shot_(ice_hockey)', 'United_States_District_Court_for_the_Southern_District_of_Iowa', 'S-type_star', 'Sense_(molecular_biology)', 'S-type_asteroid', '1996_Italian_Indoor_–_Singles', '1996_Trofeo_Conde_de_Godó_–_Singles', \"1996_French_Open_–_Men's_Singles\", 'Haplogroup_S-M230'], ['Full_stop', 'Names_of_Burma', 'University_of_Yangon', 'Ne_Win', 'Administrative_divisions_of_Burma', 'Wa_people', 'Yangon_River', 'U_Nu', 'Yangon_Technological_University', 'U_Thant', 'Yangon', 'Naypyidaw', 'Greater_Tokyo_Area', 'Allies_of_World_War_II', 'Shiva', '1991_Bangladesh_cyclone', 'Bhopal', 'Ba_Win', 'Doctor_of_Philosophy', 'Walter_Chit_Tun', 'Big_Brother_(UK)', 'Harlem', 'Combining_character', '8888_Uprising', 'Union_Solidarity_and_Development_Association', 'Uncanny', 'Yangon_Region', 'Derby', 'A_Coruña', 'Shwe_Mann'], ['Political_divisions_of_the_United_States', 'U.S._state', 'States_of_Brazil', 'States_of_Germany', 'States_and_union_territories_of_India', 'States_of_Austria', 'State_pattern', 'Administrative_divisions_of_Mexico', 'United_States_Department_of_State', 'States_of_Nigeria', 'Federated_state', 'States_of_Venezuela', 'Michigan', 'State_(magazine)', 'United_States_Secretary_of_State', 'State_(computer_science)', 'State_school', 'State_government', 'Hawaii', 'States_and_federal_territories_of_Malaysia', 'States_of_the_German_Confederation', 'State_(MBTA_station)', 'New_York', 'State_Street_(Chicago)', 'Member_state_of_the_European_Union', 'Republic_of_Ireland', 'USSR_State_Prize', 'United_States', 'State_Border_Guard_Service_of_Ukraine', 'New_South_Wales'], ['Area', 'Area_(LDS_Church)', 'Area_(band)', 'Area_(country_subdivision)', 'Area_(nightclub)', 'Area_(EP)', 'Area_(journal)', 'Electric_Area', 'Ark_Area', 'Area_(travel_agency)', 'Miami_metropolitan_area', 'Geography_of_India', 'Surface_area', 'Ranked_list_of_states_and_territories_of_Australia', 'Geography_of_Scotland', 'Charlotte_metropolitan_area', 'Trilinear_filtering', 'Area_51', 'Catanduanes', 'East_Windsor,_Connecticut', 'Ancient_Roman_units_of_measurement', 'Central_Australia', 'Braj', 'Northeastern_Pennsylvania', 'Arnold_Arboretum', 'Tenderloin,_San_Francisco', 'Geography_of_the_United_States', 'Biblical_and_Talmudic_units_of_measurement', 'Recovered_Territories', 'English_units'], ['Area_51', 'Area_51_(1995_video_game)', 'Seattle'], ['No._51_Squadron_RAF', '51', \"Now_That's_What_I_Call_Music!_51_(UK_series)\", 'Saskatchewan_Highway_51', 'Route_51_(MTA_Maryland)', 'Adh-Dhariyat', 'Malaysia_Federal_Route_51', 'Bugatti_Type_51', 'National_Highway_51_(India)', 'Small_nucleolar_RNA_SNORA51', 'Small_nucleolar_RNA_SNORD51', 'London_Buses_route_51', 'UFC_51', 'U.S._Route_51', 'Pennsylvania_House_of_Representatives,_District_51', 'Parker_51', 'February_20', \"California's_51st_State_Assembly_district\", 'Jauchzet_Gott_in_allen_Landen,_BWV_51', '51_(number)', '51_(film)', 'Psalm_51', 'Mexican_Federal_Highway_51', 'Sonnet_51', 'Dick_Butkus', 'Symphony_No._51_(Haydn)', 'Ontario_Highway_51', 'The_Absolute_(Animorphs)', 'Fabric_51', 'FabricLive.51'], ['Locus_(genetics)', 'Space_Shuttle_Challenger_disaster', 'South_Padre_Island', 'Location_(geography)', 'Map_Room_(White_House)', 'Sderot', \"Shenzhen_Bao'an_International_Airport\", 'Rural_Khmer_house', 'Liver', 'Search_for_HMAS_Sydney_and_German_auxiliary_cruiser_Kormoran', 'Nazi_concentration_camps', 'Yellow_Sea', 'Battle_between_HMAS_Sydney_and_German_auxiliary_cruiser_Kormoran', 'Tallapoosa_County,_Alabama', 'Naypyidaw', 'Topkapı_Palace', 'Latvia', 'Drax_power_station', 'Palazzo_Malta', 'World_Geodetic_System', 'CBLFT-DT'], ['Question_mark', '?_(Lost)', 'Rugby_league_positions', '?_(Neal_Morse_album)', 'Chess_annotation_symbols', \"The_Emperor's_New_School\", 'Michigan', 'Pinyin', '?_(EP)', 'Latin_alphabet', '?_(film)', 'Jyutping', 'Yale_romanization_of_Cantonese', 'January_2006_in_Malaysia_and_Singapore', 'Traditional_Chinese_characters', 'Pe̍h-ōe-jī', '?_(bistro)']], 'candidate_entity_priors': [[0.2694610778443102, 0.054131736526946146, 0.0479041916167662, 0.0359281437125745, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.013413173652694624, 0.012694610778442875], [0.20981793918596725, 0.06200552854828033, 0.05444666857306266, 0.05444666857306266, 0.05444666857306266, 0.05444666857306266, 0.05444666857306266, 0.05444666857306266, 0.05444666857306266, 0.05444666857306266, 0.05444666857306266, 0.0538080259269851, 0.050281193403869814, 0.028691259174530814, 0.016776284434277016, 0.011009436659994225, 0.010675817367267242, 0.009055380802592472, 0.00891240110570987, 0.006529406157659219, 0.005242588885711541, 0.005242588885711541, 0.005147269087789514, 0.0044800305023353325, 0.00428939090649128, 0.004003431512725203, 0.003860451815842163, 0.003669812219998111, 0.0032408731293489938, 0.0032408731293489938], [0.4705882352941141, 0.11764705882353167, 0.08403361344537887, 0.025210084033613033, 0.025210084033613033, 0.025210084033613033, 0.025210084033613033, 0.016806722689075772, 0.016806722689075772, 0.016806722689075772, 0.016806722689075772, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886], [0.09842482461282503, 0.07561976438552914, 0.06253427377418072, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.021424654425807856, 0.011251252765539102, 0.008150067129323216, 0.007828602764593809, 0.0077718737590527455, 0.007280222377701462, 0.006032184255810027, 0.00597545525026949, 0.005332526520810084, 0.005237978178242566, 0.005029971824593906, 0.005029971824593906, 0.004708507459864236, 0.004689597791350745], [0.4705882352941141, 0.11764705882353167, 0.08403361344537887, 0.025210084033613033, 0.025210084033613033, 0.025210084033613033, 0.025210084033613033, 0.016806722689075772, 0.016806722689075772, 0.016806722689075772, 0.016806722689075772, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886], [0.49733649419169623, 0.10236499337592048, 0.03329344422907955, 0.031455804318718486, 0.025987785054905108, 0.025397520485207676, 0.023002660731060214, 0.020237750496679623, 0.016399012795120044, 0.014997512816813309, 0.013968585816900626, 0.01376703821382942, 0.011680427734968161, 0.011158775115252846, 0.010992794736252719, 0.010826814357252593, 0.010565988047394495, 0.010269594513465319, 0.010127325617179245, 0.009899544033232188, 0.009890210790036078, 0.009854643565965, 0.009724230411035952, 0.009724230411035952, 0.009617528738821837, 0.009581961514749876, 0.009570105773392852, 0.009570105773392852, 0.009368558170320765, 0.009368558170320765], [0.44163340657054684, 0.054259675762813986, 0.05354463786580836, 0.05318061857278422, 0.050723488344883785, 0.050437473186080536, 0.05017745940534757, 0.05011245596016433, 0.05007345389305639, 0.05007345389305639, 0.05007345389305639, 0.03433481974544642, 0.006929367256464794, 0.0014560771720901072, 0.0008320440983372112, 0.0002470130916938588, 0.00023401240265734098, 0.00023401240265734098, 0.000156008268438229, 0.000156008268438229, 0.00014300757940170615, 0.00013000689036518832, 0.00013000689036518832, 0.00011700620132867049, 0.00011700620132867049, 0.00010400551229215266, 0.00010400551229215266, 0.00010400551229215266, 9.100482325563483e-05, 9.100482325563483e-05], [0.8185938188455949, 0.18096556933341953, 0.00044061182098570893], [0.09255801547079186, 0.08802347292611305, 0.051080288076820926, 0.04547879434515865, 0.04361162976793788, 0.04321152307281988, 0.04201120298746331, 0.04067751400373493, 0.03841024273139488, 0.03654307815417411, 0.036409709255801025, 0.03560949586556374, 0.03320885569485187, 0.027473993064817775, 0.027473993064817775, 0.027207255268071585, 0.02667377967458049, 0.025606828487597013, 0.024806615097359725, 0.024406508402240443, 0.02400640170712244, 0.022405974926646584, 0.022005868231528582, 0.021205654841291294, 0.018805014670579438, 0.01720458789010358, 0.01707121899173049, 0.016137636703121388, 0.01533742331288282, 0.01533742331288282], [0.5045296167247405, 0.13937282229965112, 0.13937282229965112, 0.06480836236933663, 0.03972125435540094, 0.02299651567944281, 0.01742160278745626, 0.016724738675958133, 0.009059233449477195, 0.008362369337979066, 0.007665505226480937, 0.0055749128919860445, 0.0041811846689895835, 0.0041811846689895835, 0.0034843205574913026, 0.0034843205574913026, 0.0034843205574913026, 0.0034843205574913026, 0.0006968641114982807, 0.0006968641114982807, 0.0006968641114982807], [0.9163961038961033, 0.01785714285714306, 0.008928571428571432, 0.00811688311688313, 0.007305194805194826, 0.007305194805194826, 0.006493506493506523, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129]], 'candidate_segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['In', 'which', 'U', '.', 'S', '.', 'state', 'is', 'Area', '51', 'located', '?'], 'candidate_spans': [[1, 1], [3, 3], [5, 5], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11]], 'candidate_entities': [['in.s.03', 'in.s.02', 'in.s.01', 'in.r.01', 'indiana.n.01', 'inch.n.01', 'indium.n.01'], ['u.s.01', 'u.n.03', 'u.n.03', 'uranium.n.01', 'uracil.n.01'], ['randomness.n.01', 's.n.05', 's.n.05', 'mho.n.01', 'south.n.03', 'sulfur.n.01', 'second.n.01'], ['state.n.02', 'department_of_state.n.01', 'state.n.04', 'state.n.03', 'country.n.02', 'state.n.01', 'state.n.06', 'state_of_matter.n.01', 'submit.v.02', 'state.v.01', 'express.v.04'], ['beryllium.n.01', 'be.v.10', 'be.v.08', 'exist.v.01', 'be.v.01', 'be.v.11', 'be.v.02', 'constitute.v.01', 'be.v.03', 'equal.v.01', 'embody.v.02', 'cost.v.01', 'be.v.12', 'be.v.05'], ['area.n.05', 'area.n.06', 'area.n.03', 'area.n.02', 'area.n.01', 'sphere.n.01'], ['fifty-one.s.01'], ['settle.v.04', 'locate.v.01', 'locate.v.03', 'situate.v.01']], 'candidate_entity_priors': [[0.034482758620689655, 0.034482758620689655, 0.034482758620689655, 0.6896551724137931, 0.034482758620689655, 0.13793103448275862, 0.034482758620689655], [0.2, 0.2, 0.2, 0.2, 0.2], [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285], [0.13651877133105803, 0.0034129692832764505, 0.07508532423208192, 0.08532423208191127, 0.0034129692832764505, 0.3720136518771331, 0.0034129692832764505, 0.0034129692832764505, 0.05460750853242321, 0.2525597269624573, 0.010238907849829351], [5.994844433786943e-05, 0.0001798453330136083, 0.0052155146573946405, 0.04208380792518434, 0.6440261375217313, 0.00011989688867573886, 0.1810443019003657, 0.011390204424195192, 0.054073496792758226, 0.016246028415562615, 0.0035369582159342967, 5.994844433786943e-05, 5.994844433786943e-05, 0.04190396259217073], [0.04072398190045249, 0.027149321266968326, 0.09502262443438914, 0.12669683257918551, 0.665158371040724, 0.04524886877828054], [1.0], [0.125, 0.425, 0.125, 0.325]], 'candidate_segment_ids': [0, 0, 0, 0, 0, 0, 0, 0]}}, 'offsets_a': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], 'offsets_b': None}\n",
      "In which U . S . state is Area 51 located ?\n",
      "['[CLS]', 'in', 'which', 'u', '.', 's', '.', 'state', 'is', 'area', '51', 'located', '?', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e7eb2a180>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 14 with text: \n",
      " \t\t[[CLS], in, which, u, ., s, ., state, is, area, 51, located, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([ 101, 1999, 2029, 1057, 1012, 1055, 1012, 2110, 2003, 2181, 4868, 2284,\n",
      "        1029,  102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e7eb2a180>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7f9e901ee640>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e901eeb80>}\n",
      "TextField of length 14 with text: \n",
      " \t\t[[CLS], in, which, u, ., s, ., state, is, area, 51, located, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 14 with text: \n",
      " \t\t[[CLS], in, which, u, ., s, ., state, is, area, 51, located, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([14]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "offsets: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "word_piece_tokens: [['who'], ['is'], ['the'], ['mayor'], ['of'], ['new'], ['york'], ['city'], ['?']]\n",
      "tokens: ['Who', 'is', 'the', 'mayor', 'of', 'New', 'York', 'City', '?']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'who', 'is', 'the', 'mayor', 'of', 'new', 'york', 'city', '?', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['Who', 'is', 'the', 'mayor', 'of', 'New', 'York', 'City', '?'], 'candidate_spans': [[1, 1], [4, 4], [4, 7], [4, 8], [6, 6], [6, 7], [6, 8], [7, 7], [7, 8], [8, 8], [9, 9]], 'candidate_entities': [['The_Who', 'Doctor_Who', 'Who_(magazine)', 'Who_(pronoun)', 'Jim_Neidhart', 'Who?_(album)', 'William_Coventry', 'Who?_(song)', 'Bobby_Who', 'Doctor_Who_(film)', 'Who?_(novel)', 'Who_(Unix)', 'Who_Dat_(Young_Jeezy_song)', 'Guess_Who_(rapper)', 'Speak_Your_Language', 'Who_See', 'Horton_Hears_a_Who!', 'Alfred_Russel_Wallace', 'Casimir_Pulaski', 'Harold_Dieterle', 'Measuring_poverty', 'Ace_Young', 'Victor_Lustig', 'Saint_Patrick', 'Section_28', 'The_Girl_in_the_Fireplace', 'New_York_City_Hall', 'Ken_Jennings', 'Zen_and_the_Art_of_Motorcycle_Maintenance', 'Diana,_Princess_of_Wales'], ['Mayor', 'Burgomaster', 'Mayor_of_New_York_City', 'Mayor_of_Chicago', 'Mayor_of_San_Francisco', 'Mayor_of_London', 'Mayor_of_Mumbai', 'Mayor_of_Gibraltar', 'Michel_Mayor', 'Mayors_in_England', 'Mayor_of_Los_Angeles', 'Mayor_(musical)', 'Mayor_(Buffy_the_Vampire_Slayer)', 'Lord_Mayor_of_Liverpool', 'Mayor_of_Cape_Town', 'Burgemeester', 'Danny_Mayor', 'Mayor_of_Castile', 'Mayor_of_Honolulu', 'Governing_Mayor_of_Berlin', 'Mayor_of_Dunedin', 'Mayor_of_the_Palace', 'Lord_Mayor_of_London', 'Directly_elected_mayor_of_Doncaster', 'Mayor_of_Hamilton,_New_Zealand', 'Mayor_of_Wellington', 'Mayor_of_Raleigh,_North_Carolina', 'Mayor_of_Derry', 'Mayor_of_Kilkenny', 'Mayor_of_Kiev'], ['Mayor_of_New_York_City'], ['Mayor_of_New_York_City'], ['Harry_Stewart_New', 'New_feminism', 'New_(film)', 'New_Testament', 'New_antisemitism', 'New_(song)', 'New_South_Wales', 'New_Delhi', 'French_New_Wave', 'New_Island', 'New_World', 'New_York_City', 'New_Latin', 'New_Zealand', 'USS_New_(DD-818)', 'New_River_(Kanawha_River)', 'New_River_(North_Carolina)', 'Northeast_blackout_of_1965', 'New_Journalism', 'New_York', 'New_England_Patriots', 'New_South', 'New_Gate', 'New_College,_Toronto', 'New_Jersey', 'Tom_New', 'John_C._New', 'New_Orleans_Pelicans', 'New_Town,_Edinburgh', 'New_Order'], ['New_York', 'New_York_City', 'New_York_(magazine)', 'United_States_congressional_delegations_from_New_York', 'New_York_(film)', 'Province_of_New_York', 'Manhattan', 'New_York_Knicks', 'New_York_metropolitan_area', 'New_York_GAA', 'New_York_Liberty', 'New_York_Yankees', 'New_York_Stock_Exchange', 'Miss_New_York_USA', 'New_York_(album)', 'New_York_Republican_State_Committee', 'New_York_Mets', 'New_York-class_battleship', 'John_F._Kennedy_International_Airport', 'New_York_(Paloma_Faith_song)', 'New_York_(Ja_Rule_song)', 'Miss_New_York_Teen_USA', 'Tiffany_Pollard', 'New_York_Harbor', 'Federal_Reserve_Bank_of_New_York', 'Pennsylvania_Station_(New_York_City)', 'Miss_New_York', 'USS_New_York_(ACR-2)', 'Roman_Catholic_Archdiocese_of_New_York', 'New_York_(U2_song)'], ['New_York_City', 'New_York', 'Manhattan', 'New_York_City_(Brazilian_Girls_album)', 'Pennsylvania_Station_(New_York_City)', 'New_York_metropolitan_area', 'USS_New_York_City_(SSN-696)', 'New_York_City_(band)', 'New_York_City_(Emigrate_song)', 'New_York_Fashion_Week', 'New_York_City_Marathon', 'New_York_City_bid_for_the_2012_Summer_Olympics', 'New_York_City_(album)', 'New_York_City_Subway', 'The_Real_Housewives_of_New_York_City', 'New_York_City_Police_Department', 'New_York_City_water_supply_system', 'WNBC', 'WABC-TV', 'WCBS-TV', 'Bus_depots_of_MTA_Regional_Bus_Operations', 'New_York_City_Department_of_Transportation', 'Labor_Day_Carnival', 'New_York_City_Fire_Department', 'New_York_City_(video_game)', 'Midtown_Manhattan', 'Congestion_pricing_in_New_York_City', 'New_Jersey_Generals', 'Evacuation_Day_(New_York)', 'Greenwich_Village'], ['York', 'York,_Pennsylvania', 'York,_Upper_Canada', 'York_railway_station', 'York,_South_Carolina', 'York_County,_Maine', 'York,_Maine', 'York,_Ontario', 'York_County,_Pennsylvania', 'York_County,_South_Carolina', 'Province_of_York', 'York,_Nebraska', 'York_County,_Virginia', 'National_Register_of_Historic_Places_listings_in_York_County,_Pennsylvania', 'York,_Western_Australia', 'Archbishop_of_York', 'York_Racecourse', 'House_of_York', 'York_City_Knights', 'York_(explorer)', 'MV_York', 'Regional_Municipality_of_York', 'University_of_York', 'City_of_York_(UK_Parliament_constituency)', 'York,_Dane_County,_Wisconsin', 'York,_Clark_County,_Wisconsin', 'Maryland_Route_45', 'York_County,_New_Brunswick', 'Diocese_of_York', 'York_River_(Virginia)'], ['York_City_F.C.', 'York_City_School_District', 'York,_Pennsylvania', '2010–11_York_City_F.C._season', '2007–08_York_City_F.C._season', '2009–10_York_City_F.C._season', '2006–07_York_City_F.C._season', '2008–09_York_City_F.C._season', 'New_York_City', 'History_of_York_City_F.C.'], ['City', 'City_of_London', 'Administrative_divisions_of_New_York', 'City_(New_Jersey)', 'Cities_of_the_Philippines', 'City_(novel)', 'City_status_in_the_United_Kingdom', 'Honda_City', 'London_City_Airport', 'City-state', 'Types_of_inhabited_localities_in_Russia', 'Lego_City', 'Manchester_City_F.C.', 'Central_railway_station,_Brisbane', 'City_University_London', 'GWR_3700_Class', 'Cities_of_Japan', 'City_(typeface)', 'City_(Strapping_Young_Lad_album)', 'Adelaide', 'City_(band)', 'City_(artwork)', 'City_(newspaper)', 'Bowen_Hills_railway_station', 'City_(Client_album)', 'City_Township,_Barton_County,_Missouri', 'City,_Australian_Capital_Territory', 'San_Diego', 'City_car', 'City_(magazine)'], ['Question_mark', '?_(Lost)', 'Rugby_league_positions', '?_(Neal_Morse_album)', 'Chess_annotation_symbols', \"The_Emperor's_New_School\", 'Michigan', 'Pinyin', '?_(EP)', 'Latin_alphabet', '?_(film)', 'Jyutping', 'Yale_romanization_of_Cantonese', 'January_2006_in_Malaysia_and_Singapore', 'Traditional_Chinese_characters', 'Pe̍h-ōe-jī', '?_(bistro)']], 'candidate_entity_priors': [[0.27126923076923193, 0.10634615384615292, 0.08480769230769412, 0.038038461538461195, 0.03342307692307671, 0.03342307692307671, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.01999999999999996, 0.01476923076923056, 0.011692307692307571, 0.008307692307692387, 0.007692307692307473, 0.006769230769230894, 0.0049230769230768886, 0.00461538461538459, 0.003999999999999991, 0.003999999999999991, 0.003999999999999991, 0.0036923076923076927, 0.0036923076923076927, 0.0033846153846153943], [0.5183833817864864, 0.04969671475144521, 0.039559875441826806, 0.02561927051119103, 0.024972238214832555, 0.016874530990708306, 0.016796102833573464, 0.016443176126469096, 0.014776577787363201, 0.014541293315960057, 0.013678583587482323, 0.013639369508915247, 0.013502120233930139, 0.013482513194646254, 0.013423692076795295, 0.013345263919661144, 0.013345263919661144, 0.013286442801810187, 0.013090372408974116, 0.013070765369690925, 0.01303155129112385, 0.012894302016138047, 0.012894302016138047, 0.012855087937570972, 0.012815873859003896, 0.012815873859003896, 0.012815873859003896, 0.012796266819720705, 0.012776659780436822, 0.012776659780436822], [1.0], [1.0], [0.09425606588183326, 0.08752279887249212, 0.08326286409108523, 0.06257668711656397, 0.05327474713977803, 0.04795777372464469, 0.044818438069971295, 0.0395332449013427, 0.037841983087381834, 0.037207759907146205, 0.03633034875366226, 0.03488227491294972, 0.033613828552478464, 0.026605593323384268, 0.025791742662908585, 0.024068700602442983, 0.0234662576687121, 0.023043442215221276, 0.021140772674515616, 0.018815287680317906, 0.016880837893107504, 0.016278394959376618, 0.015823799259382272, 0.01543276405239619, 0.015221356325651388, 0.015189576079146644, 0.012684463604708878, 0.012441275631459333, 0.012229867904714533, 0.011807052451224195], [0.6740615113811484, 0.15013833239867524, 0.017392424509258934, 0.008614759966229736, 0.008589453684598267, 0.00810863433360035, 0.007721809742947918, 0.007569972053159102, 0.006886702449109431, 0.005975676310376626, 0.005769610874234674, 0.005657540198438116, 0.005541854339551451, 0.00537194073431156, 0.0053538648188604845, 0.0053249433541388185, 0.005317712987958424, 0.00521287267834235, 0.005202027129071669, 0.005198411945981472, 0.0051586449319892145, 0.005151414565808731, 0.005151414565808731, 0.0051261082841772615, 0.005108032368726275, 0.0050971868194555955, 0.0050899564532752, 0.005075495720914322, 0.005057419805463337, 0.004974270594388446], [0.588712368028073, 0.015109064634840257, 0.014789874967088817, 0.014615771511951401, 0.014563012889182663, 0.014404737020876458, 0.014317685293308043, 0.014175237011831867, 0.014162047356139683, 0.014159409425001246, 0.014154133562724372, 0.014146219769309062, 0.014138305975893752, 0.01413039218247844, 0.014088185284263453, 0.01403278873035628, 0.014030150799217843, 0.014027512868079406, 0.014027512868079406, 0.014022237005802532, 0.014019599074664095, 0.014019599074664095, 0.014019599074664095, 0.014019599074664095, 0.014019599074664095, 0.014019599074664095, 0.014019599074664095, 0.014019599074664095, 0.014019599074664095, 0.014016961143525658], [0.49189032148069056, 0.05068771688537083, 0.02506277120317958, 0.023316646585897542, 0.02145713725320706, 0.021321075594717936, 0.021185013936227792, 0.02095824450541292, 0.020595413416106892, 0.018985350457315, 0.018980601359286454, 0.017738118587827114, 0.017035133352297758, 0.016554168449557777, 0.016377502002931782, 0.01630947117368773, 0.0157425475966475, 0.01510759319036322, 0.015016885418037473, 0.014835469873383952, 0.014467889686051406, 0.014313900182508119, 0.014223192410181358, 0.01306666831302023, 0.01261312945138947, 0.012545098622144398, 0.010164019598578084, 0.00995992711084348, 0.009801188509272462, 0.009687803793864518], [0.58903182125931, 0.1979237192507348, 0.19634394041976802, 0.0036109230422026566, 0.0029338749717896695, 0.0028210336267208086, 0.0025953509365831467, 0.0022568269013766825, 0.002143985556307822, 0.00033852403520649943], [0.5270548578263492, 0.06026662317185873, 0.0397712173109331, 0.03585733703039179, 0.027791659870602888, 0.021848529331810876, 0.021132169847224512, 0.019619855379764312, 0.017895286250203896, 0.015706844995378253, 0.013809384004784167, 0.013782852172021971, 0.013437938346109887, 0.012774642527047915, 0.011448050888924857, 0.011288859892349913, 0.011129668895775853, 0.010997009731963107, 0.010864350568151243, 0.010519436742239157, 0.010519436742239157, 0.010280650247376741, 0.010227586581851465, 0.009962268254226853, 0.009007122274778075, 0.009007122274778075, 0.008954058609253683, 0.008396890121241734, 0.008384059152938616, 0.008264230957429427], [0.9163961038961033, 0.01785714285714306, 0.008928571428571432, 0.00811688311688313, 0.007305194805194826, 0.007305194805194826, 0.006493506493506523, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129]], 'candidate_segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['Who', 'is', 'the', 'mayor', 'of', 'New', 'York', 'City', '?'], 'candidate_spans': [[1, 1], [2, 2], [4, 4], [6, 6], [6, 7], [6, 8], [7, 7], [8, 8]], 'candidate_entities': [['world_health_organization.n.01'], ['beryllium.n.01', 'be.v.10', 'be.v.08', 'exist.v.01', 'be.v.01', 'be.v.11', 'be.v.02', 'constitute.v.01', 'be.v.03', 'equal.v.01', 'embody.v.02', 'cost.v.01', 'be.v.12', 'be.v.05'], ['mayor.n.01'], ['new.s.11', 'new.s.04', 'new.s.10', 'modern.s.05', 'new.s.08', 'raw.s.12', 'new.a.01', 'fresh.s.04', 'newfangled.s.01', 'new.s.05', 'new.a.06', 'newly.r.01'], ['new_york.n.02', 'new_york.n.03', 'new_york.n.01'], ['new_york.n.01'], ['york.n.01'], ['city.n.03', 'city.n.01', 'city.n.02']], 'candidate_entity_priors': [[1.0], [5.994844433786943e-05, 0.0001798453330136083, 0.0052155146573946405, 0.04208380792518434, 0.6440261375217313, 0.00011989688867573886, 0.1810443019003657, 0.011390204424195192, 0.054073496792758226, 0.016246028415562615, 0.0035369582159342967, 5.994844433786943e-05, 5.994844433786943e-05, 0.04190396259217073], [1.0], [0.0026455026455026454, 0.015873015873015872, 0.0026455026455026454, 0.0026455026455026454, 0.0026455026455026454, 0.031746031746031744, 0.8227513227513228, 0.09788359788359788, 0.0026455026455026454, 0.010582010582010581, 0.0026455026455026454, 0.005291005291005291], [0.26153846153846155, 0.015384615384615385, 0.7230769230769231], [1.0], [1.0], [0.016666666666666666, 0.8666666666666667, 0.11666666666666667]], 'candidate_segment_ids': [0, 0, 0, 0, 0, 0, 0, 0]}}, 'offsets_a': [2, 3, 4, 5, 6, 7, 8, 9, 10], 'offsets_b': None}\n",
      "Who is the mayor of New York City ?\n",
      "['[CLS]', 'who', 'is', 'the', 'mayor', 'of', 'new', 'york', 'city', '?', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7fa03a6adec0>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 11 with text: \n",
      " \t\t[[CLS], who, is, the, mayor, of, new, york, city, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([ 101, 2040, 2003, 1996, 3664, 1997, 2047, 2259, 2103, 1029,  102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7fa03a6adec0>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7f9e901ee1c0>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e901c8ca0>}\n",
      "TextField of length 11 with text: \n",
      " \t\t[[CLS], who, is, the, mayor, of, new, york, city, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 11 with text: \n",
      " \t\t[[CLS], who, is, the, mayor, of, new, york, city, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([11]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "offsets: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "word_piece_tokens: [['which'], ['countries'], ['have'], ['places'], ['with'], ['more'], ['than'], ['two'], ['caves'], ['?']]\n",
      "tokens: ['Which', 'countries', 'have', 'places', 'with', 'more', 'than', 'two', 'caves', '?']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'which', 'countries', 'have', 'places', 'with', 'more', 'than', 'two', 'caves', '?', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['Which', 'countries', 'have', 'places', 'with', 'more', 'than', 'two', 'caves', '?'], 'candidate_spans': [[1, 1], [2, 2], [4, 4], [9, 9], [10, 10]], 'candidate_entities': [['Wilhelm_Canaris', 'Gluten-sensitive_enteropathy_associated_conditions'], ['Country', 'Communist_state', 'Eurozone', 'Brazil', 'ABC_nations', 'Dadao_government_(Shanghai_1937–40)', 'Nation', 'Countries_of_the_United_Kingdom', 'Israel', 'National_service', 'Lists_of_countries_and_territories', 'ISO_3166-1_alpha-2', 'Abortion_in_Nicaragua', 'Yugoslavia', 'Sovereignty', 'Surrogacy', 'Robert_Mugabe', 'Australia', 'Constituent_country', 'Hemp', 'Corruption_Perceptions_Index', 'Spain', 'War_in_Darfur', 'Ethiopia', 'Incitement_to_ethnic_or_racial_hatred', 'Ninja_World', 'American_exceptionalism', 'Switzerland', 'Whaling', 'Country_code_top-level_domain'], ['Lists_of_places_in_Kansas', 'Places_(Jan_Garbarek_album)', 'Places_(Béla_Fleck_album)', 'People,_Places,_Pieces', 'Places_(Casiopea_album)', 'African-American_historic_places', 'High_Places', 'Places_in_Harry_Potter', 'Nottinghamshire', 'Sites_and_places_associated_with_Arthurian_legend', 'Places_of_interest_in_Dorset', 'The_Dark_Tower_(series)', 'Places_of_interest_in_the_Death_Valley_area', \"Places_in_The_Hitchhiker's_Guide_to_the_Galaxy\", 'Location_(geography)', 'Tobias', 'Cranbourne,_Victoria', 'Bender,_Moldova', 'COPS_(1988_TV_series)', 'Satomi', 'Akiyama', 'Tappahannock,_Virginia', 'El_Cerrito,_California', 'Gustavo', 'Roman_Catholic_Archdiocese_of_Cambrai', 'Theophilus', 'Delaware,_Ohio', 'Buddhism_by_country', 'Lists_of_places', 'Roscoe'], ['Cave', 'Qumran_Caves', 'Caves_of_the_Mendip_Hills', 'Wookey_Hole_Caves', 'Caves_of_Han-sur-Lesse', 'Cave_diving', 'Batcave', 'Analogy_of_the_Cave', 'Mogao_Caves', 'Elephanta_Caves', 'Carlsbad_Caverns_National_Park', 'Near_Caves', 'Wine_cave', 'Speleology', 'Ajanta_Caves', 'Caving', 'Aggtelek_National_Park', 'Caves_of_Nerja', 'Chauvet_Cave', 'Cave_insect', 'Pertosa_Caves', 'Maya_cave_sites', 'Sea_cave', 'Glacier_cave', 'Nidderdale_Caves', 'Yagura_(tombs)'], ['Question_mark', '?_(Lost)', 'Rugby_league_positions', '?_(Neal_Morse_album)', 'Chess_annotation_symbols', \"The_Emperor's_New_School\", 'Michigan', 'Pinyin', '?_(EP)', 'Latin_alphabet', '?_(film)', 'Jyutping', 'Yale_romanization_of_Cantonese', 'January_2006_in_Malaysia_and_Singapore', 'Traditional_Chinese_characters', 'Pe̍h-ōe-jī', '?_(bistro)']], 'candidate_entity_priors': [[0.84444444444444, 0.15555555555556], [0.4070281885981535, 0.10446214132221003, 0.10338768802932652, 0.10300846922007353, 0.10294526608519804, 0.10294526608519804, 0.02275312855517642, 0.008785235747692964, 0.0054354695992919755, 0.004929844520288233, 0.0047402351156617326, 0.0041714069017823345, 0.002654531664770591, 0.0024649222601440903, 0.0020857034508911933, 0.001769687776513693, 0.001769687776513693, 0.0014536721021362442, 0.0013904689672607953, 0.0012640626975097954, 0.0012640626975097954, 0.0012008595626342954, 0.001137656427758795, 0.0010744532928833467, 0.0010744532928833467, 0.0010744532928833467, 0.0010112501580078464, 0.0009480470231323464, 0.0008848438882568465, 0.0008848438882568465], [0.22349168169973865, 0.10085521480590347, 0.09905124607469755, 0.0932384579408043, 0.0932384579408043, 0.0932384579408043, 0.0932384579408043, 0.035678492683904106, 0.025856885147324135, 0.022649829625175415, 0.021046301864101054, 0.016837041491280506, 0.011024253357386158, 0.010022048506714894, 0.007817197835237438, 0.006013229104028713, 0.004008819402685901, 0.0038083784325515925, 0.0038083784325515925, 0.0038083784325515925, 0.0036079374624172836, 0.0036079374624172836, 0.0034074964922829742, 0.0034074964922829742, 0.0032070555221487213, 0.0030066145520144124, 0.0030066145520144124, 0.0028061735818801035, 0.00260573261174585, 0.00260573261174585], [0.4547101449275345, 0.13687600644122486, 0.12650966183574985, 0.12630837359097985, 0.12510064412238486, 0.007347020933977492, 0.005535426731078994, 0.0030193236714975966, 0.002717391304347847, 0.0018115942028985481, 0.0016103059581320483, 0.0014090177133655485, 0.0013083735909822985, 0.001006441223832549, 0.000905797101449299, 0.000905797101449299, 0.0006038647342994993, 0.0006038647342994993, 0.0006038647342994993, 0.0005032206119162494, 0.00010064412238325489, 0.00010064412238325489, 0.00010064412238325489, 0.00010064412238325489, 0.00010064412238325489, 0.00010064412238325489], [0.9163961038961033, 0.01785714285714306, 0.008928571428571432, 0.00811688311688313, 0.007305194805194826, 0.007305194805194826, 0.006493506493506523, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129]], 'candidate_segment_ids': [0, 0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['Which', 'countries', 'have', 'places', 'with', 'more', 'than', 'two', 'caves', '?'], 'candidate_spans': [[2, 2], [3, 3], [4, 4], [6, 6], [6, 7], [8, 8], [9, 9]], 'candidate_entities': [['nation.n.02', 'state.n.04', 'area.n.01', 'country.n.02', 'country.n.04'], ['rich_person.n.01', 'give_birth.v.01', 'have.v.12', 'suffer.v.02', 'get.v.03', 'have.v.11', 'induce.v.02', 'consume.v.02', 'take.v.35', 'hold.v.03', 'experience.v.03', 'have.v.01', 'own.v.01', 'have.v.09', 'receive.v.01', 'accept.v.02', 'have.v.17', 'have.v.07', 'have.v.02', 'have.v.10'], ['put.v.01', 'topographic_point.n.01', 'place.n.02', 'place.n.03', 'place.n.04', 'place.v.02', 'stead.n.01', 'place.n.06', 'rate.v.01', 'home.n.01', 'position.n.06', 'place.v.05', 'locate.v.03', 'position.n.01', 'place.v.06', 'place.n.12', 'seat.n.01', 'place.n.10', 'identify.v.01', 'target.v.01', 'space.n.07', 'place.n.15', 'plaza.n.01', 'place.n.13', 'place.v.11', 'set.v.09', 'place.v.09', 'place.v.16', 'place.v.15', 'station.v.01'], ['more.a.01', 'more.a.02', 'more.r.01', 'more.r.02', 'more.n.01'], ['more.a.01'], ['two.s.01', 'deuce.n.04', 'two.n.01'], ['cave.n.01', 'cave.v.02', 'cave.v.01']], 'candidate_entity_priors': [[0.1015625, 0.5390625, 0.03125, 0.234375, 0.09375], [0.0004438526409232135, 0.001775410563692854, 0.005326231691078562, 0.002663115845539281, 0.02885042166000888, 0.01154016866400355, 0.0039946737683089215, 0.01908566355969818, 0.0013315579227696406, 0.013759431868619618, 0.09809143364403018, 0.5339547270306259, 0.06391478029294274, 0.01287172658677319, 0.003550821127385708, 0.003550821127385708, 0.001775410563692854, 0.014203284509542832, 0.1677762982689747, 0.01154016866400355], [0.3434343434343434, 0.19696969696969696, 0.09848484848484848, 0.05808080808080808, 0.045454545454545456, 0.03535353535353535, 0.025252525252525252, 0.020202020202020204, 0.020202020202020204, 0.017676767676767676, 0.012626262626262626, 0.012626262626262626, 0.012626262626262626, 0.010101010101010102, 0.010101010101010102, 0.007575757575757576, 0.007575757575757576, 0.007575757575757576, 0.007575757575757576, 0.007575757575757576, 0.005050505050505051, 0.005050505050505051, 0.005050505050505051, 0.005050505050505051, 0.005050505050505051, 0.005050505050505051, 0.005050505050505051, 0.0025252525252525255, 0.0025252525252525255, 0.0025252525252525255], [0.21986970684039087, 0.11074918566775244, 0.6107491856677525, 0.057003257328990226, 0.0016286644951140066], [1.0], [0.9356617647058824, 0.001838235294117647, 0.0625], [0.7142857142857143, 0.14285714285714285, 0.14285714285714285]], 'candidate_segment_ids': [0, 0, 0, 0, 0, 0, 0]}}, 'offsets_a': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'offsets_b': None}\n",
      "Which countries have places with more than two caves ?\n",
      "['[CLS]', 'which', 'countries', 'have', 'places', 'with', 'more', 'than', 'two', 'caves', '?', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e88fc03c0>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 12 with text: \n",
      " \t\t[[CLS], which, countries, have, places, with, more, than, two, caves, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([  101,  2029,  3032,  2031,  3182,  2007,  2062,  2084,  2048, 10614,\n",
      "         1029,   102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e88fc03c0>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7f9e90180dc0>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e7e6f34c0>}\n",
      "TextField of length 12 with text: \n",
      " \t\t[[CLS], which, countries, have, places, with, more, than, two, caves, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 12 with text: \n",
      " \t\t[[CLS], which, countries, have, places, with, more, than, two, caves, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([12]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "offsets: [1, 2, 3, 4, 5, 6]\n",
      "word_piece_tokens: [['where'], ['did'], ['abraham'], ['lincoln'], ['die'], ['?']]\n",
      "tokens: ['Where', 'did', 'Abraham', 'Lincoln', 'die', '?']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'where', 'did', 'abraham', 'lincoln', 'die', '?', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['Where', 'did', 'Abraham', 'Lincoln', 'die', '?'], 'candidate_spans': [[1, 1], [3, 3], [3, 4], [4, 4], [5, 5], [6, 6]], 'candidate_entities': [['Himeji,_Hyōgo', 'Torah', 'Where_No_Man_Has_Gone_Before', 'Where_Once_We_Walked', 'Where_I_Come_From_(album)', 'Where.com', 'Wonder_Where', 'Where_(SQL)', 'Detroit', 'Peter_Popoff', 'Arnhem', \"Galileo's_Leaning_Tower_of_Pisa_experiment\", 'The_Little_Mermaid_(1989_film)', \"I've_fallen_and_I_can't_get_up!\", 'Cheshunt', 'University_of_Kent', 'Sandy,_Bedfordshire', 'Santander,_Spain', 'Catholic_sex_abuse_cases', 'Geographic_coordinate_system', 'Where_the_Wild_Things_Are', 'Chinese_economic_stimulus_program', 'Darth_Vader', 'Give-away_shop', 'Where_the_Red_Fern_Grows', 'Idealism', 'Sun_Wukong', \"Saint_Patrick's_Day\", 'Where_Is_the_Love?', 'Joe_Arpaio'], ['Abraham', 'Abraham_in_Islam', 'Pope_Abraham_of_Alexandria', 'Abraham_Lake', 'Abraham,_West_Virginia', 'Alan_Abraham', 'Hérard_Abraham', 'Abraham_Lincoln', 'Abraham_(film)', 'John_Abraham_(American_football)', 'Spencer_Abraham', 'Abraham_González_Casanova', 'William_Abraham_(trade_unionist)', 'Winston_Abraham', 'Abraham_(name)', 'Grampa_Simpson', 'Abraham_of_Strathearn', 'Binding_of_Isaac', 'Martin_Abraham', 'Mount_Abraham_(Vermont)', 'Mount_Abraham_(Maine)', 'Abraham_Maslow', 'Esther_Hicks', 'Abraham_Gneki_Guié', 'Ralph_Abraham', 'Abraham_Mendelssohn_Bartholdy', 'Max_Abraham', 'Karel_Abraham', 'Abraham_of_Makuria', 'John_Abraham_(actor)'], ['Abraham_Lincoln', 'Abraham_Lincoln_(1930_film)', 'Abraham_Lincoln_(train)', 'USS_Abraham_Lincoln_(CVN-72)', 'Abraham_Lincoln_(captain)', 'Abraham_Lincoln_(Pullman_car)', 'Abraham_Lincoln_(French_1920)', 'Lincoln_Memorial', 'USS_Abraham_Lincoln_(SSBN-602)', 'Abraham_Lincoln_Brigade', 'Abraham_Lincoln_High_School_(Philadelphia)', 'Abraham_Lincoln_(French_1912)', 'Fort_Abraham_Lincoln', 'Abraham_Lincoln_cultural_depictions', 'Abraham_Lincoln,_Friend_of_the_People', 'Abraham_Lincoln_(Morse_books)', 'Lincoln_High_School_(Tacoma,_Washington)', 'Abraham_Lincoln_II', 'Carrier_Strike_Group_Nine', 'Abraham_Lincoln_High_School_(Brooklyn)', 'Abraham_Lincoln_in_the_Black_Hawk_War', 'Sexuality_of_Abraham_Lincoln', 'Gettysburg_Address', 'Assassination_of_Abraham_Lincoln', 'Abraham_Lincoln_(Cecere)', 'Lincoln–Douglas_debates', \"Lincoln's_House_Divided_Speech\", 'United_States_presidential_election,_1860', 'Republican_Party_(United_States)', 'Abraham_Lincoln_and_slavery'], ['Lincoln,_England', 'Abraham_Lincoln', 'Lincoln_Motor_Company', 'Lincoln,_Nebraska', 'Lincoln,_Illinois', 'Lincoln_County,_Montana', 'Lincoln,_Massachusetts', 'Lincoln,_Rhode_Island', 'Lincoln_County,_Oklahoma', 'Lincoln_County,_Kansas', 'Lincoln,_California', 'Lincoln_County,_Nevada', 'Lincoln_County,_Tennessee', 'Lincoln,_New_Hampshire', 'Lincoln_(UK_Parliament_constituency)', 'Lincoln_County,_North_Carolina', 'National_Register_of_Historic_Places_listings_in_West_Virginia', 'Lincoln_County,_Kentucky', 'Lincoln,_Pennsylvania', 'Lincoln_County,_Colorado', 'Lincoln,_Montana', 'Lincoln,_Alabama', 'Lincoln_County,_Wyoming', 'Lincoln_County,_Nebraska', 'Lincoln_County,_South_Dakota', 'Lincoln_County,_Missouri', 'Lincoln_Parish,_Louisiana', 'Lincoln_County,_Maine', 'Lincoln,_Maine', 'Lincoln_(electoral_district)'], ['Die_(manufacturing)', 'Die_(integrated_circuit)', 'Integrated_circuit', 'Coining_(mint)', 'Bill_Oddie', 'Dice', 'Death', 'Masjid_al-Haram', 'Per_\"Dead\"_Ohlin', 'Tap_and_die', 'Thunderbirds_Are_Go', 'Coining_(metalworking)', 'Rabbit_starvation', 'Galveston,_Texas', 'Death_of_Ian_Tomlinson', 'Delirium_tremens', 'Percy_Bysshe_Shelley', 'Iraq_War_troop_surge_of_2007', 'June_2011_lunar_eclipse', 'Air_New_Zealand', 'David_Icke', 'Pindar', 'CD-i_games_from_The_Legend_of_Zelda_series', 'German_grammar', 'Shalwar_kameez', 'Nintendo', 'Honor_killing', 'Hyponatremia', 'Yotsuba&!', 'Snow_Crash'], ['Question_mark', '?_(Lost)', 'Rugby_league_positions', '?_(Neal_Morse_album)', 'Chess_annotation_symbols', \"The_Emperor's_New_School\", 'Michigan', 'Pinyin', '?_(EP)', 'Latin_alphabet', '?_(film)', 'Jyutping', 'Yale_romanization_of_Cantonese', 'January_2006_in_Malaysia_and_Singapore', 'Traditional_Chinese_characters', 'Pe̍h-ōe-jī', '?_(bistro)']], 'candidate_entity_priors': [[0.13333333333333486, 0.11414141414141488, 0.0999999999999999, 0.0999999999999999, 0.0999999999999999, 0.0999999999999999, 0.0999999999999999, 0.04545454545454545, 0.03939393939393946, 0.020202020202019978, 0.014141414141413984, 0.011111111111110988, 0.00909090909090899, 0.00909090909090899, 0.00808080808080799, 0.00808080808080799, 0.00808080808080799, 0.00808080808080799, 0.00808080808080799, 0.007070707070706992, 0.007070707070706992, 0.007070707070706992, 0.006060606060605993, 0.006060606060605993, 0.0050505050505049946, 0.0050505050505049946, 0.0050505050505049946, 0.0050505050505049946, 0.0050505050505049946, 0.0050505050505049946], [0.7848134873224473, 0.0797578374450665, 0.018291447455756525, 0.012995451591942897, 0.010116889196307991, 0.006710823254871574, 0.0058689136221677, 0.005820006008649662, 0.005453198907264175, 0.004300376588624099, 0.004300376588624099, 0.004090772530689549, 0.004038371516205837, 0.003933569487238612, 0.003933569487238612, 0.0036715644148204484, 0.003619163400336737, 0.003510867970403937, 0.0034619603568858, 0.003406065941436613, 0.0033012639124693865, 0.0031475542699840237, 0.0029903512265330866, 0.0028855491975657626, 0.0028331481830821494, 0.0028331481830821494, 0.0026759451396312127, 0.002620050724182025, 0.0023615390527294356, 0.0022567370237621116], [0.5047071811677979, 0.02683075368589862, 0.026738711688157852, 0.02654440080403777, 0.026329636142642637, 0.025900106819851863, 0.025889879931213833, 0.025889879931213833, 0.0254398968311475, 0.025337627944768695, 0.025245585947027926, 0.025245585947027926, 0.025235359058389896, 0.025235359058389896, 0.025235359058389896, 0.025235359058389896, 0.025235359058389896, 0.025235359058389896, 0.025235359058389896, 0.025235359058389896, 0.0017692517343524921, 0.0015851677388706964, 0.0014113106320268315, 0.0008590586455815453, 0.0007670166478406726, 0.00048066376598015413, 0.0003374873250498949, 0.00032726043641201965, 0.00027612599322264313, 0.00020453777275751103], [0.18493280618963148, 0.12523893346580373, 0.1065235418452411, 0.09765429718989187, 0.034721222070194215, 0.027754366123527892, 0.026289012658731042, 0.02356396937331901, 0.022715606841068395, 0.021995784086431325, 0.020504722666111766, 0.01844808622429139, 0.018370962357723262, 0.01752259982547265, 0.017316936181290977, 0.017239812314722852, 0.01712149837815344, 0.017085564581585378, 0.016931316848449122, 0.016879900937403707, 0.016442865693517654, 0.01631432591590289, 0.016134370227243927, 0.01608295431619851, 0.014977512228720803, 0.014694724717969785, 0.014360521296174569, 0.01433481334065186, 0.014231981518561023, 0.01361499058601479], [0.2551850718874254, 0.2060365045375734, 0.10529213826858419, 0.10243703477108299, 0.10202916284286707, 0.09258692770470153, 0.06179259712450453, 0.020393596410726886, 0.008157438564290754, 0.006016110941164597, 0.005608239012949702, 0.004996431120628125, 0.003568879371877218, 0.003059039461609058, 0.002447231569287226, 0.0020393596410726886, 0.0019373916590190669, 0.0017334556949117725, 0.0017334556949117725, 0.001631487712858151, 0.001223615784643613, 0.001223615784643613, 0.001223615784643613, 0.001223615784643613, 0.001223615784643613, 0.0011216478025899914, 0.0011216478025899914, 0.0010196798205363699, 0.0010196798205363699, 0.0009177118384826971], [0.9163961038961033, 0.01785714285714306, 0.008928571428571432, 0.00811688311688313, 0.007305194805194826, 0.007305194805194826, 0.006493506493506523, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129]], 'candidate_segment_ids': [0, 0, 0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['Where', 'did', 'Abraham', 'Lincoln', 'die', '?'], 'candidate_spans': [[2, 2], [3, 3], [3, 4], [4, 4], [5, 5]], 'candidate_entities': [['doctor_of_osteopathy.n.01', 'do.n.02', 'bash.n.02', 'act.v.02', 'dress.v.16', 'do.v.08', 'cause.v.01', 'perform.v.01', 'do.v.13', 'do.v.11', 'make.v.01', 'do.v.03', 'practice.v.01', 'do.v.04', 'suffice.v.01', 'serve.v.09'], ['abraham.n.01'], ['lincoln.n.01'], ['lincoln.n.03', 'lincoln.n.02', 'lincoln.n.01'], ['die.n.01', 'die.n.02', 'die.n.03', 'die.v.11', 'die.v.10', 'die.v.01', 'fail.v.04', 'die.v.09', 'die.v.08', 'die.v.07', 'die.v.03', 'die.v.06', 'die.v.05', 'die.v.02']], 'candidate_entity_priors': [[0.0010080645161290322, 0.0010080645161290322, 0.0010080645161290322, 0.004032258064516129, 0.0030241935483870967, 0.010080645161290322, 0.036290322580645164, 0.17540322580645162, 0.0020161290322580645, 0.0030241935483870967, 0.53125, 0.13608870967741934, 0.021169354838709676, 0.059475806451612906, 0.012096774193548387, 0.0030241935483870967], [1.0], [1.0], [0.25, 0.25, 0.5], [0.04242424242424243, 0.012121212121212121, 0.006060606060606061, 0.006060606060606061, 0.006060606060606061, 0.8606060606060606, 0.012121212121212121, 0.006060606060606061, 0.006060606060606061, 0.006060606060606061, 0.012121212121212121, 0.006060606060606061, 0.006060606060606061, 0.012121212121212121]], 'candidate_segment_ids': [0, 0, 0, 0, 0]}}, 'offsets_a': [2, 3, 4, 5, 6, 7], 'offsets_b': None}\n",
      "Where did Abraham Lincoln die ?\n",
      "['[CLS]', 'where', 'did', 'abraham', 'lincoln', 'die', '?', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7fa03a6add80>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 8 with text: \n",
      " \t\t[[CLS], where, did, abraham, lincoln, die, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([ 101, 2073, 2106, 8181, 5367, 3280, 1029,  102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7fa03a6add80>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7fa0448b60d0>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e7e6f3cd0>}\n",
      "TextField of length 8 with text: \n",
      " \t\t[[CLS], where, did, abraham, lincoln, die, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 8 with text: \n",
      " \t\t[[CLS], where, did, abraham, lincoln, die, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([8]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "offsets: [1, 2, 3, 4, 5, 6, 7]\n",
      "word_piece_tokens: [['which'], ['airports'], ['does'], ['air'], ['china'], ['serve'], ['?']]\n",
      "tokens: ['Which', 'airports', 'does', 'Air', 'China', 'serve', '?']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'which', 'airports', 'does', 'air', 'china', 'serve', '?', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['Which', 'airports', 'does', 'Air', 'China', 'serve', '?'], 'candidate_spans': [[1, 1], [2, 2], [4, 4], [4, 5], [5, 5], [6, 6], [7, 7]], 'candidate_entities': [['Wilhelm_Canaris', 'Gluten-sensitive_enteropathy_associated_conditions'], ['Airport', 'Adnan_Menderes_Airport', 'Larry_Craig', 'Airport_security', 'Rome_and_Vienna_airport_attacks', 'Kobe_Airport', 'Ronald_Reagan_Washington_National_Airport', \"World's_busiest_airports_by_aircraft_movements\", 'LaGuardia_Airport', 'Logan_International_Airport', 'Airport_novel', 'Airport_bus', 'Long_Island_MacArthur_Airport', 'Detroit_Metropolitan_Wayne_County_Airport', 'International_airport'], ['Air_(visual_novel)', 'Air_(classical_element)', 'Air_(music)', 'Aerial_warfare', 'Air_(novel)', 'MacBook_Air', 'Air_(roller_coaster)', 'Air_(free_jazz_trio)', 'Air_(comics)', 'Air_(film)', 'Air_(Stargate_Universe)', 'Atmosphere_of_Earth', 'Air_(Japanese_band)', 'Air_(1977_video_game)', 'Railway_air_brake', 'Air-cooled_engine', 'Air_(Cecil_Taylor_album)', 'Michael_Jordan', 'Air_Force_Amy', 'Giulio_Douhet', 'Air_Attack_(video_game)', 'Air_Pirates', 'Air_Zonk', 'Air_Transport_Auxiliary', 'Don_Coryell', 'Lee_Payne_(bassist)', 'Air_Buster', 'Air_commodore', 'Ethiopian_Air_Force', 'Air_Fortress'], ['Air_China'], ['China', 'China_national_football_team', 'Taiwan', 'Second_Sino-Japanese_War', 'China_at_the_2008_Summer_Olympics', 'Qing_Dynasty', 'China,_Texas', \"People's_Liberation_Army\", \"China_women's_national_football_team\", 'China_national_badminton_team', 'Cinema_of_China', 'History_of_China', 'China_national_cricket_team', 'China_at_the_2004_Summer_Olympics', 'China_at_the_Olympics', 'Chinese_rock', 'Mainland_China', 'A1_Team_China', 'China,_Maine', \"China_women's_national_basketball_team\", 'China_at_the_2010_Winter_Olympics', \"China_women's_national_volleyball_team\", 'China_national_baseball_team', 'China_at_the_2008_Summer_Paralympics', 'China_at_the_2000_Summer_Olympics', \"People's_Bank_of_China\", \"China_men's_national_ice_hockey_team\", 'China_at_the_1992_Summer_Olympics', 'China_(Epcot)', 'China_Baseball_League'], ['Serve_(tennis)', 'Service_of_process', 'United_States_Postal_Service', 'Public_service', 'Domestic_worker', 'Works_of_mercy', 'Military_service', 'Civil_service', 'Server_(computing)', 'Summons', 'Service_of_process_in_Virginia', 'Web_server'], ['Question_mark', '?_(Lost)', 'Rugby_league_positions', '?_(Neal_Morse_album)', 'Chess_annotation_symbols', \"The_Emperor's_New_School\", 'Michigan', 'Pinyin', '?_(EP)', 'Latin_alphabet', '?_(film)', 'Jyutping', 'Yale_romanization_of_Cantonese', 'January_2006_in_Malaysia_and_Singapore', 'Traditional_Chinese_characters', 'Pe̍h-ōe-jī', '?_(bistro)']], 'candidate_entity_priors': [[0.84444444444444, 0.15555555555556], [0.9482636428065195, 0.014410583510512992, 0.008977084809827496, 0.008977084809827496, 0.006142215922513597, 0.005905976848570797, 0.0021261516654854993, 0.0016536735175997994, 0.0011811953697141995, 0.0011811953697141995, 0.0002362390739428299, 0.0002362390739428299, 0.0002362390739428299, 0.0002362390739428299, 0.0002362390739428299], [0.13787489420636073, 0.0838624297914907, 0.04561360313918569, 0.04401015618988943, 0.04073247672539818, 0.03857197814880328, 0.03841194121720427, 0.03521120258521227, 0.03241055628221898, 0.029689928445025188, 0.02832961452642888, 0.02664922674463337, 0.02664922674463337, 0.02544894975763608, 0.024808802031237677, 0.024248672770638784, 0.024088635839039772, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276], [1.0], [0.7867279459025556, 0.014421681978380927, 0.011689092318318389, 0.01057875245644538, 0.007965127781583654, 0.00753973783450268, 0.00735227785782296, 0.0073450678587198455, 0.007283782866343775, 0.007161212881591637, 0.007020617899081847, 0.0069468341358055515, 0.006876417917020453, 0.006861997918814314, 0.00685478791971129, 0.006847577920608174, 0.00684036792150515, 0.006825947923299012, 0.006634882947067688, 0.006548362957830943, 0.006537547959176316, 0.0064618429685941075, 0.006440212971284944, 0.006422187973527201, 0.006386137978011898, 0.006332062984738852, 0.00631043298742969, 0.006267172992811271, 0.006263567993259759, 0.006256357994156644], [0.5379959650302623, 0.16139878950907866, 0.140551445864156, 0.13449899125756556, 0.00605245460659045, 0.00605245460659045, 0.0040349697377269666, 0.0040349697377269666, 0.0033624747814391394, 0.0006724949562878278, 0.0006724949562878278, 0.0006724949562878278], [0.9163961038961033, 0.01785714285714306, 0.008928571428571432, 0.00811688311688313, 0.007305194805194826, 0.007305194805194826, 0.006493506493506523, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129]], 'candidate_segment_ids': [0, 0, 0, 0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['Which', 'airports', 'does', 'Air', 'China', 'serve', '?'], 'candidate_spans': [[2, 2], [3, 3], [4, 4], [5, 5], [6, 6]], 'candidate_entities': [['airport.n.01'], ['doctor_of_osteopathy.n.01', 'do.n.02', 'bash.n.02', 'act.v.02', 'dress.v.16', 'do.v.08', 'cause.v.01', 'perform.v.01', 'do.v.13', 'do.v.11', 'make.v.01', 'do.v.03', 'practice.v.01', 'do.v.04', 'suffice.v.01', 'serve.v.09'], ['air_travel.n.01', 'air.n.03', 'air.n.08', 'tune.n.01', 'atmosphere.n.03', 'air.n.02', 'breeze.n.01', 'air.n.01', 'air.n.06', 'vent.v.02', 'air.v.05', 'publicize.v.01', 'air.v.03', 'air.v.02', 'air_out.v.01'], ['china.n.02', 'chinaware.n.01', 'china.n.01', 'taiwan.n.01'], ['serve.n.01', 'serve.v.15', 'serve.v.02', 'serve.v.06', 'serve.v.05', 'serve.v.14', 'serve.v.11', 'serve.v.13', 'serve.v.10', 'service.v.01', 'serve.v.07', 'suffice.v.01', 'serve.v.03', 'serve.v.08', 'serve.v.01', 'serve.v.09']], 'candidate_entity_priors': [[1.0], [0.0010080645161290322, 0.0010080645161290322, 0.0010080645161290322, 0.004032258064516129, 0.0030241935483870967, 0.010080645161290322, 0.036290322580645164, 0.17540322580645162, 0.0020161290322580645, 0.0030241935483870967, 0.53125, 0.13608870967741934, 0.021169354838709676, 0.059475806451612906, 0.012096774193548387, 0.0030241935483870967], [0.01, 0.1, 0.01, 0.01, 0.02, 0.3, 0.04, 0.43, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.02], [0.38461538461538464, 0.07692307692307693, 0.46153846153846156, 0.07692307692307693], [0.004347826086956522, 0.004347826086956522, 0.1608695652173913, 0.09130434782608696, 0.09565217391304348, 0.004347826086956522, 0.017391304347826087, 0.004347826086956522, 0.017391304347826087, 0.10434782608695652, 0.08695652173913043, 0.004347826086956522, 0.10869565217391304, 0.034782608695652174, 0.24347826086956523, 0.017391304347826087]], 'candidate_segment_ids': [0, 0, 0, 0, 0]}}, 'offsets_a': [2, 3, 4, 5, 6, 7, 8], 'offsets_b': None}\n",
      "Which airports does Air China serve ?\n",
      "['[CLS]', 'which', 'airports', 'does', 'air', 'china', 'serve', '?', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e7e511080>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 9 with text: \n",
      " \t\t[[CLS], which, airports, does, air, china, serve, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([  101,  2029, 13586,  2515,  2250,  2859,  3710,  1029,   102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e7e511080>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7f9e8ff43880>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e8ff436d0>}\n",
      "TextField of length 9 with text: \n",
      " \t\t[[CLS], which, airports, does, air, china, serve, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 9 with text: \n",
      " \t\t[[CLS], which, airports, does, air, china, serve, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([9]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)\n",
      "{'tokens': {'tokens': tensor([[  101,  2862,  2035,  2604, 26393,  2011, 13938,  2102,  1012,   102,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2040,  2764,  3712,  5051,  1029,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2029,  2111,  2020,  2141,  1999,  2014,  4817, 18964,  1029,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  1999,  2029,  1057,  1012,  1055,  1012,  2110,  2003,  2181,\n",
      "          4868,  2284,  1029,   102],\n",
      "        [  101,  2040,  2003,  1996,  3664,  1997,  2047,  2259,  2103,  1029,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  2029,  3032,  2031,  3182,  2007,  2062,  2084,  2048, 10614,\n",
      "          1029,   102,     0,     0],\n",
      "        [  101,  2073,  2106,  8181,  5367,  3280,  1029,   102,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2029, 13586,  2515,  2250,  2859,  3710,  1029,   102,     0,\n",
      "             0,     0,     0,     0]])}, 'segment_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'candidates': {'wiki': {'candidate_entity_priors': tensor([[[1.0823e-01, 6.4316e-02, 4.2703e-02,  ..., 2.6648e-02,\n",
      "          2.6648e-02, 2.6648e-02],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [5.2199e-01, 5.4423e-02, 5.2931e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[2.7127e-01, 1.0635e-01, 8.4808e-02,  ..., 3.6923e-03,\n",
      "          3.6923e-03, 3.3846e-03],\n",
      "         [1.8887e-01, 1.6703e-01, 8.0026e-02,  ..., 2.7741e-03,\n",
      "          2.6971e-03, 2.5430e-03],\n",
      "         [6.5703e-01, 3.2965e-01, 8.0717e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[8.4444e-01, 1.5556e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.1796e-01, 5.3777e-02, 3.0802e-02,  ..., 2.1226e-02,\n",
      "          9.6297e-03, 7.2562e-03],\n",
      "         [7.0251e-01, 1.5931e-02, 1.4717e-02,  ..., 9.7139e-03,\n",
      "          9.7139e-03, 9.6654e-03],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[8.4444e-01, 1.5556e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [4.0703e-01, 1.0446e-01, 1.0339e-01,  ..., 9.4805e-04,\n",
      "          8.8484e-04, 8.8484e-04],\n",
      "         [2.2349e-01, 1.0086e-01, 9.9051e-02,  ..., 2.8062e-03,\n",
      "          2.6057e-03, 2.6057e-03],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.3333e-01, 1.1414e-01, 1.0000e-01,  ..., 5.0505e-03,\n",
      "          5.0505e-03, 5.0505e-03],\n",
      "         [7.8481e-01, 7.9758e-02, 1.8291e-02,  ..., 2.6201e-03,\n",
      "          2.3615e-03, 2.2567e-03],\n",
      "         [5.0471e-01, 2.6831e-02, 2.6739e-02,  ..., 3.2726e-04,\n",
      "          2.7613e-04, 2.0454e-04],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[8.4444e-01, 1.5556e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [9.4826e-01, 1.4411e-02, 8.9771e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.3787e-01, 8.3862e-02, 4.5614e-02,  ..., 2.2568e-02,\n",
      "          2.2568e-02, 2.2568e-02],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]]), 'candidate_entities': {'ids': tensor([[[184845, 145312, 437595,  ..., 295929, 260022,  13536],\n",
      "         [212329,      0,      0,  ...,      0,      0,      0],\n",
      "         [224175, 436989, 260228,  ...,      0,      0,      0],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[ 53720, 226298, 468574,  ..., 422535, 437179,  17870],\n",
      "         [463935,  13060, 142421,  ..., 431870, 162728, 457156],\n",
      "         [222373,  79308, 368272,  ...,      0,      0,      0],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[397844, 292749,      0,  ...,      0,      0,      0],\n",
      "         [191092, 379501,  18700,  ..., 395964, 131562, 216689],\n",
      "         [203057,  51328, 117464,  ..., 331303, 389967, 144977],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[397844, 292749,      0,  ...,      0,      0,      0],\n",
      "         [180714,  34518, 365532,  ..., 268304,  57654,  82790],\n",
      "         [250672, 447330, 243182,  ..., 228556,  14420, 413021],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[362417, 235345,  41805,  ...,  40643,  51518, 382851],\n",
      "         [410770, 231636,  13620,  ..., 321163, 345244, 351034],\n",
      "         [222932, 316497, 117282,  ..., 131406, 455905, 335828],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[397844, 292749,      0,  ...,      0,      0,      0],\n",
      "         [  7271, 105620,  57907,  ...,      0,      0,      0],\n",
      "         [325198,  61398, 376909,  ..., 153924, 133085, 438218],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]]])}, 'candidate_spans': tensor([[[ 1,  1],\n",
      "         [ 3,  4],\n",
      "         [ 6,  7],\n",
      "         [ 8,  8],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 3,  4],\n",
      "         [ 5,  5],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 4,  4],\n",
      "         [ 6,  8],\n",
      "         [ 9,  9],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5],\n",
      "         [ 6,  6],\n",
      "         [ 7,  7],\n",
      "         [ 9,  9],\n",
      "         [ 9, 10],\n",
      "         [10, 10],\n",
      "         [11, 11],\n",
      "         [12, 12]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 4,  4],\n",
      "         [ 4,  7],\n",
      "         [ 4,  8],\n",
      "         [ 6,  6],\n",
      "         [ 6,  7],\n",
      "         [ 6,  8],\n",
      "         [ 7,  7],\n",
      "         [ 7,  8],\n",
      "         [ 8,  8],\n",
      "         [ 9,  9]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 4,  4],\n",
      "         [ 9,  9],\n",
      "         [10, 10],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 3,  3],\n",
      "         [ 3,  4],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5],\n",
      "         [ 6,  6],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 4,  4],\n",
      "         [ 4,  5],\n",
      "         [ 5,  5],\n",
      "         [ 6,  6],\n",
      "         [ 7,  7],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]]]), 'candidate_segment_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}, 'wordnet': {'candidate_entity_priors': tensor([[[1.7544e-02, 5.7018e-01, 2.1053e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.4337e-02, 8.8889e-01, 9.6774e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.5000e-01, 7.5000e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [8.9686e-02, 5.8296e-02, 4.4843e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[8.7162e-01, 1.3514e-02, 9.7973e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [5.9948e-05, 1.7985e-04, 5.2155e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.0202e-02, 1.0101e-02, 2.0202e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0156e-01, 5.3906e-01, 3.1250e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [4.4385e-04, 1.7754e-03, 5.3262e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.4343e-01, 1.9697e-01, 9.8485e-02,  ..., 2.5253e-03,\n",
      "          2.5253e-03, 2.5253e-03],\n",
      "         ...,\n",
      "         [9.3566e-01, 1.8382e-03, 6.2500e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.1429e-01, 1.4286e-01, 1.4286e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.0081e-03, 1.0081e-03, 1.0081e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0081e-03, 1.0081e-03, 1.0081e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e-02, 1.0000e-01, 1.0000e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]]), 'candidate_entities': {'ids': tensor([[[ 49863,  56747, 108447,  ...,      0,      0,      0],\n",
      "         [  2925,  12562,  18198,  ...,      0,      0,      0],\n",
      "         [ 19751,  21009,      0,  ...,      0,      0,      0],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[ 67002,      0,      0,  ...,      0,      0,      0],\n",
      "         [104359, 104685, 105005,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[ 65293,  65436,  66268,  ...,      0,      0,      0],\n",
      "         [100139, 115193, 116069,  ...,      0,      0,      0],\n",
      "         [ 32892,  74736, 104125,  ...,      0,      0,      0],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 66300,  66313,  67944,  ...,      0,      0,      0],\n",
      "         [ 78805, 104174, 104219,  ...,      0,      0,      0],\n",
      "         [111313,  68735,  68021,  ..., 108936, 109141, 109154],\n",
      "         ...,\n",
      "         [ 12008,  39063,  95331,  ...,      0,      0,      0],\n",
      "         [ 71414, 107098, 110198,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[ 57960,  58811,  62085,  ...,      0,      0,      0],\n",
      "         [ 80475,      0,      0,  ...,      0,      0,      0],\n",
      "         [ 82206,      0,      0,  ...,      0,      0,      0],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[ 36137,      0,      0,  ...,      0,      0,      0],\n",
      "         [ 57960,  58811,  62085,  ...,      0,      0,      0],\n",
      "         [ 23215,  48108,  55610,  ...,      0,      0,      0],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]]])}, 'candidate_spans': tensor([[[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 5,  5],\n",
      "         [ 6,  7],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 3,  3],\n",
      "         [ 5,  5],\n",
      "         [ 7,  7],\n",
      "         [ 8,  8],\n",
      "         [ 9,  9],\n",
      "         [10, 10],\n",
      "         [11, 11]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 4,  4],\n",
      "         [ 6,  6],\n",
      "         [ 6,  7],\n",
      "         [ 6,  8],\n",
      "         [ 7,  7],\n",
      "         [ 8,  8]],\n",
      "\n",
      "        [[ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 6,  6],\n",
      "         [ 6,  7],\n",
      "         [ 8,  8],\n",
      "         [ 9,  9],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 3,  4],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5],\n",
      "         [ 6,  6],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]]]), 'candidate_segment_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0]])}}}\n",
      "tensor([[  101,  2862,  2035,  2604, 26393,  2011, 13938,  2102,  1012,   102,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2040,  2764,  3712,  5051,  1029,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2029,  2111,  2020,  2141,  1999,  2014,  4817, 18964,  1029,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  1999,  2029,  1057,  1012,  1055,  1012,  2110,  2003,  2181,\n",
      "          4868,  2284,  1029,   102],\n",
      "        [  101,  2040,  2003,  1996,  3664,  1997,  2047,  2259,  2103,  1029,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  2029,  3032,  2031,  3182,  2007,  2062,  2084,  2048, 10614,\n",
      "          1029,   102,     0,     0],\n",
      "        [  101,  2073,  2106,  8181,  5367,  3280,  1029,   102,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2029, 13586,  2515,  2250,  2859,  3710,  1029,   102,     0,\n",
      "             0,     0,     0,     0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[  101,  2862,  2035,  2604, 26393,  2011, 13938,  2102,  1012,   102,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2040,  2764,  3712,  5051,  1029,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2029,  2111,  2020,  2141,  1999,  2014,  4817, 18964,  1029,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  1999,  2029,  1057,  1012,  1055,  1012,  2110,  2003,  2181,\n",
      "          4868,  2284,  1029,   102],\n",
      "        [  101,  2040,  2003,  1996,  3664,  1997,  2047,  2259,  2103,  1029,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  2029,  3032,  2031,  3182,  2007,  2062,  2084,  2048, 10614,\n",
      "          1029,   102,     0,     0],\n",
      "        [  101,  2073,  2106,  8181,  5367,  3280,  1029,   102,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2029, 13586,  2515,  2250,  2859,  3710,  1029,   102,     0,\n",
      "             0,     0,     0,     0]])\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False, False, False, False]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "batch = batcher.iter_batches([train_example.source for train_example in train_examples])\n",
    "source_fields = next(batch)\n",
    "\n",
    "source_fields['tokens']['tokens'] = source_fields['tokens']['tokens']['tokens']\n",
    "source_fields['candidates']['wiki']['candidate_entities']['ids'] = \\\n",
    "    source_fields['candidates']['wiki']['candidate_entities']['ids']['token_characters']\n",
    "\n",
    "candidate_mask = (source_fields['candidates']['wiki']['candidate_entities']['ids'] > 0).type(torch.uint8)\n",
    "source_fields['candidates']['wiki']['candidate_entities']['ids'] -= candidate_mask\n",
    "print(candidate_mask)\n",
    "\n",
    "source_fields['candidates']['wordnet']['candidate_entities']['ids'] = \\\n",
    "    source_fields['candidates']['wordnet']['candidate_entities']['ids']['token_characters']\n",
    "\n",
    "candidate_mask = (source_fields['candidates']['wordnet']['candidate_entities']['ids'] > 0).type(torch.uint8)\n",
    "source_fields['candidates']['wordnet']['candidate_entities']['ids'] -= candidate_mask\n",
    "\n",
    "print(source_fields)\n",
    "all_source_ids = source_fields['tokens']['tokens']\n",
    "all_source_segment_ids = source_fields['segment_ids']\n",
    "print(all_source_ids)\n",
    "print(all_source_segment_ids)\n",
    "max_source_length = 32\n",
    "padding_length = max(max_source_length - len(all_source_ids[0]), 0)\n",
    "num_examples = len(all_source_ids)\n",
    "if padding_length > 0:\n",
    "    source_ids = torch.cat((all_source_ids, torch.full((num_examples,padding_length), fill_value=tokenizer_uncased.pad_token_id)), dim=1)\n",
    "    source_segment_ids = torch.cat((all_source_segment_ids, torch.full((num_examples,padding_length), fill_value=0)), dim=1)\n",
    "source_candidates = source_fields['candidates']\n",
    "all_source_mask = all_source_ids > 0\n",
    "\n",
    "print(all_source_ids)\n",
    "print(all_source_mask)\n",
    "print(all_source_segment_ids)\n",
    "\n",
    "all_source_wiki_candidate_priors = source_fields['candidates']['wiki']['candidate_entity_priors']\n",
    "all_source_wiki_candidate_ids = source_fields['candidates']['wiki']['candidate_entities']['ids']\n",
    "all_source_wiki_candidate_spans = source_fields['candidates']['wiki']['candidate_spans']\n",
    "all_source_wiki_candidate_segment_ids = source_fields['candidates']['wiki']['candidate_segment_ids']\n",
    "\n",
    "all_source_wordnet_candidate_priors = source_fields['candidates']['wordnet']['candidate_entity_priors']\n",
    "all_source_wordnet_candidate_ids = source_fields['candidates']['wordnet']['candidate_entities']['ids']\n",
    "all_source_wordnet_candidate_spans = source_fields['candidates']['wordnet']['candidate_spans']\n",
    "all_source_wordnet_candidate_segment_ids = source_fields['candidates']['wordnet']['candidate_segment_ids']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_triples_ids = torch.tensor(\n",
    "    [f.triples_ids for f in train_features], dtype=torch.long\n",
    ")\n",
    "all_triples_mask = torch.tensor(\n",
    "    [f.triples_mask for f in train_features], dtype=torch.long\n",
    ")\n",
    "all_target_ids = torch.tensor(\n",
    "    [f.target_ids for f in train_features], dtype=torch.long\n",
    ")\n",
    "all_target_mask = torch.tensor(\n",
    "    [f.target_mask for f in train_features], dtype=torch.long\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "train_data = TensorDataset(\n",
    "    all_source_ids,\n",
    "    all_source_mask,\n",
    "    all_source_wiki_candidate_priors,\n",
    "    all_source_wiki_candidate_ids,\n",
    "    all_source_wiki_candidate_spans,\n",
    "    all_source_wiki_candidate_segment_ids,\n",
    "    all_source_wordnet_candidate_priors,\n",
    "    all_source_wordnet_candidate_ids,\n",
    "    all_source_wordnet_candidate_spans,\n",
    "    all_source_wordnet_candidate_segment_ids,\n",
    "    all_triples_ids,\n",
    "    all_triples_mask,\n",
    "    all_target_ids,\n",
    "    all_target_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "06/07/2022 07:55:51 - INFO - __main__ -   ***** Running training *****\n",
      "06/07/2022 07:55:51 - INFO - __main__ -     Num examples = 8\n",
      "06/07/2022 07:55:51 - INFO - __main__ -     Batch size = 2\n",
      "06/07/2022 07:55:51 - INFO - __main__ -     Num epoch = 2\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=2 // 1\n",
    ")\n",
    "\n",
    "num_train_optimization_steps = -1\n",
    "\n",
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p\n",
    "            for n, p in model.named_parameters()\n",
    "            if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.01,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p\n",
    "            for n, p in model.named_parameters()\n",
    "            if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "t_total = (\n",
    "    len(train_dataloader)\n",
    "    // 1\n",
    "    * 2\n",
    ")\n",
    "optimizer = AdamW(\n",
    "    optimizer_grouped_parameters, lr=5e-5, eps=1e-8\n",
    ")\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=int(t_total * 0.1), num_training_steps=t_total\n",
    ")\n",
    "\n",
    "# Start training\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "logger.info(\"  Batch size = %d\", 2)\n",
    "logger.info(\"  Num epoch = %d\", 2)\n",
    "\n",
    "model.train()\n",
    "dev_dataset = {}\n",
    "nb_tr_examples, nb_tr_steps, tr_loss, global_step, best_bleu, best_loss = (\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    -1,\n",
    "    1e6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In forward\n",
      "tokens tensor([[  101,  2029, 13586,  2515,  2250,  2859,  3710,  1029,   102,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2040,  2003,  1996,  3664,  1997,  2047,  2259,  2103,  1029,\n",
      "           102,     0,     0,     0]], device='cuda:0')\n",
      "candidates {'wiki': {'candidate_entity_priors': tensor([[[8.4444e-01, 1.5556e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [9.4826e-01, 1.4411e-02, 8.9771e-03, 8.9771e-03, 6.1422e-03,\n",
      "          5.9060e-03, 2.1262e-03, 1.6537e-03, 1.1812e-03, 1.1812e-03,\n",
      "          2.3624e-04, 2.3624e-04, 2.3624e-04, 2.3624e-04, 2.3624e-04,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.3787e-01, 8.3862e-02, 4.5614e-02, 4.4010e-02, 4.0732e-02,\n",
      "          3.8572e-02, 3.8412e-02, 3.5211e-02, 3.2411e-02, 2.9690e-02,\n",
      "          2.8330e-02, 2.6649e-02, 2.6649e-02, 2.5449e-02, 2.4809e-02,\n",
      "          2.4249e-02, 2.4089e-02, 2.2568e-02, 2.2568e-02, 2.2568e-02,\n",
      "          2.2568e-02, 2.2568e-02, 2.2568e-02, 2.2568e-02, 2.2568e-02,\n",
      "          2.2568e-02, 2.2568e-02, 2.2568e-02, 2.2568e-02, 2.2568e-02],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [7.8673e-01, 1.4422e-02, 1.1689e-02, 1.0579e-02, 7.9651e-03,\n",
      "          7.5397e-03, 7.3523e-03, 7.3451e-03, 7.2838e-03, 7.1612e-03,\n",
      "          7.0206e-03, 6.9468e-03, 6.8764e-03, 6.8620e-03, 6.8548e-03,\n",
      "          6.8476e-03, 6.8404e-03, 6.8259e-03, 6.6349e-03, 6.5484e-03,\n",
      "          6.5375e-03, 6.4618e-03, 6.4402e-03, 6.4222e-03, 6.3861e-03,\n",
      "          6.3321e-03, 6.3104e-03, 6.2672e-03, 6.2636e-03, 6.2564e-03],\n",
      "         [5.3800e-01, 1.6140e-01, 1.4055e-01, 1.3450e-01, 6.0525e-03,\n",
      "          6.0525e-03, 4.0350e-03, 4.0350e-03, 3.3625e-03, 6.7249e-04,\n",
      "          6.7249e-04, 6.7249e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [9.1640e-01, 1.7857e-02, 8.9286e-03, 8.1169e-03, 7.3052e-03,\n",
      "          7.3052e-03, 6.4935e-03, 5.6818e-03, 5.6818e-03, 5.6818e-03,\n",
      "          5.6818e-03, 8.1169e-04, 8.1169e-04, 8.1169e-04, 8.1169e-04,\n",
      "          8.1169e-04, 8.1169e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[2.7127e-01, 1.0635e-01, 8.4808e-02, 3.8038e-02, 3.3423e-02,\n",
      "          3.3423e-02, 3.3115e-02, 3.3115e-02, 3.3115e-02, 3.3115e-02,\n",
      "          3.3115e-02, 3.3115e-02, 3.3115e-02, 3.3115e-02, 3.3115e-02,\n",
      "          3.3115e-02, 2.0000e-02, 1.4769e-02, 1.1692e-02, 8.3077e-03,\n",
      "          7.6923e-03, 6.7692e-03, 4.9231e-03, 4.6154e-03, 4.0000e-03,\n",
      "          4.0000e-03, 4.0000e-03, 3.6923e-03, 3.6923e-03, 3.3846e-03],\n",
      "         [5.1838e-01, 4.9697e-02, 3.9560e-02, 2.5619e-02, 2.4972e-02,\n",
      "          1.6875e-02, 1.6796e-02, 1.6443e-02, 1.4777e-02, 1.4541e-02,\n",
      "          1.3679e-02, 1.3639e-02, 1.3502e-02, 1.3483e-02, 1.3424e-02,\n",
      "          1.3345e-02, 1.3345e-02, 1.3286e-02, 1.3090e-02, 1.3071e-02,\n",
      "          1.3032e-02, 1.2894e-02, 1.2894e-02, 1.2855e-02, 1.2816e-02,\n",
      "          1.2816e-02, 1.2816e-02, 1.2796e-02, 1.2777e-02, 1.2777e-02],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [9.4256e-02, 8.7523e-02, 8.3263e-02, 6.2577e-02, 5.3275e-02,\n",
      "          4.7958e-02, 4.4818e-02, 3.9533e-02, 3.7842e-02, 3.7208e-02,\n",
      "          3.6330e-02, 3.4882e-02, 3.3614e-02, 2.6606e-02, 2.5792e-02,\n",
      "          2.4069e-02, 2.3466e-02, 2.3043e-02, 2.1141e-02, 1.8815e-02,\n",
      "          1.6881e-02, 1.6278e-02, 1.5824e-02, 1.5433e-02, 1.5221e-02,\n",
      "          1.5190e-02, 1.2684e-02, 1.2441e-02, 1.2230e-02, 1.1807e-02],\n",
      "         [6.7406e-01, 1.5014e-01, 1.7392e-02, 8.6148e-03, 8.5895e-03,\n",
      "          8.1086e-03, 7.7218e-03, 7.5700e-03, 6.8867e-03, 5.9757e-03,\n",
      "          5.7696e-03, 5.6575e-03, 5.5419e-03, 5.3719e-03, 5.3539e-03,\n",
      "          5.3249e-03, 5.3177e-03, 5.2129e-03, 5.2020e-03, 5.1984e-03,\n",
      "          5.1586e-03, 5.1514e-03, 5.1514e-03, 5.1261e-03, 5.1080e-03,\n",
      "          5.0972e-03, 5.0900e-03, 5.0755e-03, 5.0574e-03, 4.9743e-03],\n",
      "         [5.8871e-01, 1.5109e-02, 1.4790e-02, 1.4616e-02, 1.4563e-02,\n",
      "          1.4405e-02, 1.4318e-02, 1.4175e-02, 1.4162e-02, 1.4159e-02,\n",
      "          1.4154e-02, 1.4146e-02, 1.4138e-02, 1.4130e-02, 1.4088e-02,\n",
      "          1.4033e-02, 1.4030e-02, 1.4028e-02, 1.4028e-02, 1.4022e-02,\n",
      "          1.4020e-02, 1.4020e-02, 1.4020e-02, 1.4020e-02, 1.4020e-02,\n",
      "          1.4020e-02, 1.4020e-02, 1.4020e-02, 1.4020e-02, 1.4017e-02],\n",
      "         [4.9189e-01, 5.0688e-02, 2.5063e-02, 2.3317e-02, 2.1457e-02,\n",
      "          2.1321e-02, 2.1185e-02, 2.0958e-02, 2.0595e-02, 1.8985e-02,\n",
      "          1.8981e-02, 1.7738e-02, 1.7035e-02, 1.6554e-02, 1.6378e-02,\n",
      "          1.6309e-02, 1.5743e-02, 1.5108e-02, 1.5017e-02, 1.4835e-02,\n",
      "          1.4468e-02, 1.4314e-02, 1.4223e-02, 1.3067e-02, 1.2613e-02,\n",
      "          1.2545e-02, 1.0164e-02, 9.9599e-03, 9.8012e-03, 9.6878e-03],\n",
      "         [5.8903e-01, 1.9792e-01, 1.9634e-01, 3.6109e-03, 2.9339e-03,\n",
      "          2.8210e-03, 2.5954e-03, 2.2568e-03, 2.1440e-03, 3.3852e-04,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [5.2705e-01, 6.0267e-02, 3.9771e-02, 3.5857e-02, 2.7792e-02,\n",
      "          2.1849e-02, 2.1132e-02, 1.9620e-02, 1.7895e-02, 1.5707e-02,\n",
      "          1.3809e-02, 1.3783e-02, 1.3438e-02, 1.2775e-02, 1.1448e-02,\n",
      "          1.1289e-02, 1.1130e-02, 1.0997e-02, 1.0864e-02, 1.0519e-02,\n",
      "          1.0519e-02, 1.0281e-02, 1.0228e-02, 9.9623e-03, 9.0071e-03,\n",
      "          9.0071e-03, 8.9541e-03, 8.3969e-03, 8.3841e-03, 8.2642e-03],\n",
      "         [9.1640e-01, 1.7857e-02, 8.9286e-03, 8.1169e-03, 7.3052e-03,\n",
      "          7.3052e-03, 6.4935e-03, 5.6818e-03, 5.6818e-03, 5.6818e-03,\n",
      "          5.6818e-03, 8.1169e-04, 8.1169e-04, 8.1169e-04, 8.1169e-04,\n",
      "          8.1169e-04, 8.1169e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n",
      "       device='cuda:0'), 'candidate_entities': {'ids': tensor([[[397844, 292749,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [  7271, 105620,  57907, 465936,  11856, 420907,  31244, 137415,\n",
      "          429912, 128647, 454144, 238142, 153484, 299430,  20440,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [325198,  61398, 376909, 250478, 197057, 309405, 340090,  96994,\n",
      "          288214, 106413, 257665,  89570, 134161, 270126,  49853, 379350,\n",
      "          303872, 194147, 403275,  83402, 282951,  12304, 195461, 328513,\n",
      "           38736,  69495, 325403, 153924, 133085, 438218],\n",
      "         [ 24746,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [328870, 385128,  68616,  11199,  48435,  32718, 105666,  34804,\n",
      "          231663,  19760, 117124,  27063, 296930, 287376, 163846, 150541,\n",
      "          236720,  29061, 406874, 295880, 274467, 283858, 381711, 111884,\n",
      "          410548, 413299,  98678, 381038,   8158, 409901],\n",
      "         [ 20415, 258341, 160331, 308763, 229433, 295590, 117218,   1720,\n",
      "          317104, 371576, 333624, 290683,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [413109, 145638, 183720, 387203, 192984,  76998, 430493,  75479,\n",
      "          395961, 205293, 166167, 235561, 112265, 391338, 279010, 353056,\n",
      "          394274,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0]],\n",
      "\n",
      "        [[ 53720, 226298, 468574, 335640, 132908, 317347, 361399, 328227,\n",
      "          205744, 131527,  68235, 407378, 110900, 418763, 111529, 230968,\n",
      "          310778, 146298, 257953,  18157, 279844, 192144, 295141, 178261,\n",
      "          142573, 403517,  29577, 422535, 437179,  17870],\n",
      "         [245750,   7727, 277772, 328758, 450840, 289174,  17143, 216632,\n",
      "           44577, 416518, 390139,  42541, 434856,  83967, 437466, 438647,\n",
      "          164963, 461527, 275377, 228301, 402072, 277702, 462105, 448575,\n",
      "          224552, 463298, 451436,  20924, 261393,  85468],\n",
      "         [277772,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [277772,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [100504,  30964, 131137, 356623,  96573, 192563, 237848, 117209,\n",
      "          429412, 309029, 212877,  37968,   9651, 445762, 240883,  25800,\n",
      "          118386, 302592, 376597,  99912, 452501, 115008, 186997, 149142,\n",
      "          174906, 246136, 420517,  35666,  36045, 118428],\n",
      "         [ 99912,  37968, 340260,  69097, 319026, 331761, 223521, 316824,\n",
      "          348051, 101128, 101825, 295839, 209667, 451819,  86149, 277553,\n",
      "          263613,  85352,  25594, 325133, 151120, 386591, 181344,  53602,\n",
      "           48485, 358470, 427191,  63691, 213393, 257881],\n",
      "         [ 37968,  99912, 223521, 184052, 358470, 348051,  84944, 308120,\n",
      "          447937,  56968, 254718, 226421, 197806, 182942, 383093, 315175,\n",
      "          302780, 163156, 328077, 464750, 316217, 142303,  30090, 329178,\n",
      "           58523, 154491, 436575, 135444, 398517, 103982],\n",
      "         [128519,   5807, 288555, 229414, 261355,  34156, 207714, 410195,\n",
      "          245124,  97140, 460620,  75967, 423394, 315443,  70502, 286498,\n",
      "          278557, 355589, 398274, 469282, 393728, 315934, 150058, 148738,\n",
      "          329155,  19133, 141238, 326374, 141440, 326611],\n",
      "         [351622, 136650,   5807, 380774, 180350, 120504, 282700, 159030,\n",
      "           37968,   2000,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [143921,  21622, 330430, 266167, 198360, 375684, 321248, 359684,\n",
      "          383841, 200862, 434733, 175939,    111, 379575, 104881, 179793,\n",
      "           39633, 339030, 375023, 392434,  72806, 309122, 419457, 155842,\n",
      "          366565,  53585, 240904, 198062, 365272, 236161],\n",
      "         [413109, 145638, 183720, 387203, 192984,  76998, 430493,  75479,\n",
      "          395961, 205293, 166167, 235561, 112265, 391338, 279010, 353056,\n",
      "          394274,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0]]], device='cuda:0')}, 'candidate_spans': tensor([[[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 4,  4],\n",
      "         [ 4,  5],\n",
      "         [ 5,  5],\n",
      "         [ 6,  6],\n",
      "         [ 7,  7],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 4,  4],\n",
      "         [ 4,  7],\n",
      "         [ 4,  8],\n",
      "         [ 6,  6],\n",
      "         [ 6,  7],\n",
      "         [ 6,  8],\n",
      "         [ 7,  7],\n",
      "         [ 7,  8],\n",
      "         [ 8,  8],\n",
      "         [ 9,  9]]], device='cuda:0'), 'candidate_segment_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}, 'wordnet': {'candidate_entity_priors': tensor([[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0081e-03, 1.0081e-03, 1.0081e-03, 4.0323e-03, 3.0242e-03,\n",
      "          1.0081e-02, 3.6290e-02, 1.7540e-01, 2.0161e-03, 3.0242e-03,\n",
      "          5.3125e-01, 1.3609e-01, 2.1169e-02, 5.9476e-02, 1.2097e-02,\n",
      "          3.0242e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e-02, 1.0000e-01, 1.0000e-02, 1.0000e-02, 2.0000e-02,\n",
      "          3.0000e-01, 4.0000e-02, 4.3000e-01, 1.0000e-02, 1.0000e-02,\n",
      "          1.0000e-02, 1.0000e-02, 1.0000e-02, 1.0000e-02, 2.0000e-02,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [3.8462e-01, 7.6923e-02, 4.6154e-01, 7.6923e-02, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [4.3478e-03, 4.3478e-03, 1.6087e-01, 9.1304e-02, 9.5652e-02,\n",
      "          4.3478e-03, 1.7391e-02, 4.3478e-03, 1.7391e-02, 1.0435e-01,\n",
      "          8.6957e-02, 4.3478e-03, 1.0870e-01, 3.4783e-02, 2.4348e-01,\n",
      "          1.7391e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [5.9948e-05, 1.7985e-04, 5.2155e-03, 4.2084e-02, 6.4403e-01,\n",
      "          1.1990e-04, 1.8104e-01, 1.1390e-02, 5.4073e-02, 1.6246e-02,\n",
      "          3.5370e-03, 5.9948e-05, 5.9948e-05, 4.1904e-02, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [2.6455e-03, 1.5873e-02, 2.6455e-03, 2.6455e-03, 2.6455e-03,\n",
      "          3.1746e-02, 8.2275e-01, 9.7884e-02, 2.6455e-03, 1.0582e-02,\n",
      "          2.6455e-03, 5.2910e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [2.6154e-01, 1.5385e-02, 7.2308e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.6667e-02, 8.6667e-01, 1.1667e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n",
      "       device='cuda:0'), 'candidate_entities': {'ids': tensor([[[ 36137,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 57960,  58811,  62085, 103935, 104076, 111970, 112082, 112425,\n",
      "          113034, 116441, 116609, 116616, 116649, 116878, 117130, 117322,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 23215,  48108,  55610,  59821,  67951,  68680,  83891, 101279,\n",
      "          101287, 106268, 106269, 108488, 108573, 108575, 114439,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 38086,  38088,  68972,  69005,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 24615, 109093, 109185, 109636, 109641, 110986, 111038, 115912,\n",
      "          116521, 116523, 116766, 117130, 117132, 117133, 117134, 117322,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0]],\n",
      "\n",
      "        [[ 67002,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [100139, 115193, 116069, 116824, 116829, 116859, 116872, 116893,\n",
      "          117059, 117105, 117260, 117283, 117513, 117542,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 77511,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [   120,    683,   4503,   4515,   4516,   5136,   8984,   9240,\n",
      "            9243,  11347,  14345,  18854,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 70779,  70780,  70786,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 70786,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 66266,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 66575,  68081,  68100,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0]]], device='cuda:0')}, 'candidate_spans': tensor([[[ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5],\n",
      "         [ 6,  6],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 4,  4],\n",
      "         [ 6,  6],\n",
      "         [ 6,  7],\n",
      "         [ 6,  8],\n",
      "         [ 7,  7],\n",
      "         [ 8,  8]]], device='cuda:0'), 'candidate_segment_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}}\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False]], device='cuda:0')\n",
      "None\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=4'>5</a>\u001b[0m (\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=5'>6</a>\u001b[0m     source_ids,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=6'>7</a>\u001b[0m     source_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=18'>19</a>\u001b[0m     target_mask\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=19'>20</a>\u001b[0m ) \u001b[39m=\u001b[39m batch\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=21'>22</a>\u001b[0m source_candidates \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=22'>23</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mwiki\u001b[39m\u001b[39m'\u001b[39m : {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=23'>24</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcandidate_entity_priors\u001b[39m\u001b[39m'\u001b[39m : source_wiki_candidate_priors,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=33'>34</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=34'>35</a>\u001b[0m }\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=37'>38</a>\u001b[0m loss, _, _ \u001b[39m=\u001b[39m model(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=38'>39</a>\u001b[0m     source_ids\u001b[39m=\u001b[39;49msource_ids,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=39'>40</a>\u001b[0m     source_mask\u001b[39m=\u001b[39;49msource_mask,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=40'>41</a>\u001b[0m     source_candidates\u001b[39m=\u001b[39;49msource_candidates,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=41'>42</a>\u001b[0m     triples_ids\u001b[39m=\u001b[39;49mtriples_ids,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=42'>43</a>\u001b[0m     triples_mask\u001b[39m=\u001b[39;49mtriples_mask,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=43'>44</a>\u001b[0m     target_ids\u001b[39m=\u001b[39;49mtarget_ids,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=44'>45</a>\u001b[0m     target_mask\u001b[39m=\u001b[39;49mtarget_mask,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=45'>46</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=47'>48</a>\u001b[0m tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=48'>49</a>\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=49'>50</a>\u001b[0m     tr_loss \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (nb_tr_steps \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m4\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=50'>51</a>\u001b[0m )\n",
      "File \u001b[0;32m~/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py:95\u001b[0m, in \u001b[0;36mBertSeq2Seq.forward\u001b[0;34m(self, source_ids, source_mask, source_candidates, triples_ids, triples_mask, target_ids, target_mask)\u001b[0m\n\u001b[1;32m     <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=84'>85</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m     <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=85'>86</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=86'>87</a>\u001b[0m     source_ids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=92'>93</a>\u001b[0m     target_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=93'>94</a>\u001b[0m ):\n\u001b[0;32m---> <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=94'>95</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(tokens\u001b[39m=\u001b[39;49msource_ids, segment_ids\u001b[39m=\u001b[39;49msource_mask, candidates\u001b[39m=\u001b[39;49msource_candidates)\n\u001b[1;32m     <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=95'>96</a>\u001b[0m     question_encoder_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=96'>97</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtriple_encoder(triples_ids, attention_mask\u001b[39m=\u001b[39mtriples_mask)\n",
      "File \u001b[0;32m~/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/knowbert.py:889\u001b[0m, in \u001b[0;36mKnowBert.forward\u001b[0;34m(self, tokens, segment_ids, candidates, lm_label_ids, next_sentence_label, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/knowbert.py?line=884'>885</a>\u001b[0m \u001b[39mprint\u001b[39m(kwargs)\n\u001b[1;32m    <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/knowbert.py?line=886'>887</a>\u001b[0m \u001b[39massert\u001b[39;00m candidates\u001b[39m.\u001b[39mkeys() \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoldered_kgs\u001b[39m.\u001b[39mkeys()\n\u001b[0;32m--> <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/knowbert.py?line=888'>889</a>\u001b[0m mask \u001b[39m=\u001b[39m tokens[\u001b[39m'\u001b[39;49m\u001b[39mtokens\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/knowbert.py?line=889'>890</a>\u001b[0m attention_mask \u001b[39m=\u001b[39m extend_attention_mask_for_bert(mask, get_dtype_for_module(\u001b[39mself\u001b[39m))\n\u001b[1;32m    <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/knowbert.py?line=890'>891</a>\u001b[0m contextual_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpretrained_bert\u001b[39m.\u001b[39mbert\u001b[39m.\u001b[39membeddings(tokens[\u001b[39m'\u001b[39m\u001b[39mtokens\u001b[39m\u001b[39m'\u001b[39m], segment_ids)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    bar = tqdm(train_dataloader, total=len(train_dataloader))\n",
    "    for batch in bar:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        (\n",
    "            source_ids,\n",
    "            source_mask,\n",
    "            source_wiki_candidate_priors,\n",
    "            source_wiki_candidate_ids,\n",
    "            source_wiki_candidate_spans,\n",
    "            source_wiki_candidate_segment_ids,\n",
    "            source_wordnet_candidate_priors,\n",
    "            source_wordnet_candidate_ids,\n",
    "            source_wordnet_candidate_spans,\n",
    "            source_wordnet_candidate_segment_ids,\n",
    "            triples_ids,\n",
    "            triples_mask,\n",
    "            target_ids,\n",
    "            target_mask\n",
    "        ) = batch\n",
    "\n",
    "        source_candidates = {\n",
    "            'wiki' : {\n",
    "                'candidate_entity_priors' : source_wiki_candidate_priors,\n",
    "                'candidate_entities' : {'ids' : source_wiki_candidate_ids},\n",
    "                'candidate_spans' : source_wiki_candidate_spans,\n",
    "                'candidate_segment_ids' : source_wiki_candidate_segment_ids\n",
    "            },\n",
    "            'wordnet' : {\n",
    "                'candidate_entity_priors' : source_wordnet_candidate_priors,\n",
    "                'candidate_entities' : {'ids' : source_wordnet_candidate_ids},\n",
    "                'candidate_spans' : source_wordnet_candidate_spans,\n",
    "                'candidate_segment_ids' : source_wordnet_candidate_segment_ids\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "        loss, _, _ = model(\n",
    "            source_ids=source_ids,\n",
    "            source_mask=source_mask,\n",
    "            source_candidates=source_candidates,\n",
    "            triples_ids=triples_ids,\n",
    "            triples_mask=triples_mask,\n",
    "            target_ids=target_ids,\n",
    "            target_mask=target_mask,\n",
    "        )\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        train_loss = round(\n",
    "            tr_loss * -1 / (nb_tr_steps + 1), 4\n",
    "        )\n",
    "        bar.set_description(\"epoch {} loss {}\".format(epoch, train_loss))\n",
    "        nb_tr_examples += source_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        loss.backward()\n",
    "\n",
    "        if (nb_tr_steps + 1) % -1 == 0:\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            global_step += 1\n",
    "\n",
    "    if False and (epoch + 1) % 1 == 0:\n",
    "        # Eval model with dev dataset\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        eval_flag = False\n",
    "\n",
    "        # Calculate bleu\n",
    "        if \"dev_bleu\" in dev_dataset:\n",
    "            eval_examples, eval_data = dev_dataset[\"dev_bleu\"]\n",
    "        else:\n",
    "            eval_examples = read_examples(\n",
    "                args.dev_filename + \".\" + args.source,\n",
    "                args.dev_filename + \".triple\",\n",
    "                args.dev_filename + \".\" + args.target,\n",
    "            )\n",
    "            eval_examples = random.sample(\n",
    "                eval_examples, min(1000, len(eval_examples))\n",
    "            )\n",
    "            eval_features = convert_examples_to_features(\n",
    "                eval_examples, tokenizer, args, stage=\"test\"\n",
    "            )\n",
    "            all_source_ids = torch.tensor(\n",
    "                [f.source_ids for f in eval_features], dtype=torch.long\n",
    "            )\n",
    "            all_source_mask = torch.tensor(\n",
    "                [f.source_mask for f in eval_features], dtype=torch.long\n",
    "            )\n",
    "            all_triples_ids = torch.tensor(\n",
    "                [f.triples_ids for f in eval_features], dtype=torch.long\n",
    "            )\n",
    "            all_triples_mask = torch.tensor(\n",
    "                [f.triples_mask for f in eval_features], dtype=torch.long\n",
    "            )\n",
    "            eval_data = TensorDataset(\n",
    "                all_source_ids,\n",
    "                all_source_mask,\n",
    "                all_triples_ids,\n",
    "                all_triples_mask,\n",
    "            )\n",
    "            dev_dataset[\"dev_bleu\"] = eval_examples, eval_data\n",
    "\n",
    "        eval_sampler = SequentialSampler(eval_data)\n",
    "        eval_dataloader = DataLoader(\n",
    "            eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size\n",
    "        )\n",
    "\n",
    "        model.eval()\n",
    "        p = []\n",
    "        for batch in eval_dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            source_ids, source_mask, triples_ids, triples_mask = batch\n",
    "            with torch.no_grad():\n",
    "                preds = model(\n",
    "                    source_ids=source_ids,\n",
    "                    source_mask=source_mask,\n",
    "                    triples_ids=triples_ids,\n",
    "                    triples_mask=triples_mask,\n",
    "                )\n",
    "                for pred in preds:\n",
    "                    t = pred[0].cpu().numpy()\n",
    "                    t = list(t)\n",
    "                    if 0 in t:\n",
    "                        t = t[: t.index(0)]\n",
    "                    text = tokenizer.decode(\n",
    "                        t, clean_up_tokenization_spaces=False\n",
    "                    )\n",
    "                    p.append(text)\n",
    "        model.train()\n",
    "        predictions = []\n",
    "        pred_str = []\n",
    "        label_str = []\n",
    "        with open(os.path.join(args.output_dir, \"dev.output\"), \"w\") as f, open(\n",
    "            os.path.join(args.output_dir, \"dev.gold\"), \"w\"\n",
    "        ) as f1:\n",
    "            for ref, gold in zip(p, eval_examples):\n",
    "                ref = ref.strip().replace(\"< \", \"<\").replace(\" >\", \">\")\n",
    "                ref = re.sub(\n",
    "                    r' ?([!\"#$%&\\'(’)*+,-./:;=?@\\\\^_`{|}~]) ?', r\"\\1\", ref\n",
    "                )\n",
    "                ref = ref.replace(\"attr_close>\", \"attr_close >\").replace(\n",
    "                    \"_attr_open\", \"_ attr_open\"\n",
    "                )\n",
    "                ref = ref.replace(\" [ \", \" [\").replace(\" ] \", \"] \")\n",
    "                ref = ref.replace(\"_obd_\", \" _obd_ \").replace(\n",
    "                    \"_oba_\", \" _oba_ \"\n",
    "                )\n",
    "\n",
    "                pred_str.append(ref.split())\n",
    "                label_str.append([gold.target.strip().split()])\n",
    "                predictions.append(str(gold.idx) + \"\\t\" + ref)\n",
    "                f.write(str(gold.idx) + \"\\t\" + ref + \"\\n\")\n",
    "                f1.write(str(gold.idx) + \"\\t\" + gold.target + \"\\n\")\n",
    "\n",
    "        bl_score = corpus_bleu(label_str, pred_str) * 100\n",
    "\n",
    "        logger.info(\"  {} = {} \".format(\"BLEU\", str(round(bl_score, 4))))\n",
    "        logger.info(\"  \" + \"*\" * 20)\n",
    "        if bl_score > best_bleu:\n",
    "            logger.info(\"  Best bleu:%s\", bl_score)\n",
    "            logger.info(\"  \" + \"*\" * 20)\n",
    "            best_bleu = bl_score\n",
    "            # Save best checkpoint for best bleu\n",
    "            output_dir = os.path.join(args.output_dir, \"checkpoint-best-bleu\")\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            model_to_save = (\n",
    "                model.module if hasattr(model, \"module\") else model\n",
    "            )  # Only save the model it-self\n",
    "            output_model_file = os.path.join(output_dir, \"pytorch_model.bin\")\n",
    "            torch.save(model_to_save.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a2cfeb9246a79e14cff750d6c31ddf53a672c28bf2fc0b5b4eabcb8d601b798"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('allennlp-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
