{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers import BertConfig\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaModel\n",
    "from transformers import RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-10 09:15:30,338 - knowbert-logger - ERROR - This is the first error\n"
     ]
    }
   ],
   "source": [
    "from KBQA.appB.transformer_architectures.kb.knowbert import KnowBert\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "logger = logging.getLogger('knowbert-logger')\n",
    "streamHandler = logging.StreamHandler(sys.stdout)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "streamHandler.setFormatter(formatter)\n",
    "logger.addHandler(streamHandler)\n",
    "logger.error(\"This is the first error\")\n",
    "logger.setLevel(logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-10 09:15:34,006 - knowbert-logger.main - INFO - Loaded Vocabulary\n",
      "2022-06-10 09:15:34,007 - knowbert-logger.main - DEBUG - Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'*labels', '*tags'}\n",
      " \tNamespace: entity_wiki, Size: 470116 \n",
      " \tNamespace: entity_wordnet, Size: 117663 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cd89d7ce7448b5835cbd005526cb1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-10 09:16:19,879 - knowbert-logger.main - INFO - Loaded wiki embedding\n",
      "2022-06-10 09:16:19,885 - knowbert-logger.main - INFO - Init Bert Encoder\n",
      "2022-06-10 09:16:19,913 - knowbert-logger.main - INFO - Loaded wiki soldered KG\n",
      "2022-06-10 09:16:26,082 - knowbert-logger.main - INFO - Loaded wordnet embedding\n",
      "2022-06-10 09:16:26,086 - knowbert-logger.main - INFO - Init Bert Encoder\n",
      "2022-06-10 09:16:26,106 - knowbert-logger.main - INFO - Loaded wordnet soldered KG\n"
     ]
    }
   ],
   "source": [
    "encoder = KnowBert.load_pretrained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triple_encoder_config = BertConfig.from_pretrained(\"razent/spbert-mlm-wso-base\")\n",
    "triple_encoder = BertModel.from_pretrained(\n",
    "    \"razent/spbert-mlm-wso-base\", config=triple_encoder_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_config = BertConfig.from_pretrained(\n",
    "    \"razent/spbert-mlm-wso-base\"\n",
    ")\n",
    "decoder_config.is_decoder = True\n",
    "decoder_config.add_cross_attention = True\n",
    "decoder = BertModel.from_pretrained(\n",
    "    \"razent/spbert-mlm-wso-base\", config=decoder_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KBQA.appB.transformer_architectures.kb.model import BertSeq2Seq\n",
    "\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "device = torch.device(\"cuda:0\")\n",
    "tokenizer_uncased = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "model = BertSeq2Seq(encoder=encoder,\n",
    "                    triple_encoder=triple_encoder,\n",
    "                    decoder=decoder,\n",
    "                    config=config,\n",
    "                    beam_size=2,\n",
    "                    max_length=4,\n",
    "                    sos_id=tokenizer_uncased.cls_token_id,\n",
    "                    eos_id=tokenizer_uncased.sep_token_id,\n",
    "                    device=device\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-10 09:17:09,264 - knowbert-logger.batchifier - INFO - Building Generators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/allennlp/data/token_indexers/token_characters_indexer.py:55: UserWarning: You are using the default value (0) of `min_padding_length`, which can cause some subtle bugs (more info see https://github.com/allenai/allennlp/issues/1954). Strongly recommend to set a value, usually the maximum size of the convolutional layer size when using CnnEncoder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-10 09:18:10,234 - knowbert-logger.wiki - INFO - duplicate_mentions_cnt: 6777\n",
      "2022-06-10 09:18:10,235 - knowbert-logger.wiki - INFO - end of p_e_m reading. wall time: 0.9682023803393046 minutes\n",
      "2022-06-10 09:18:10,235 - knowbert-logger.wiki - INFO - p_e_m_errors: 0\n",
      "2022-06-10 09:18:10,236 - knowbert-logger.wiki - INFO - incompatible_ent_ids: 0\n",
      "2022-06-10 09:18:39,660 - knowbert-logger.batchifier - INFO - Build Generators\n",
      "2022-06-10 09:18:50,385 - knowbert-logger.batchifier - INFO - Done building candidate generators\n"
     ]
    }
   ],
   "source": [
    "from KBQA.appB.transformer_architectures.kb.knowbert_utils import KnowBertBatchifier\n",
    "\n",
    "archive_file = 'https://allennlp.s3-us-west-2.amazonaws.com/knowbert/models/knowbert_wiki_wordnet_model.tar.gz'\n",
    "batcher = KnowBertBatchifier(archive_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-10 09:31:50,216 - knowbert-logger.candidate-generator - DEBUG - offsets: [1, 2, 3, 4, 5, 6]\n",
      "2022-06-10 09:31:50,216 - knowbert-logger.candidate-generator - DEBUG - word_piece_tokens: [['paris'], ['is'], ['located'], ['in'], ['france'], ['.']]\n",
      "2022-06-10 09:31:50,217 - knowbert-logger.candidate-generator - DEBUG - tokens: ['Paris', 'is', 'located', 'in', 'France', '.']\n",
      "2022-06-10 09:31:50,222 - knowbert-logger.batchifier - DEBUG - token_candidates: {'tokens': ['[CLS]', 'paris', 'is', 'located', 'in', 'france', '.', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['Paris', 'is', 'located', 'in', 'France', '.'], 'candidate_spans': [[1, 1], [3, 3], [5, 5], [6, 6]], 'candidate_entities': [['Paris', 'Paris_(mythology)', 'Paris_Hilton', 'Paris,_Texas', 'Paris,_Kentucky', 'Paris_Las_Vegas', 'Paris_Masters', 'Paris_(Paris_Hilton_album)', 'Paris,_Missouri', 'Paris_Metropolitan_Area', 'Paris_(The_Cure_album)', 'Count_Paris', 'University_of_Paris', 'Paris_(rapper)', 'Paris,_Ontario', 'Paris,_Maine', 'Paris_(Malcolm_McLaren_album)', 'Paris,_Kenosha_County,_Wisconsin', 'Paris,_Grant_County,_Wisconsin', 'Liberation_of_Paris', 'Bubba_Paris', 'Paris,_Illinois', 'Paris,_Virginia', 'Charles_de_Gaulle_Airport', 'Paris_FC', 'Live_8_concert,_Paris', 'Open_GDF_Suez', 'Paris_Métro', 'Paris,_Arkansas', 'Paris,_Tennessee'], ['Locus_(genetics)', 'Space_Shuttle_Challenger_disaster', 'South_Padre_Island', 'Location_(geography)', 'Map_Room_(White_House)', 'Sderot', \"Shenzhen_Bao'an_International_Airport\", 'Rural_Khmer_house', 'Liver', 'Search_for_HMAS_Sydney_and_German_auxiliary_cruiser_Kormoran', 'Nazi_concentration_camps', 'Yellow_Sea', 'Battle_between_HMAS_Sydney_and_German_auxiliary_cruiser_Kormoran', 'Tallapoosa_County,_Alabama', 'Naypyidaw', 'Topkapı_Palace', 'Latvia', 'Drax_power_station', 'Palazzo_Malta', 'World_Geodetic_System', 'CBLFT-DT'], ['France', 'France_national_football_team', 'France_national_rugby_union_team', 'French_Third_Republic', 'Early_modern_France', 'France_national_rugby_league_team', 'Louisiana_Purchase', 'Battle_of_France', 'French_Football_Federation', 'France_Davis_Cup_team', 'France_national_basketball_team', 'First_French_Empire', \"France_women's_national_football_team\", 'French_rock', \"Syndicat_National_de_l'Édition_Phonographique\", 'Anarchism_in_France', 'France_in_the_Eurovision_Song_Contest', 'French_colonial_empire', 'LNB_Pro_A', 'France_national_cricket_team', \"France_men's_national_ice_hockey_team\", 'Military_history_of_France_during_World_War_II', 'Second_French_Empire', 'Ligue_1', 'France_Fed_Cup_team', 'French_Rugby_Federation', 'France_at_the_2008_Summer_Olympics', 'French_euro_coins', 'France_in_the_Middle_Ages', 'French_Communist_Party'], ['Full_stop', 'Names_of_Burma', 'University_of_Yangon', 'Ne_Win', 'Administrative_divisions_of_Burma', 'Wa_people', 'Yangon_River', 'U_Nu', 'Yangon_Technological_University', 'U_Thant', 'Yangon', 'Naypyidaw', 'Greater_Tokyo_Area', 'Allies_of_World_War_II', 'Shiva', '1991_Bangladesh_cyclone', 'Bhopal', 'Ba_Win', 'Doctor_of_Philosophy', 'Walter_Chit_Tun', 'Big_Brother_(UK)', 'Harlem', 'Combining_character', '8888_Uprising', 'Union_Solidarity_and_Development_Association', 'Uncanny', 'Yangon_Region', 'Derby', 'A_Coruña', 'Shwe_Mann']], 'candidate_entity_priors': [[0.8109870459693594, 0.015042638404379095, 0.008772948535125481, 0.007844291508854923, 0.0076334612650529295, 0.007387492647283889, 0.0073774531118647475, 0.00733227520247865, 0.007327255434769125, 0.007141524029514941, 0.006619468187719615, 0.006559230975204759, 0.006318282125145336, 0.006227926306373053, 0.006167689093858196, 0.006022115830280675, 0.005961878617765818, 0.005821325121897821, 0.0057108902322872525, 0.00566069255519154, 0.005535198362452302, 0.0054850006853565895, 0.005404684402003448, 0.005178794855072785, 0.005153696016524882, 0.0051135378748483114, 0.005108518107138786, 0.0050884390363005, 0.005028201823785645, 0.004988043682109074], [0.5045296167247405, 0.13937282229965112, 0.13937282229965112, 0.06480836236933663, 0.03972125435540094, 0.02299651567944281, 0.01742160278745626, 0.016724738675958133, 0.009059233449477195, 0.008362369337979066, 0.007665505226480937, 0.0055749128919860445, 0.0041811846689895835, 0.0041811846689895835, 0.0034843205574913026, 0.0034843205574913026, 0.0034843205574913026, 0.0034843205574913026, 0.0006968641114982807, 0.0006968641114982807, 0.0006968641114982807], [0.8163134859182082, 0.032590228038436794, 0.01313293982148377, 0.009977829851932168, 0.008833694700492079, 0.006906607592058549, 0.00552013016821569, 0.005478186313376747, 0.0054478935293264365, 0.005259146182551242, 0.005158946973769328, 0.0050098132676752345, 0.004867670204054378, 0.00480009399348052, 0.004788442922691984, 0.00463697900244024, 0.0046136768608630715, 0.00455775172107775, 0.004541440221973722, 0.0045321193653429315, 0.0045227985087120445, 0.004415608657456893, 0.004345702232725387, 0.004331720947779104, 0.00431307923451733, 0.004303758377886443, 0.0042548238805743595, 0.004252493666416613, 0.004149964243476955, 0.004142973601003813], [0.4705882352941141, 0.11764705882353167, 0.08403361344537887, 0.025210084033613033, 0.025210084033613033, 0.025210084033613033, 0.025210084033613033, 0.016806722689075772, 0.016806722689075772, 0.016806722689075772, 0.016806722689075772, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886]], 'candidate_segment_ids': [0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['Paris', 'is', 'located', 'in', 'France', '.'], 'candidate_spans': [[1, 1], [2, 2], [3, 3], [4, 4], [5, 5]], 'candidate_entities': [['paris.n.01', 'paris.n.04', 'paris.n.03', 'paris.n.02'], ['beryllium.n.01', 'be.v.10', 'be.v.08', 'exist.v.01', 'be.v.01', 'be.v.11', 'be.v.02', 'constitute.v.01', 'be.v.03', 'equal.v.01', 'embody.v.02', 'cost.v.01', 'be.v.12', 'be.v.05'], ['settle.v.04', 'locate.v.01', 'locate.v.03', 'situate.v.01'], ['in.s.03', 'in.s.02', 'in.s.01', 'in.r.01', 'indiana.n.01', 'inch.n.01', 'indium.n.01'], ['france.n.01', 'france.n.02']], 'candidate_entity_priors': [[0.875, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664], [5.994844433786943e-05, 0.0001798453330136083, 0.0052155146573946405, 0.04208380792518434, 0.6440261375217313, 0.00011989688867573886, 0.1810443019003657, 0.011390204424195192, 0.054073496792758226, 0.016246028415562615, 0.0035369582159342967, 5.994844433786943e-05, 5.994844433786943e-05, 0.04190396259217073], [0.125, 0.425, 0.125, 0.325], [0.034482758620689655, 0.034482758620689655, 0.034482758620689655, 0.6896551724137931, 0.034482758620689655, 0.13793103448275862, 0.034482758620689655], [0.9166666666666666, 0.08333333333333333]], 'candidate_segment_ids': [0, 0, 0, 0, 0]}}, 'offsets_a': [2, 3, 4, 5, 6, 7], 'offsets_b': None}\n",
      "2022-06-10 09:31:50,223 - knowbert-logger.batchifier - DEBUG - Paris is located in France.\n",
      "2022-06-10 09:31:50,225 - knowbert-logger.batchifier - DEBUG - ['[CLS]', 'paris', 'is', 'located', 'in', 'france', '.', '[SEP]']\n",
      "2022-06-10 09:31:50,226 - knowbert-logger.batchifier - DEBUG - {'tokens': <allennlp.data.fields.text_field.TextField object at 0x7fdcac7702c0>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7fdaf8c41a60>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7fdcf50e0d00>}\n",
      "2022-06-10 09:31:50,227 - knowbert-logger.batchifier - DEBUG - Instance with fields:\n",
      " \t tokens: TextField of length 8 with text: \n",
      " \t\t[[CLS], paris, is, located, in, france, ., [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([8]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "2022-06-10 09:31:50,228 - knowbert-logger.candidate-generator - DEBUG - offsets: [2, 3, 4, 5, 6, 7]\n",
      "2022-06-10 09:31:50,229 - knowbert-logger.candidate-generator - DEBUG - word_piece_tokens: [['know', '##bert'], ['is'], ['a'], ['knowledge'], ['enhanced'], ['bert']]\n",
      "2022-06-10 09:31:50,229 - knowbert-logger.candidate-generator - DEBUG - tokens: ['KnowBert', 'is', 'a', 'knowledge', 'enhanced', 'BERT']\n",
      "2022-06-10 09:31:50,235 - knowbert-logger.batchifier - DEBUG - token_candidates: {'tokens': ['[CLS]', 'know', '##bert', 'is', 'a', 'knowledge', 'enhanced', 'bert', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['KnowBert', 'is', 'a', 'knowledge', 'enhanced', 'BERT'], 'candidate_spans': [[5, 5], [6, 6], [7, 7]], 'candidate_entities': [['Knowledge', 'Jnana', 'Platonic_epistemology', 'Sociology_of_knowledge', 'Artificial_intelligence', 'Epistemology', 'Knowledge_representation_and_reasoning', 'Knowledge_worker', 'Qibya_massacre', 'Saraswati', 'Descriptive_knowledge', 'Knowledge_ecosystem', 'Cognition', 'Taxicabs_of_the_United_Kingdom', 'Safety_(firearms)', 'Truth', 'Pebble-bed_reactor', 'Wisdom_in_Buddhism', 'Exploding_head_syndrome', 'Carnal_knowledge', 'Toyohiro_Akiyama', 'Science', 'Pareidolia', 'John_Patterson_(pitcher)', 'Knowledge_economy', 'Rakim', 'Gnosis', 'Placenta', 'Home', 'Film'], ['Enhanced_CD', 'Macintosh_512Ke', 'Video_game_remake', 'Human_enhancement', 'Acoustic_enhancement', 'Diamond_enhancement', 'Green_fluorescent_protein', 'MRI_contrast_agent', 'IBM_PC_keyboard'], ['Bert_(Sesame_Street)', 'Bert,_Allier', 'Bert_and_Ernie', 'Bert_is_Evil', 'Bert_Newton', 'Q*bert', 'Mary_Poppins', 'Bert_(horse)', 'Bert_Diaries', 'Bert_Jansch', 'Bert_van_Marwijk', 'Bert_Gould', 'Bert_Blyleven', 'Bert_McCracken', 'Sesame_Street', 'Bertie_Ahern', 'Bert_Rankin', 'Herbert_S._Green', 'Bert_Clay', 'Bert_Barlow', 'Bert_James', 'Black_site', 'Mary_Poppins_(film)', 'Arlesdale_Railway', 'Bert_Lipsham', 'Bert_Crossthwaite', 'Bert_Corbeau', 'Bert_Freeman', 'Bert_Beard', 'Paul_Bert']], 'candidate_entity_priors': [[0.47317399298010904, 0.2523074637398565, 0.25080320166397363, 0.005329916244173294, 0.003807083031552346, 0.00323137779263469, 0.0015042620758816741, 0.0008914145634854197, 0.0008914145634854197, 0.0008357011532675966, 0.0008357011532675966, 0.000705703196092626, 0.0006499897858748031, 0.0005942763756569297, 0.0004457072817427149, 0.0004085650082641561, 0.0003899938715248768, 0.0003899938715248768, 0.00035285159804631803, 0.0003342804613070387, 0.0003157093245677593, 0.00027856705108919556, 0.0002414247776106368, 0.00020428250413207806, 0.00020428250413207806, 0.00018571136739279872, 0.00018571136739279872, 0.00016714023065351934, 0.00016714023065351934, 0.00016714023065351934], [0.43376068376068355, 0.2606837606837591, 0.11752136752136962, 0.08547008547008471, 0.06410256410256479, 0.019230769230768937, 0.010683760683760464, 0.0064102564102564786, 0.002136752136752143], [0.493215707091559, 0.2741958134270307, 0.04945610502102221, 0.03097799984833275, 0.01767623573557162, 0.012784972601623541, 0.011412947312543293, 0.00898065683077603, 0.00898065683077603, 0.007893709467676606, 0.007350235786126988, 0.006806762104577276, 0.006806762104577276, 0.006263288423027563, 0.005434736815497028, 0.005434736815497028, 0.004089393696828714, 0.0038043157708478915, 0.0035459200152790017, 0.0035459200152790017, 0.0035459200152790017, 0.003260842089298179, 0.003260842089298179, 0.003260842089298179, 0.0030024463337293846, 0.0030024463337293846, 0.0030024463337293846, 0.0030024463337293846, 0.0030024463337293846, 0.0030024463337293846]], 'candidate_segment_ids': [0, 0, 0]}, 'wordnet': {'tokenized_text': ['KnowBert', 'is', 'a', 'knowledge', 'enhanced', 'BERT'], 'candidate_spans': [[3, 3], [4, 4], [5, 5], [6, 6]], 'candidate_entities': [['beryllium.n.01', 'be.v.10', 'be.v.08', 'exist.v.01', 'be.v.01', 'be.v.11', 'be.v.02', 'constitute.v.01', 'be.v.03', 'equal.v.01', 'embody.v.02', 'cost.v.01', 'be.v.12', 'be.v.05'], ['a.n.07', 'a.n.06', 'a.n.06', 'ampere.n.02', 'angstrom.n.01', 'adenine.n.01', 'deoxyadenosine_monophosphate.n.01', 'vitamin_a.n.01'], ['cognition.n.01'], ['enhance.v.01', 'enhance.v.02']], 'candidate_entity_priors': [[5.994844433786943e-05, 0.0001798453330136083, 0.0052155146573946405, 0.04208380792518434, 0.6440261375217313, 0.00011989688867573886, 0.1810443019003657, 0.011390204424195192, 0.054073496792758226, 0.016246028415562615, 0.0035369582159342967, 5.994844433786943e-05, 5.994844433786943e-05, 0.04190396259217073], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.5, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [1.0], [0.5454545454545454, 0.45454545454545453]], 'candidate_segment_ids': [0, 0, 0, 0]}}, 'offsets_a': [3, 4, 5, 6, 7, 8], 'offsets_b': None}\n",
      "2022-06-10 09:31:50,236 - knowbert-logger.batchifier - DEBUG - KnowBert is a knowledge enhanced BERT\n",
      "2022-06-10 09:31:50,237 - knowbert-logger.batchifier - DEBUG - ['[CLS]', 'know', '##bert', 'is', 'a', 'knowledge', 'enhanced', 'bert', '[SEP]']\n",
      "2022-06-10 09:31:50,237 - knowbert-logger.batchifier - DEBUG - {'tokens': <allennlp.data.fields.text_field.TextField object at 0x7fdcb3e07040>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7fdaf8c41c70>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7fdafa43de80>}\n",
      "2022-06-10 09:31:50,238 - knowbert-logger.batchifier - DEBUG - Instance with fields:\n",
      " \t tokens: TextField of length 9 with text: \n",
      " \t\t[[CLS], know, ##bert, is, a, knowledge, enhanced, bert, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([9]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "2022-06-10 09:31:50,240 - knowbert-logger.main - DEBUG - In KnowBERT forward\n",
      "2022-06-10 09:31:50,240 - knowbert-logger.main - DEBUG - tokens {'tokens': tensor([[  101,  3000,  2003,  2284,  1999,  2605,  1012,   102,     0],\n",
      "        [  101,  2113,  8296,  2003,  1037,  3716,  9412, 14324,   102]])}\n",
      "2022-06-10 09:31:50,245 - knowbert-logger.main - DEBUG - candidates {'wiki': {'candidate_entity_priors': tensor([[[8.1099e-01, 1.5043e-02, 8.7729e-03, 7.8443e-03, 7.6335e-03,\n",
      "          7.3875e-03, 7.3775e-03, 7.3323e-03, 7.3273e-03, 7.1415e-03,\n",
      "          6.6195e-03, 6.5592e-03, 6.3183e-03, 6.2279e-03, 6.1677e-03,\n",
      "          6.0221e-03, 5.9619e-03, 5.8213e-03, 5.7109e-03, 5.6607e-03,\n",
      "          5.5352e-03, 5.4850e-03, 5.4047e-03, 5.1788e-03, 5.1537e-03,\n",
      "          5.1135e-03, 5.1085e-03, 5.0884e-03, 5.0282e-03, 4.9880e-03],\n",
      "         [5.0453e-01, 1.3937e-01, 1.3937e-01, 6.4808e-02, 3.9721e-02,\n",
      "          2.2997e-02, 1.7422e-02, 1.6725e-02, 9.0592e-03, 8.3624e-03,\n",
      "          7.6655e-03, 5.5749e-03, 4.1812e-03, 4.1812e-03, 3.4843e-03,\n",
      "          3.4843e-03, 3.4843e-03, 3.4843e-03, 6.9686e-04, 6.9686e-04,\n",
      "          6.9686e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [8.1631e-01, 3.2590e-02, 1.3133e-02, 9.9778e-03, 8.8337e-03,\n",
      "          6.9066e-03, 5.5201e-03, 5.4782e-03, 5.4479e-03, 5.2591e-03,\n",
      "          5.1589e-03, 5.0098e-03, 4.8677e-03, 4.8001e-03, 4.7884e-03,\n",
      "          4.6370e-03, 4.6137e-03, 4.5578e-03, 4.5414e-03, 4.5321e-03,\n",
      "          4.5228e-03, 4.4156e-03, 4.3457e-03, 4.3317e-03, 4.3131e-03,\n",
      "          4.3038e-03, 4.2548e-03, 4.2525e-03, 4.1500e-03, 4.1430e-03],\n",
      "         [4.7059e-01, 1.1765e-01, 8.4034e-02, 2.5210e-02, 2.5210e-02,\n",
      "          2.5210e-02, 2.5210e-02, 1.6807e-02, 1.6807e-02, 1.6807e-02,\n",
      "          1.6807e-02, 8.4034e-03, 8.4034e-03, 8.4034e-03, 8.4034e-03,\n",
      "          8.4034e-03, 8.4034e-03, 8.4034e-03, 8.4034e-03, 8.4034e-03,\n",
      "          8.4034e-03, 8.4034e-03, 8.4034e-03, 8.4034e-03, 8.4034e-03,\n",
      "          8.4034e-03, 8.4034e-03, 8.4034e-03, 8.4034e-03, 8.4034e-03]],\n",
      "\n",
      "        [[4.7317e-01, 2.5231e-01, 2.5080e-01, 5.3299e-03, 3.8071e-03,\n",
      "          3.2314e-03, 1.5043e-03, 8.9141e-04, 8.9141e-04, 8.3570e-04,\n",
      "          8.3570e-04, 7.0570e-04, 6.4999e-04, 5.9428e-04, 4.4571e-04,\n",
      "          4.0857e-04, 3.8999e-04, 3.8999e-04, 3.5285e-04, 3.3428e-04,\n",
      "          3.1571e-04, 2.7857e-04, 2.4142e-04, 2.0428e-04, 2.0428e-04,\n",
      "          1.8571e-04, 1.8571e-04, 1.6714e-04, 1.6714e-04, 1.6714e-04],\n",
      "         [4.3376e-01, 2.6068e-01, 1.1752e-01, 8.5470e-02, 6.4103e-02,\n",
      "          1.9231e-02, 1.0684e-02, 6.4103e-03, 2.1368e-03, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [4.9322e-01, 2.7420e-01, 4.9456e-02, 3.0978e-02, 1.7676e-02,\n",
      "          1.2785e-02, 1.1413e-02, 8.9807e-03, 8.9807e-03, 7.8937e-03,\n",
      "          7.3502e-03, 6.8068e-03, 6.8068e-03, 6.2633e-03, 5.4347e-03,\n",
      "          5.4347e-03, 4.0894e-03, 3.8043e-03, 3.5459e-03, 3.5459e-03,\n",
      "          3.5459e-03, 3.2608e-03, 3.2608e-03, 3.2608e-03, 3.0024e-03,\n",
      "          3.0024e-03, 3.0024e-03, 3.0024e-03, 3.0024e-03, 3.0024e-03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]), 'candidate_entities': {'ids': tensor([[[ 61415, 186436, 156993, 388347, 212590,  96609, 288567, 439001,\n",
      "          190664, 283891, 255997, 393971, 310206,  95850, 133157, 464732,\n",
      "          377698, 331564, 368041, 210960, 204580, 297113, 151039, 294839,\n",
      "           25989, 364799, 378739, 348909, 228856, 408537],\n",
      "         [217306, 208363, 195501, 398949, 272844,  78700, 434051, 459855,\n",
      "           36386, 301496, 118479, 419394,  31593,  54692, 435604, 410440,\n",
      "           82294, 164716, 314418,  93380, 443994,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [   624, 242805,  55193, 401811, 230615, 195592, 393357, 231251,\n",
      "          321038, 384279, 171717, 438345, 292339, 197367, 149353, 270081,\n",
      "          302841, 426462, 231910, 126378, 313191, 310722,  12985, 443631,\n",
      "          221456, 124550, 291887, 366929, 191531,  79582],\n",
      "         [155492, 442608, 446511, 175560, 435016,  88942, 140342, 264309,\n",
      "           85102, 444612,  30209, 435604, 376525,  89578, 469190, 190409,\n",
      "          343863,   3214, 238398, 220121, 212294, 429705, 277539, 222287,\n",
      "          141415, 346367, 208836, 455031,  52372, 201398]],\n",
      "\n",
      "        [[228098, 331984, 152662, 263647,  83256, 219678, 187754, 196389,\n",
      "          463955,  63897, 394718, 284990, 120176, 222551, 296144, 172384,\n",
      "           24886, 432534,  56222, 421746, 234981, 264391, 306657,  73723,\n",
      "          228819, 322749,   7458,  91430, 175077, 265092],\n",
      "         [402969, 306105, 412227, 224527, 360667, 105952,  54124, 400486,\n",
      "          283493,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [229686,  66743,  72311, 400863, 313341, 149748, 406497,  76543,\n",
      "          160676,   9496, 455267, 433882,  19016, 180349, 336485, 334186,\n",
      "          264526, 204075, 112976,  53479, 265811, 321296, 252676, 366230,\n",
      "          150892, 151996, 398721, 388352, 262314, 366480],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0]]])}, 'candidate_spans': tensor([[[ 1,  1],\n",
      "         [ 3,  3],\n",
      "         [ 5,  5],\n",
      "         [ 6,  6]],\n",
      "\n",
      "        [[ 5,  5],\n",
      "         [ 6,  6],\n",
      "         [ 7,  7],\n",
      "         [-1, -1]]]), 'candidate_segment_ids': tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]])}, 'wordnet': {'candidate_entity_priors': tensor([[[8.7500e-01, 4.1667e-02, 4.1667e-02, 4.1667e-02, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [5.9948e-05, 1.7985e-04, 5.2155e-03, 4.2084e-02, 6.4403e-01,\n",
      "          1.1990e-04, 1.8104e-01, 1.1390e-02, 5.4073e-02, 1.6246e-02,\n",
      "          3.5370e-03, 5.9948e-05, 5.9948e-05, 4.1904e-02],\n",
      "         [1.2500e-01, 4.2500e-01, 1.2500e-01, 3.2500e-01, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [3.4483e-02, 3.4483e-02, 3.4483e-02, 6.8966e-01, 3.4483e-02,\n",
      "          1.3793e-01, 3.4483e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [9.1667e-01, 8.3333e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[5.9948e-05, 1.7985e-04, 5.2155e-03, 4.2084e-02, 6.4403e-01,\n",
      "          1.1990e-04, 1.8104e-01, 1.1390e-02, 5.4073e-02, 1.6246e-02,\n",
      "          3.5370e-03, 5.9948e-05, 5.9948e-05, 4.1904e-02],\n",
      "         [7.1429e-02, 7.1429e-02, 7.1429e-02, 7.1429e-02, 5.0000e-01,\n",
      "          7.1429e-02, 7.1429e-02, 7.1429e-02, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [5.4545e-01, 4.5455e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]), 'candidate_entities': {'ids': tensor([[[ 69879,  70932,  72779,  88729,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [100139, 115193, 116069, 116824, 116829, 116859, 116872, 116893,\n",
      "          117059, 117105, 117260, 117283, 117513, 117542],\n",
      "         [105908, 115280, 115517, 117247,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [  5322,   7060,  12915,  21652,  70598,  94671, 100184,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 69878,  81378,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0]],\n",
      "\n",
      "        [[100139, 115193, 116069, 116824, 116829, 116859, 116872, 116893,\n",
      "          117059, 117105, 117260, 117283, 117513, 117542],\n",
      "         [ 51586,  58620,  58620,  94597,  94722, 100516, 101215, 102734,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 21809,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [104985, 104987,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0]]])}, 'candidate_spans': tensor([[[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5]],\n",
      "\n",
      "        [[ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5],\n",
      "         [ 6,  6],\n",
      "         [-1, -1]]]), 'candidate_segment_ids': tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]])}}\n",
      "2022-06-10 09:31:50,245 - knowbert-logger.main - DEBUG - tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "2022-06-10 09:31:50,246 - knowbert-logger.main - DEBUG - None\n",
      "2022-06-10 09:31:50,246 - knowbert-logger.main - DEBUG - {}\n",
      "2022-06-10 09:31:50,248 - knowbert-logger.main - DEBUG - Bert input: tensor([[[ 0.0974, -0.1728, -0.5148,  ..., -0.0460,  0.1588,  0.2551],\n",
      "         [-0.1290, -0.7126, -0.2674,  ...,  0.7043, -0.3375, -0.3489],\n",
      "         [-0.6925, -0.0276, -0.2030,  ...,  0.7154,  0.4221,  0.5216],\n",
      "         ...,\n",
      "         [ 0.1584, -0.2734,  0.0200,  ...,  0.1369,  0.5977,  0.7679],\n",
      "         [-0.2248,  0.0184,  0.2232,  ..., -0.1836,  0.2169, -0.0617],\n",
      "         [-0.0060, -0.5670, -0.0231,  ..., -0.2658, -0.0586,  0.1345]],\n",
      "\n",
      "        [[ 0.0974, -0.1728, -0.5148,  ..., -0.0460,  0.1588,  0.2551],\n",
      "         [ 0.6432,  0.0046,  0.1032,  ...,  0.6983,  0.4975, -0.0302],\n",
      "         [-1.0352,  0.5055, -0.4117,  ...,  0.3484, -0.3857,  0.1405],\n",
      "         ...,\n",
      "         [ 0.3006, -0.5841, -0.6082,  ..., -0.6496,  0.9701, -1.2704],\n",
      "         [ 0.5469,  0.5442,  0.3720,  ...,  0.2318,  0.6092, -0.3432],\n",
      "         [-0.2513,  0.0318,  0.1341,  ..., -0.0310,  0.2259, -0.0830]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "2022-06-10 09:31:50,254 - knowbert-logger.main - DEBUG - Bert Layer9,0: tensor([[[ 0.0708,  0.0731, -0.0802,  ...,  0.0443,  0.0166,  0.0445],\n",
      "         [ 0.0876, -0.9155, -0.5138,  ...,  0.3291, -0.4104, -0.4374],\n",
      "         [-0.9307,  0.0097, -0.4335,  ...,  0.0653,  0.2175,  0.6369],\n",
      "         ...,\n",
      "         [-0.1945, -0.3811, -0.0922,  ..., -0.0626,  0.1121,  0.4325],\n",
      "         [-0.2202, -0.0210,  0.0388,  ...,  0.0151,  0.3112,  0.1303],\n",
      "         [ 0.2533, -0.8271,  0.4830,  ...,  0.0194, -0.1276,  0.0648]],\n",
      "\n",
      "        [[ 0.1446, -0.0307, -0.0810,  ...,  0.0507,  0.0281,  0.0169],\n",
      "         [ 1.1543, -0.1925,  0.1271,  ...,  0.5715,  0.2872, -0.3244],\n",
      "         [-0.9975,  0.3625, -0.4254,  ..., -0.4145, -0.8367,  0.0635],\n",
      "         ...,\n",
      "         [ 0.9455, -0.7382, -0.6312,  ..., -1.0652,  1.0495, -1.7214],\n",
      "         [ 0.8381, -0.1366,  0.6281,  ..., -0.3732,  0.3748, -0.4871],\n",
      "         [-0.0709,  0.1913,  0.1560,  ...,  0.1608,  0.4688, -0.0919]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "2022-06-10 09:31:50,261 - knowbert-logger.main - DEBUG - Bert Layer9,1: tensor([[[-0.2555, -0.2511, -0.3199,  ...,  0.0451,  0.1790,  0.0693],\n",
      "         [ 0.0295, -0.6895, -0.5565,  ...,  0.1541, -0.7562, -0.4717],\n",
      "         [-0.6019, -0.0888, -0.3354,  ..., -0.2014,  0.1894,  0.5556],\n",
      "         ...,\n",
      "         [-0.0672, -0.6538,  0.0663,  ..., -0.3654,  0.1508,  0.4350],\n",
      "         [-0.3587, -0.2746, -0.1585,  ...,  0.2028,  0.3839, -0.1232],\n",
      "         [ 0.2754, -1.4007,  0.3758,  ...,  0.4063,  0.1268,  0.2202]],\n",
      "\n",
      "        [[-0.1352, -0.1541, -0.2372,  ...,  0.0356,  0.1542,  0.0689],\n",
      "         [ 0.9494, -0.4640,  0.1889,  ...,  0.3764,  0.4387, -0.3019],\n",
      "         [-1.1685,  0.2138, -0.2318,  ..., -0.5397, -0.4283,  0.5446],\n",
      "         ...,\n",
      "         [ 1.4045, -0.3780, -0.4016,  ..., -1.1884,  0.9598, -1.4484],\n",
      "         [ 0.6791, -0.2942,  0.4251,  ..., -0.0634,  0.7559, -0.4878],\n",
      "         [-0.1723,  0.1487, -0.0056,  ...,  0.2050,  0.3865, -0.1468]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "2022-06-10 09:31:50,271 - knowbert-logger.main - DEBUG - Bert Layer9,2: tensor([[[-1.4435e-01, -6.1150e-01, -4.0238e-01,  ..., -4.1947e-02,\n",
      "           4.4499e-01,  4.1365e-01],\n",
      "         [ 1.4978e-01, -7.8488e-01, -2.8465e-01,  ..., -3.0524e-01,\n",
      "          -9.4036e-01, -7.6590e-01],\n",
      "         [-4.9672e-01, -3.3526e-01, -4.8272e-01,  ...,  1.8433e-01,\n",
      "           3.0509e-01,  9.0131e-01],\n",
      "         ...,\n",
      "         [-2.7785e-01, -7.0277e-01,  8.2094e-02,  ..., -2.3770e-01,\n",
      "           2.6891e-01,  5.2100e-01],\n",
      "         [-1.1920e-01, -7.2578e-02,  1.9791e-02,  ...,  8.5083e-02,\n",
      "           1.6088e-01,  3.7840e-02],\n",
      "         [ 3.6595e-01, -1.2312e+00,  5.4305e-01,  ...,  1.8536e-01,\n",
      "           1.3885e-01,  3.4634e-01]],\n",
      "\n",
      "        [[-7.5693e-02, -5.4236e-01, -3.2291e-01,  ..., -3.5353e-02,\n",
      "           3.9489e-01,  3.3513e-01],\n",
      "         [ 4.8989e-01, -1.1565e+00, -1.2151e-01,  ...,  4.9837e-01,\n",
      "          -6.5828e-02,  1.9490e-01],\n",
      "         [-1.3279e+00, -8.9916e-03, -1.7519e-01,  ..., -8.3848e-01,\n",
      "          -3.8308e-01,  5.5402e-01],\n",
      "         ...,\n",
      "         [ 1.5577e+00, -4.9551e-01, -6.0655e-01,  ..., -1.1785e+00,\n",
      "           1.2718e+00, -1.2983e+00],\n",
      "         [ 8.1529e-01, -7.8664e-02, -1.3274e-01,  ...,  5.7006e-02,\n",
      "           5.1907e-01, -3.1517e-01],\n",
      "         [-8.9806e-02,  9.5678e-04,  6.6934e-02,  ...,  8.2045e-02,\n",
      "           1.5707e-01,  3.1134e-02]]], grad_fn=<AddBackward0>)\n",
      "2022-06-10 09:31:50,279 - knowbert-logger.main - DEBUG - Bert Layer9,3: tensor([[[-1.3259e-01, -6.4447e-01, -1.1370e+00,  ...,  4.3024e-01,\n",
      "           1.0963e+00,  7.2757e-01],\n",
      "         [ 2.4111e-01, -6.9743e-01, -6.0758e-01,  ..., -1.3654e-01,\n",
      "          -1.2658e+00, -8.7757e-01],\n",
      "         [-8.9436e-01, -6.0487e-01, -5.1161e-01,  ...,  2.9953e-04,\n",
      "           5.3742e-01,  7.8752e-01],\n",
      "         ...,\n",
      "         [-3.2159e-01, -7.7116e-01, -3.0225e-03,  ..., -1.8596e-01,\n",
      "           3.1427e-01,  6.2231e-01],\n",
      "         [-5.1442e-02, -3.8340e-02,  1.5566e-03,  ...,  4.1860e-02,\n",
      "           3.8313e-02, -2.5145e-02],\n",
      "         [ 3.4961e-01, -1.1002e+00,  3.9205e-01,  ...,  1.5586e-01,\n",
      "           1.5704e-01,  3.6358e-01]],\n",
      "\n",
      "        [[-2.0538e-01, -8.3225e-02, -9.6789e-01,  ...,  3.8024e-01,\n",
      "           9.8255e-01,  7.5719e-01],\n",
      "         [ 2.5078e-01, -1.2594e+00,  1.2225e-01,  ...,  1.1899e-01,\n",
      "          -7.8027e-02,  5.7368e-03],\n",
      "         [-1.1943e+00, -1.1127e-01, -1.0680e-01,  ..., -5.1472e-01,\n",
      "          -7.4224e-01,  5.0405e-01],\n",
      "         ...,\n",
      "         [ 1.4002e+00, -3.2444e-01, -1.9645e-01,  ..., -8.1242e-01,\n",
      "           9.4617e-01, -1.2900e+00],\n",
      "         [ 6.0269e-01, -5.1815e-01, -2.1588e-01,  ..., -1.2963e-02,\n",
      "           4.3942e-01, -1.4308e-01],\n",
      "         [-5.1275e-02, -4.5092e-03,  2.8375e-02,  ...,  4.3497e-02,\n",
      "           5.7972e-02, -2.3901e-02]]], grad_fn=<AddBackward0>)\n",
      "2022-06-10 09:31:50,287 - knowbert-logger.main - DEBUG - Bert Layer9,4: tensor([[[ 0.0392, -0.5372, -0.3438,  ...,  0.5029,  0.7873,  0.8717],\n",
      "         [ 0.1588, -0.8098, -0.0584,  ..., -0.3118, -0.9411, -1.0073],\n",
      "         [-0.6815, -0.6305,  0.0078,  ..., -0.0310,  0.9863,  0.7542],\n",
      "         ...,\n",
      "         [-0.1982, -0.7446,  0.1894,  ..., -0.3558,  0.1693,  0.9572],\n",
      "         [-0.0388, -0.0362,  0.0491,  ...,  0.0303, -0.0036, -0.0249],\n",
      "         [ 0.2571, -0.5183,  0.5796,  ...,  0.2318,  0.6726,  0.5658]],\n",
      "\n",
      "        [[-0.2376, -0.3696, -0.1536,  ...,  0.2058,  1.0009,  1.0755],\n",
      "         [ 0.2650, -1.1000,  0.2785,  ...,  0.0279, -0.4098,  0.0763],\n",
      "         [-1.3962, -0.1818,  0.0502,  ..., -0.5353, -0.4263,  0.3116],\n",
      "         ...,\n",
      "         [ 1.4844, -0.1812, -0.1009,  ..., -0.7736,  0.9314, -1.1536],\n",
      "         [ 0.5320, -0.2685,  0.0615,  ..., -0.0395,  0.4681, -0.2140],\n",
      "         [-0.0331, -0.0350,  0.0425,  ...,  0.0256,  0.0113, -0.0124]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "2022-06-10 09:31:50,295 - knowbert-logger.main - DEBUG - Bert Layer9,5: tensor([[[-0.0598, -1.4417, -0.0360,  ...,  0.4341,  0.9675,  0.6542],\n",
      "         [ 0.1854, -0.7275, -0.3201,  ..., -0.1893, -0.5548, -0.8908],\n",
      "         [-0.9566, -0.6488, -0.2772,  ..., -0.3162,  0.5675,  1.1794],\n",
      "         ...,\n",
      "         [-0.4570, -1.1757,  0.1198,  ..., -0.5819,  0.4669,  1.0128],\n",
      "         [-0.0053, -0.0108,  0.0022,  ...,  0.0446, -0.0134, -0.0535],\n",
      "         [ 0.4886, -0.6110,  0.4386,  ...,  0.5703,  0.7522,  0.5554]],\n",
      "\n",
      "        [[-0.1969, -1.2224,  0.1045,  ...,  0.5452,  0.9041,  0.7821],\n",
      "         [ 0.2356, -1.0749,  0.1924,  ..., -0.0554, -0.2465, -0.2506],\n",
      "         [-1.6137, -0.3035,  0.0797,  ..., -0.7100, -0.3118, -0.0214],\n",
      "         ...,\n",
      "         [ 1.0175, -0.1025,  0.1401,  ..., -0.8464,  1.3334, -1.7984],\n",
      "         [ 0.3059,  0.0707, -0.1958,  ..., -0.1633,  0.3798, -0.6448],\n",
      "         [-0.0076, -0.0111,  0.0140,  ...,  0.0516, -0.0047, -0.0599]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "2022-06-10 09:31:50,301 - knowbert-logger.main - DEBUG - Bert Layer9,6: tensor([[[-1.3993e-01, -1.2918e+00, -2.7140e-01,  ...,  2.9629e-01,\n",
      "           1.2560e+00,  7.2380e-01],\n",
      "         [ 5.6456e-01, -4.9520e-01, -3.5248e-01,  ..., -2.5293e-01,\n",
      "          -4.8717e-01, -9.0292e-01],\n",
      "         [-1.1137e-01, -5.4204e-01, -5.8883e-01,  ...,  7.3074e-02,\n",
      "           9.5540e-02,  1.3386e+00],\n",
      "         ...,\n",
      "         [-3.1481e-01, -9.4609e-01,  8.9711e-02,  ..., -4.6887e-01,\n",
      "           6.4886e-01,  1.0903e+00],\n",
      "         [ 1.9374e-02, -8.2017e-04, -1.7054e-02,  ...,  3.2487e-02,\n",
      "           4.4894e-02, -5.2544e-02],\n",
      "         [ 4.0700e-01, -4.8240e-01,  2.3088e-01,  ...,  8.0917e-01,\n",
      "           8.8962e-01,  6.0661e-01]],\n",
      "\n",
      "        [[ 8.1462e-02, -3.7223e-01,  1.1318e-01,  ..., -6.3443e-02,\n",
      "           1.8929e-01,  6.3463e-01],\n",
      "         [-5.9166e-02, -1.2288e+00,  3.1600e-01,  ..., -4.2700e-01,\n",
      "           1.4037e-01, -1.5808e-01],\n",
      "         [-1.5958e+00, -1.1003e-01,  4.1398e-01,  ..., -6.1968e-01,\n",
      "          -1.6006e-01,  1.1835e-01],\n",
      "         ...,\n",
      "         [ 7.7187e-01,  2.8527e-01,  2.6150e-01,  ..., -7.8029e-01,\n",
      "           1.4477e+00, -2.0773e+00],\n",
      "         [ 5.6379e-01, -3.0666e-02, -5.0613e-02,  ..., -2.0659e-01,\n",
      "           4.3297e-01, -8.2932e-01],\n",
      "         [ 1.4339e-02,  2.9022e-02,  1.9490e-02,  ...,  3.7147e-02,\n",
      "           5.5977e-02, -5.6069e-02]]], grad_fn=<AddBackward0>)\n",
      "2022-06-10 09:31:50,307 - knowbert-logger.main - DEBUG - Bert Layer9,7: tensor([[[ 1.6467e-01, -7.2423e-01, -4.2206e-01,  ..., -2.6135e-02,\n",
      "           1.1172e+00,  6.8627e-01],\n",
      "         [ 2.0295e-01, -2.3318e-01,  2.8549e-02,  ..., -5.6371e-01,\n",
      "          -2.0570e-01, -5.4236e-01],\n",
      "         [-1.2520e-01, -2.2337e-01, -6.0608e-01,  ..., -2.4304e-01,\n",
      "           5.9030e-01,  9.5398e-01],\n",
      "         ...,\n",
      "         [-2.9662e-01, -6.2402e-01,  1.4616e-01,  ..., -1.0764e+00,\n",
      "           7.3939e-01,  8.0178e-01],\n",
      "         [ 5.6786e-02,  3.5941e-02,  1.3739e-03,  ..., -2.3249e-02,\n",
      "          -1.6908e-02, -1.0095e-01],\n",
      "         [ 4.9643e-01, -2.9056e-02,  3.9494e-01,  ...,  2.3867e-01,\n",
      "           1.0561e+00,  2.6537e-01]],\n",
      "\n",
      "        [[ 2.3206e-01, -6.7849e-01, -2.3359e-02,  ...,  6.8983e-01,\n",
      "          -6.6310e-02,  3.8769e-01],\n",
      "         [-4.5455e-02, -8.1446e-01,  6.0847e-01,  ..., -5.4774e-01,\n",
      "           3.5902e-01, -1.6903e-01],\n",
      "         [-1.8224e+00, -3.6483e-01,  3.1899e-01,  ..., -5.0559e-01,\n",
      "           1.0619e-02,  1.8654e-01],\n",
      "         ...,\n",
      "         [ 5.3234e-01,  6.7169e-01,  8.0950e-01,  ..., -2.1048e-01,\n",
      "           6.8761e-01, -2.3530e+00],\n",
      "         [ 6.8012e-01,  6.3625e-01, -1.4960e-01,  ..., -8.2588e-01,\n",
      "           4.6766e-01, -6.3217e-01],\n",
      "         [ 4.4209e-02,  4.4785e-02,  1.7870e-02,  ..., -4.4815e-02,\n",
      "          -1.7631e-02, -8.0267e-02]]], grad_fn=<AddBackward0>)\n",
      "2022-06-10 09:31:50,313 - knowbert-logger.main - DEBUG - Bert Layer9,8: tensor([[[ 0.0251, -0.3793, -0.7095,  ..., -0.3447,  0.9433,  1.2476],\n",
      "         [ 0.0040, -0.2045,  0.2568,  ..., -0.4577,  0.3733, -0.5189],\n",
      "         [-0.7649, -0.1306, -0.1968,  ..., -0.1621,  0.5700,  1.0786],\n",
      "         ...,\n",
      "         [-0.1246, -0.6723, -0.1573,  ..., -0.9598,  0.8249,  0.6653],\n",
      "         [ 0.0151,  0.0055,  0.0093,  ..., -0.0719,  0.0191, -0.0838],\n",
      "         [ 0.2928, -0.0107,  0.5349,  ...,  0.2147,  1.0434,  0.1570]],\n",
      "\n",
      "        [[ 0.3658, -0.0383,  0.4672,  ...,  0.4208, -0.4733,  0.6793],\n",
      "         [ 0.0834, -0.5919,  0.3740,  ..., -0.3526,  0.3376,  0.3777],\n",
      "         [-1.5478, -0.2667,  0.2774,  ..., -0.5927,  0.0554,  0.8180],\n",
      "         ...,\n",
      "         [ 0.6228,  0.4200,  1.0100,  ...,  0.1008,  0.5864, -2.4279],\n",
      "         [ 1.0113,  0.6534,  0.2171,  ..., -0.7661,  0.3696, -0.6888],\n",
      "         [ 0.0857,  0.0300, -0.0037,  ..., -0.0697, -0.0232, -0.0567]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "2022-06-10 09:31:50,319 - knowbert-logger.main - DEBUG - Bert Layer9,9: tensor([[[ 2.0643e-01, -6.3983e-01, -8.3226e-01,  ..., -3.5950e-01,\n",
      "           1.1362e+00,  2.0098e+00],\n",
      "         [-1.3785e-01, -4.3367e-01,  6.8766e-01,  ..., -1.4187e+00,\n",
      "           8.3835e-01, -1.4458e+00],\n",
      "         [-1.3604e+00, -5.8499e-01,  5.0907e-01,  ..., -8.8968e-01,\n",
      "           8.2104e-01,  1.3063e+00],\n",
      "         ...,\n",
      "         [ 7.9772e-02, -1.4246e-01,  1.0876e-01,  ..., -1.5529e-01,\n",
      "           3.8923e-01, -8.9395e-02],\n",
      "         [-5.7044e-03,  1.2786e-02,  7.1118e-02,  ...,  1.5084e-01,\n",
      "           1.3351e-01, -1.1882e-01],\n",
      "         [ 1.6352e-01,  1.5328e-01,  9.1605e-01,  ..., -9.5139e-02,\n",
      "           1.8134e+00, -1.6336e-01]],\n",
      "\n",
      "        [[ 1.1862e+00, -4.7038e-01,  6.0179e-01,  ...,  1.0515e+00,\n",
      "          -4.6322e-01,  1.4725e+00],\n",
      "         [-3.7706e-01, -7.9152e-01,  6.6299e-01,  ..., -2.9390e-01,\n",
      "           9.6243e-01,  2.6879e-03],\n",
      "         [-2.3120e+00, -3.4897e-01,  3.8884e-01,  ..., -7.8301e-01,\n",
      "           4.7877e-01,  8.6015e-01],\n",
      "         ...,\n",
      "         [ 7.7186e-01,  3.1978e-01,  9.9973e-01,  ..., -1.6615e-01,\n",
      "           7.2217e-01, -4.0689e+00],\n",
      "         [ 8.0697e-01,  1.3126e-01,  5.5930e-01,  ..., -1.0646e+00,\n",
      "           8.2438e-01, -7.7529e-01],\n",
      "         [ 1.7807e-02,  6.0935e-03, -1.0170e-01,  ...,  2.7520e-01,\n",
      "           8.2559e-02, -1.6395e-01]]], grad_fn=<AddBackward0>)\n",
      "2022-06-10 09:31:50,321 - knowbert-logger.main - DEBUG - candidate_entities: tensor([[[ 61415, 186436, 156993, 388347, 212590,  96609, 288567, 439001,\n",
      "          190664, 283891, 255997, 393971, 310206,  95850, 133157, 464732,\n",
      "          377698, 331564, 368041, 210960, 204580, 297113, 151039, 294839,\n",
      "           25989, 364799, 378739, 348909, 228856, 408537],\n",
      "         [217306, 208363, 195501, 398949, 272844,  78700, 434051, 459855,\n",
      "           36386, 301496, 118479, 419394,  31593,  54692, 435604, 410440,\n",
      "           82294, 164716, 314418,  93380, 443994,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [   624, 242805,  55193, 401811, 230615, 195592, 393357, 231251,\n",
      "          321038, 384279, 171717, 438345, 292339, 197367, 149353, 270081,\n",
      "          302841, 426462, 231910, 126378, 313191, 310722,  12985, 443631,\n",
      "          221456, 124550, 291887, 366929, 191531,  79582],\n",
      "         [155492, 442608, 446511, 175560, 435016,  88942, 140342, 264309,\n",
      "           85102, 444612,  30209, 435604, 376525,  89578, 469190, 190409,\n",
      "          343863,   3214, 238398, 220121, 212294, 429705, 277539, 222287,\n",
      "          141415, 346367, 208836, 455031,  52372, 201398]],\n",
      "\n",
      "        [[228098, 331984, 152662, 263647,  83256, 219678, 187754, 196389,\n",
      "          463955,  63897, 394718, 284990, 120176, 222551, 296144, 172384,\n",
      "           24886, 432534,  56222, 421746, 234981, 264391, 306657,  73723,\n",
      "          228819, 322749,   7458,  91430, 175077, 265092],\n",
      "         [402969, 306105, 412227, 224527, 360667, 105952,  54124, 400486,\n",
      "          283493,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [229686,  66743,  72311, 400863, 313341, 149748, 406497,  76543,\n",
      "          160676,   9496, 455267, 433882,  19016, 180349, 336485, 334186,\n",
      "          264526, 204075, 112976,  53479, 265811, 321296, 252676, 366230,\n",
      "          150892, 151996, 398721, 388352, 262314, 366480],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0]]])\n",
      "2022-06-10 09:31:50,325 - knowbert-logger.main - DEBUG - candidate_entity_embeddings: tensor([[[[-0.0255,  0.0321,  0.0877,  ...,  0.0598, -0.0211, -0.0635],\n",
      "          [ 0.0907,  0.0830,  0.0120,  ..., -0.0361, -0.0723, -0.0071],\n",
      "          [-0.0266, -0.0096, -0.0562,  ...,  0.0309, -0.1075, -0.0596],\n",
      "          ...,\n",
      "          [ 0.0064,  0.0599,  0.1008,  ...,  0.1054, -0.0783, -0.0191],\n",
      "          [ 0.0046, -0.0377,  0.0182,  ...,  0.0399,  0.0077, -0.0726],\n",
      "          [-0.0105, -0.0418,  0.0007,  ...,  0.0227, -0.0061, -0.0437]],\n",
      "\n",
      "         [[-0.0318, -0.0682,  0.0722,  ...,  0.0543,  0.0342,  0.0221],\n",
      "          [-0.0708,  0.0138,  0.0546,  ..., -0.0117, -0.0537, -0.1367],\n",
      "          [ 0.0061,  0.0321, -0.0254,  ...,  0.0276,  0.0012, -0.0809],\n",
      "          ...,\n",
      "          [-0.0545, -0.1143,  0.0318,  ..., -0.1121, -0.0630,  0.0189],\n",
      "          [-0.0545, -0.1143,  0.0318,  ..., -0.1121, -0.0630,  0.0189],\n",
      "          [-0.0545, -0.1143,  0.0318,  ..., -0.1121, -0.0630,  0.0189]],\n",
      "\n",
      "         [[ 0.0217, -0.0132,  0.1147,  ...,  0.0500, -0.0153, -0.0467],\n",
      "          [-0.0463,  0.0467,  0.1267,  ...,  0.0269, -0.0480, -0.0320],\n",
      "          [-0.0519,  0.0352,  0.0805,  ..., -0.0025, -0.0830, -0.1211],\n",
      "          ...,\n",
      "          [-0.0840, -0.0589,  0.0987,  ..., -0.0846,  0.0144, -0.0795],\n",
      "          [ 0.1048, -0.0225,  0.0149,  ..., -0.0449,  0.0203, -0.0077],\n",
      "          [-0.0114,  0.0184,  0.1494,  ...,  0.0141, -0.0563,  0.0173]],\n",
      "\n",
      "         [[-0.0117, -0.0478,  0.1210,  ...,  0.0144, -0.1481, -0.0391],\n",
      "          [-0.0084,  0.0504,  0.0980,  ...,  0.1030, -0.0088,  0.0411],\n",
      "          [-0.0263,  0.0202,  0.1366,  ...,  0.0438, -0.0051, -0.0036],\n",
      "          ...,\n",
      "          [-0.0570, -0.0464,  0.0852,  ...,  0.0549, -0.0566, -0.0932],\n",
      "          [ 0.0123, -0.0041,  0.1032,  ...,  0.0332,  0.0466, -0.0482],\n",
      "          [-0.0208, -0.0343, -0.0130,  ...,  0.0238, -0.0397,  0.0828]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0661, -0.0398,  0.1252,  ..., -0.0430, -0.0906, -0.0093],\n",
      "          [ 0.1032,  0.0696,  0.0965,  ...,  0.0048, -0.0692, -0.0142],\n",
      "          [ 0.0567, -0.0714,  0.1147,  ...,  0.0530, -0.0395, -0.0738],\n",
      "          ...,\n",
      "          [-0.0159,  0.0334, -0.0291,  ...,  0.0394, -0.0361, -0.0390],\n",
      "          [ 0.0220,  0.0039,  0.0394,  ...,  0.0099,  0.0032, -0.0587],\n",
      "          [ 0.0241, -0.0217, -0.0014,  ...,  0.0361, -0.0661, -0.0780]],\n",
      "\n",
      "         [[-0.0237, -0.0537,  0.0109,  ...,  0.0013, -0.1025, -0.0863],\n",
      "          [-0.0236, -0.0580,  0.0284,  ...,  0.0771, -0.1283, -0.0322],\n",
      "          [ 0.0876, -0.0644,  0.0087,  ...,  0.0199, -0.0644, -0.0777],\n",
      "          ...,\n",
      "          [-0.0545, -0.1143,  0.0318,  ..., -0.1121, -0.0630,  0.0189],\n",
      "          [-0.0545, -0.1143,  0.0318,  ..., -0.1121, -0.0630,  0.0189],\n",
      "          [-0.0545, -0.1143,  0.0318,  ..., -0.1121, -0.0630,  0.0189]],\n",
      "\n",
      "         [[ 0.0554,  0.0143,  0.0249,  ...,  0.0693, -0.0303, -0.0475],\n",
      "          [-0.0710, -0.0646, -0.0076,  ..., -0.0444,  0.0204, -0.0508],\n",
      "          [-0.0372,  0.0425,  0.0218,  ...,  0.0439, -0.0613, -0.0779],\n",
      "          ...,\n",
      "          [-0.0538,  0.0155, -0.0024,  ...,  0.0069, -0.0225, -0.0709],\n",
      "          [ 0.0124, -0.0045,  0.0946,  ...,  0.0113, -0.0651,  0.0105],\n",
      "          [-0.0478, -0.0078,  0.0516,  ...,  0.0120,  0.0391,  0.0024]],\n",
      "\n",
      "         [[-0.0545, -0.1143,  0.0318,  ..., -0.1121, -0.0630,  0.0189],\n",
      "          [-0.0545, -0.1143,  0.0318,  ..., -0.1121, -0.0630,  0.0189],\n",
      "          [-0.0545, -0.1143,  0.0318,  ..., -0.1121, -0.0630,  0.0189],\n",
      "          ...,\n",
      "          [-0.0545, -0.1143,  0.0318,  ..., -0.1121, -0.0630,  0.0189],\n",
      "          [-0.0545, -0.1143,  0.0318,  ..., -0.1121, -0.0630,  0.0189],\n",
      "          [-0.0545, -0.1143,  0.0318,  ..., -0.1121, -0.0630,  0.0189]]]])\n",
      "2022-06-10 09:31:50,332 - knowbert-logger.main - DEBUG - KG Layer: tensor([[[ 0.1673, -0.4086, -0.5686,  ..., -0.1912,  0.8125,  0.7367],\n",
      "         [ 0.0414, -0.4255,  0.6228,  ..., -1.1679,  0.7202, -0.4505],\n",
      "         [-1.2010, -0.5325,  0.5541,  ..., -0.5031,  0.8208,  0.9287],\n",
      "         ...,\n",
      "         [ 0.0587, -0.0519,  0.0627,  ..., -0.0761,  0.1676, -0.4507],\n",
      "         [ 0.0339,  0.0238,  0.0150,  ..., -0.0166, -0.0046, -0.5009],\n",
      "         [ 0.1152,  0.2003,  0.9610,  ..., -0.0664,  1.4924,  0.2881]],\n",
      "\n",
      "        [[ 1.2331, -0.3093,  0.5649,  ...,  0.9330, -0.3152,  0.9040],\n",
      "         [-0.3361, -0.6210,  0.7103,  ..., -0.2832,  1.0034,  0.3234],\n",
      "         [-2.0649, -0.1876,  0.4528,  ..., -0.6618,  0.4176,  0.5656],\n",
      "         ...,\n",
      "         [ 0.7717,  0.2340,  0.8775,  ..., -0.0895,  0.6990, -1.5151],\n",
      "         [ 0.8436,  0.2331,  0.6149,  ..., -0.8869,  0.8424,  0.0246],\n",
      "         [ 0.0969,  0.1041, -0.0171,  ...,  0.0684,  0.0786, -0.4829]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "2022-06-10 09:31:50,338 - knowbert-logger.main - DEBUG - Bert Layer10,0: tensor([[[-0.0937,  0.0345,  0.2128,  ..., -0.4893,  0.9809,  0.6015],\n",
      "         [-0.4318, -0.7357,  0.3991,  ..., -1.8342,  0.6745, -0.3795],\n",
      "         [-1.6585, -1.1068,  0.2109,  ..., -0.4201,  1.1544,  0.4394],\n",
      "         ...,\n",
      "         [-0.0958, -0.1241,  0.4585,  ...,  0.1681,  0.2336, -0.5825],\n",
      "         [-0.1073, -0.0620,  0.4799,  ...,  0.1221,  0.2547, -0.5762],\n",
      "         [-0.3405, -0.1946,  0.8284,  ..., -0.0708,  1.7176,  0.2810]],\n",
      "\n",
      "        [[ 1.1722, -0.1976,  0.9810,  ...,  1.0609, -0.3202,  1.4595],\n",
      "         [-0.5636, -0.7402,  0.7260,  ..., -0.2094,  0.7432,  0.2783],\n",
      "         [-2.4274,  0.0611,  0.0167,  ..., -0.6192,  0.5627,  0.3168],\n",
      "         ...,\n",
      "         [ 0.4604, -0.1171,  0.9921,  ..., -0.0614,  0.6962, -2.9847],\n",
      "         [ 0.4533,  0.0999,  0.1552,  ..., -0.6373,  0.5447, -0.9568],\n",
      "         [-0.0177, -0.0945,  0.3684,  ...,  0.2228,  0.1933, -0.5660]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "2022-06-10 09:31:50,339 - knowbert-logger.main - DEBUG - candidate_entities: tensor([[[ 69879,  70932,  72779,  88729,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [100139, 115193, 116069, 116824, 116829, 116859, 116872, 116893,\n",
      "          117059, 117105, 117260, 117283, 117513, 117542],\n",
      "         [105908, 115280, 115517, 117247,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [  5322,   7060,  12915,  21652,  70598,  94671, 100184,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 69878,  81378,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0]],\n",
      "\n",
      "        [[100139, 115193, 116069, 116824, 116829, 116859, 116872, 116893,\n",
      "          117059, 117105, 117260, 117283, 117513, 117542],\n",
      "         [ 51586,  58620,  58620,  94597,  94722, 100516, 101215, 102734,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 21809,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [104985, 104987,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0]]])\n",
      "2022-06-10 09:31:50,340 - knowbert-logger.wordnet - DEBUG - tensor([[ 0.0889,  0.1013, -0.1155,  ..., -0.0548,  0.0735, -0.0570],\n",
      "        [ 0.0360,  0.0962, -0.1832,  ...,  0.0745,  0.0099,  0.1055],\n",
      "        [ 0.0360,  0.0962, -0.1832,  ...,  0.0745,  0.0099,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0950,  0.0180, -0.0320,  ..., -0.1098,  0.0654, -0.1420],\n",
      "        [ 0.0950,  0.0180, -0.0320,  ..., -0.1098,  0.0654, -0.1420],\n",
      "        [ 0.0950,  0.0180, -0.0320,  ..., -0.1098,  0.0654, -0.1420]],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "2022-06-10 09:31:50,347 - knowbert-logger.main - DEBUG - candidate_entity_embeddings: tensor([[[[-0.0817,  0.4249, -0.3387,  ...,  0.2686, -0.0864, -0.0907],\n",
      "          [ 0.6915,  0.3836,  0.0078,  ..., -0.0098, -0.1751, -0.6107],\n",
      "          [ 0.2105, -0.4902,  0.0204,  ..., -0.3849, -0.3807,  0.5122],\n",
      "          ...,\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345]],\n",
      "\n",
      "         [[-0.1635, -0.1528, -0.3440,  ..., -0.8364,  0.1483,  0.5833],\n",
      "          [-0.0459, -0.1142, -0.7877,  ...,  0.0529,  0.1255,  0.0296],\n",
      "          [-0.0825,  0.2039, -0.5391,  ...,  0.0075,  0.2209,  0.3807],\n",
      "          ...,\n",
      "          [-0.2391,  0.2269,  0.0168,  ...,  0.1142,  0.0541,  0.2620],\n",
      "          [-0.2492, -0.2958, -0.0997,  ..., -0.2630, -0.0964,  0.0019],\n",
      "          [ 0.2459,  0.0905, -0.2263,  ..., -0.1467, -0.3209, -0.1027]],\n",
      "\n",
      "         [[-0.3705,  0.3051, -0.3293,  ..., -0.0401, -0.5880,  0.3661],\n",
      "          [ 0.2762, -0.2898,  0.1991,  ..., -0.0260, -0.1907, -0.1070],\n",
      "          [ 0.1898, -0.1399,  0.1436,  ...,  0.0574,  0.2798, -0.1545],\n",
      "          ...,\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345]],\n",
      "\n",
      "         [[ 0.0534,  0.6854, -0.3359,  ...,  0.1767,  0.2818,  0.1039],\n",
      "          [ 0.1705, -0.2201, -0.3064,  ..., -0.1320, -0.1078,  0.1756],\n",
      "          [ 0.6812,  0.1202,  0.4540,  ..., -0.1792, -0.0927,  0.0286],\n",
      "          ...,\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345]],\n",
      "\n",
      "         [[ 0.1429, -0.4828, -0.2640,  ...,  0.9575, -0.1044, -0.2634],\n",
      "          [ 0.4786,  1.3320, -0.8275,  ..., -0.0631,  0.3333,  0.6313],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          ...,\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345]]],\n",
      "\n",
      "\n",
      "        [[[-0.1635, -0.1528, -0.3440,  ..., -0.8364,  0.1483,  0.5833],\n",
      "          [-0.0459, -0.1142, -0.7877,  ...,  0.0529,  0.1255,  0.0296],\n",
      "          [-0.0825,  0.2039, -0.5391,  ...,  0.0075,  0.2209,  0.3807],\n",
      "          ...,\n",
      "          [-0.2391,  0.2269,  0.0168,  ...,  0.1142,  0.0541,  0.2620],\n",
      "          [-0.2492, -0.2958, -0.0997,  ..., -0.2630, -0.0964,  0.0019],\n",
      "          [ 0.2459,  0.0905, -0.2263,  ..., -0.1467, -0.3209, -0.1027]],\n",
      "\n",
      "         [[ 0.4265, -0.4030, -1.0881,  ..., -0.1281,  0.0699, -0.2353],\n",
      "          [-0.5277, -0.5727,  0.0743,  ..., -0.2556, -0.5565, -0.5039],\n",
      "          [-0.5277, -0.5727,  0.0743,  ..., -0.2556, -0.5565, -0.5039],\n",
      "          ...,\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345]],\n",
      "\n",
      "         [[ 0.0328,  0.2959, -1.0510,  ...,  0.3281, -0.4710, -0.3794],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          ...,\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345]],\n",
      "\n",
      "         [[-0.1416,  0.0545, -0.1358,  ..., -0.2433, -0.0190, -0.4950],\n",
      "          [-0.6484, -0.2741, -0.3047,  ..., -0.1833,  0.2991,  0.0976],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          ...,\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345]],\n",
      "\n",
      "         [[-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          ...,\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345],\n",
      "          [-0.1009,  0.1045,  0.0371,  ..., -0.0673,  0.0896, -0.1345]]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "2022-06-10 09:31:50,361 - knowbert-logger.main - DEBUG - KG Layer: tensor([[[-0.1648,  0.2433,  0.0817,  ..., -0.3590,  0.7549,  0.3592],\n",
      "         [-0.3088, -0.4141,  0.1348,  ..., -1.5046,  0.7170, -0.2699],\n",
      "         [-1.4991, -0.8560,  0.1149,  ..., -0.3281,  1.2647,  0.5862],\n",
      "         ...,\n",
      "         [ 0.0207,  0.0286,  0.0395,  ...,  0.0054,  0.0128, -0.1372],\n",
      "         [ 0.0201,  0.0405,  0.0391,  ..., -0.0036,  0.0139, -0.1345],\n",
      "         [-0.4259, -0.1907,  0.5224,  ..., -0.2055,  1.7140,  0.1512]],\n",
      "\n",
      "        [[ 1.4636, -0.4772,  0.8898,  ...,  0.9099, -0.4147,  0.9782],\n",
      "         [-0.4584, -0.5452,  0.6058,  ..., -0.3264,  0.7767,  0.1790],\n",
      "         [-2.0013,  0.0397, -0.1843,  ..., -0.6263,  0.5096,  0.2478],\n",
      "         ...,\n",
      "         [ 0.6697,  0.0424,  0.8306,  ..., -0.0549,  0.6018, -2.4509],\n",
      "         [ 0.3231,  0.2289, -0.1504,  ..., -0.9159,  0.6401, -0.9244],\n",
      "         [ 0.1279,  0.0276,  0.0124,  ...,  0.0126, -0.0451, -0.0216]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "2022-06-10 09:31:50,368 - knowbert-logger.main - DEBUG - Bert Layer11,0: tensor([[[-0.2191,  0.0469,  0.3313,  ..., -0.1035,  0.4215,  0.0816],\n",
      "         [-0.2557, -0.3025,  0.3482,  ..., -0.8384,  0.2088, -0.1212],\n",
      "         [-0.7448, -0.2799,  0.1577,  ..., -0.1018,  0.5554,  0.1610],\n",
      "         ...,\n",
      "         [-0.1899, -0.0831,  0.3375,  ..., -0.2673,  0.3587, -0.3385],\n",
      "         [-0.1916, -0.0494,  0.3349,  ..., -0.2962,  0.3412, -0.3320],\n",
      "         [-0.3173, -0.0397,  0.3969,  ..., -0.1223,  0.7033,  0.1718]],\n",
      "\n",
      "        [[ 0.9990, -0.0845,  0.7059,  ...,  0.8191,  0.0556,  0.1988],\n",
      "         [-0.1391, -0.1822,  0.2163,  ...,  0.1031,  0.7076, -0.1632],\n",
      "         [-0.8084,  0.1797, -0.0894,  ..., -0.3327,  0.2993,  0.1269],\n",
      "         ...,\n",
      "         [ 0.3399, -0.0032,  0.6638,  ..., -0.1124,  0.0432, -1.2237],\n",
      "         [ 0.0315,  0.1576,  0.2010,  ...,  0.0202,  0.0044, -0.5098],\n",
      "         [ 0.5316,  0.3982,  0.8043,  ...,  0.2626,  0.1034, -0.3791]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "2022-06-10 09:31:50,369 - knowbert-logger - INFO - {'wiki': {'entity_attention_probs': tensor([[[[1.7156e-01, 8.9533e-02, 6.7579e-01, 6.3125e-02],\n",
      "          [5.2613e-01, 1.6096e-01, 1.8986e-01, 1.2304e-01],\n",
      "          [4.9681e-01, 1.1624e-01, 2.8177e-01, 1.0519e-01],\n",
      "          [9.4205e-02, 4.8835e-01, 3.1223e-01, 1.0522e-01],\n",
      "          [6.0727e-02, 3.7283e-01, 4.7930e-01, 8.7143e-02],\n",
      "          [4.2987e-02, 1.8406e-01, 7.3316e-01, 3.9793e-02],\n",
      "          [2.2592e-01, 9.6647e-02, 5.8767e-01, 8.9765e-02],\n",
      "          [3.0059e-01, 1.1698e-01, 5.0093e-01, 8.1506e-02],\n",
      "          [1.2149e-01, 1.3010e-01, 7.2902e-01, 1.9392e-02]],\n",
      "\n",
      "         [[3.8330e-02, 3.0528e-01, 5.5875e-01, 9.7637e-02],\n",
      "          [9.9112e-01, 2.1545e-03, 4.5585e-03, 2.1688e-03],\n",
      "          [1.4829e-02, 7.7607e-01, 1.8095e-01, 2.8153e-02],\n",
      "          [1.3698e-02, 7.9087e-01, 1.9101e-01, 4.4181e-03],\n",
      "          [1.6195e-02, 1.5730e-01, 8.1204e-01, 1.4462e-02],\n",
      "          [1.0653e-02, 1.7037e-02, 9.6469e-01, 7.6228e-03],\n",
      "          [2.8705e-01, 2.1491e-01, 3.3681e-01, 1.6123e-01],\n",
      "          [4.9925e-01, 1.3923e-01, 3.0296e-01, 5.8559e-02],\n",
      "          [1.9691e-02, 3.7569e-01, 1.4643e-01, 4.5819e-01]],\n",
      "\n",
      "         [[1.2903e-01, 3.0195e-01, 2.2095e-01, 3.4808e-01],\n",
      "          [3.3476e-01, 1.9876e-01, 1.3540e-01, 3.3109e-01],\n",
      "          [1.0349e-01, 5.6801e-01, 2.1254e-01, 1.1596e-01],\n",
      "          [3.8118e-02, 4.8420e-01, 4.0054e-01, 7.7149e-02],\n",
      "          [1.5245e-01, 1.3083e-01, 6.2564e-01, 9.1089e-02],\n",
      "          [3.0228e-02, 2.2058e-01, 4.9819e-01, 2.5100e-01],\n",
      "          [1.7870e-01, 3.7101e-01, 2.1734e-01, 2.3295e-01],\n",
      "          [1.6612e-01, 4.2819e-01, 2.2145e-01, 1.8424e-01],\n",
      "          [4.4913e-01, 2.8156e-01, 1.5808e-01, 1.1123e-01]],\n",
      "\n",
      "         [[7.2683e-02, 4.4500e-01, 3.2411e-01, 1.5821e-01],\n",
      "          [9.3982e-01, 5.4263e-03, 3.1676e-02, 2.3075e-02],\n",
      "          [6.8294e-02, 7.2953e-01, 1.4216e-01, 6.0022e-02],\n",
      "          [6.1594e-03, 8.8139e-01, 9.5911e-02, 1.6542e-02],\n",
      "          [4.8831e-02, 3.7722e-01, 5.4046e-01, 3.3484e-02],\n",
      "          [6.6546e-02, 4.0016e-02, 8.5549e-01, 3.7949e-02],\n",
      "          [2.0709e-01, 2.4477e-01, 2.7749e-01, 2.7066e-01],\n",
      "          [3.7710e-01, 1.8830e-01, 2.9416e-01, 1.4044e-01],\n",
      "          [1.4130e-01, 2.7781e-01, 2.9044e-01, 2.9045e-01]]],\n",
      "\n",
      "\n",
      "        [[[2.5608e-01, 3.1473e-01, 4.2919e-01, 0.0000e+00],\n",
      "          [3.4628e-01, 2.7346e-01, 3.8026e-01, 0.0000e+00],\n",
      "          [1.1264e-01, 6.1276e-01, 2.7460e-01, 0.0000e+00],\n",
      "          [4.4537e-01, 3.4762e-01, 2.0702e-01, 0.0000e+00],\n",
      "          [5.3402e-01, 3.5125e-01, 1.1472e-01, 0.0000e+00],\n",
      "          [9.5379e-01, 3.6904e-02, 9.3067e-03, 0.0000e+00],\n",
      "          [7.4096e-01, 2.5179e-01, 7.2571e-03, 0.0000e+00],\n",
      "          [5.2774e-02, 3.9854e-01, 5.4869e-01, 0.0000e+00],\n",
      "          [3.7228e-01, 2.5419e-01, 3.7354e-01, 0.0000e+00]],\n",
      "\n",
      "         [[2.6258e-01, 3.8793e-01, 3.4949e-01, 0.0000e+00],\n",
      "          [7.6667e-01, 2.1225e-01, 2.1083e-02, 0.0000e+00],\n",
      "          [1.0383e-01, 8.0364e-01, 9.2529e-02, 0.0000e+00],\n",
      "          [6.7022e-01, 2.7639e-01, 5.3390e-02, 0.0000e+00],\n",
      "          [7.4766e-01, 2.2737e-01, 2.4969e-02, 0.0000e+00],\n",
      "          [9.8922e-01, 8.9745e-03, 1.8012e-03, 0.0000e+00],\n",
      "          [5.9222e-04, 9.9700e-01, 2.4088e-03, 0.0000e+00],\n",
      "          [1.6676e-04, 2.0906e-04, 9.9962e-01, 0.0000e+00],\n",
      "          [1.5484e-01, 2.8292e-01, 5.6224e-01, 0.0000e+00]],\n",
      "\n",
      "         [[6.5471e-01, 2.1636e-01, 1.2892e-01, 0.0000e+00],\n",
      "          [3.0608e-01, 6.3258e-01, 6.1336e-02, 0.0000e+00],\n",
      "          [5.5596e-01, 3.1390e-01, 1.3014e-01, 0.0000e+00],\n",
      "          [8.2687e-01, 1.1376e-01, 5.9366e-02, 0.0000e+00],\n",
      "          [7.6964e-01, 6.9887e-02, 1.6047e-01, 0.0000e+00],\n",
      "          [3.1056e-01, 6.2092e-01, 6.8514e-02, 0.0000e+00],\n",
      "          [3.0118e-02, 5.3564e-01, 4.3424e-01, 0.0000e+00],\n",
      "          [2.0202e-01, 1.8692e-01, 6.1106e-01, 0.0000e+00],\n",
      "          [5.1690e-01, 2.5001e-01, 2.3309e-01, 0.0000e+00]],\n",
      "\n",
      "         [[6.7304e-01, 1.9233e-01, 1.3463e-01, 0.0000e+00],\n",
      "          [6.3060e-01, 2.5945e-01, 1.0995e-01, 0.0000e+00],\n",
      "          [3.2246e-01, 4.0477e-01, 2.7277e-01, 0.0000e+00],\n",
      "          [8.7965e-01, 9.7932e-02, 2.2413e-02, 0.0000e+00],\n",
      "          [9.1255e-01, 7.1859e-02, 1.5591e-02, 0.0000e+00],\n",
      "          [9.7545e-01, 2.1646e-02, 2.9008e-03, 0.0000e+00],\n",
      "          [2.7343e-02, 9.6918e-01, 3.4809e-03, 0.0000e+00],\n",
      "          [8.6169e-03, 7.6503e-03, 9.8373e-01, 0.0000e+00],\n",
      "          [3.8893e-01, 3.2898e-01, 2.8208e-01, 0.0000e+00]]]],\n",
      "       grad_fn=<SoftmaxBackward0>), 'linking_scores': tensor([[[ 2.0041e-01, -2.0016e-01, -2.0016e-01, -2.0016e-01, -2.0018e-01,\n",
      "          -2.6909e-01, -2.0017e-01, -2.0016e-01, -2.0021e-01, -2.0015e-01,\n",
      "          -2.0023e-01, -2.0017e-01, -2.0015e-01, -2.0019e-01, -2.0015e-01,\n",
      "          -2.0017e-01, -2.0021e-01, -2.0021e-01, -2.0020e-01, -2.0016e-01,\n",
      "          -2.0016e-01, -2.0014e-01, -2.0021e-01, -2.0016e-01, -2.0016e-01,\n",
      "          -2.0019e-01, -2.0019e-01, -2.0015e-01, -2.0015e-01, -2.0014e-01],\n",
      "         [-2.0021e-01, -2.0022e-01, -2.0018e-01, -2.0020e-01, -2.0021e-01,\n",
      "          -2.0017e-01, -2.0017e-01, -2.0023e-01, -2.0020e-01, -2.0024e-01,\n",
      "          -2.0020e-01, -2.0020e-01, -2.0021e-01, -2.0020e-01, -2.0019e-01,\n",
      "          -2.0019e-01, -2.0018e-01, -2.0018e-01, -2.0019e-01, -2.0024e-01,\n",
      "          -2.0021e-01, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04],\n",
      "         [ 2.0043e-01, -2.0016e-01, -2.0015e-01, -2.0014e-01, -2.0015e-01,\n",
      "          -2.0017e-01, -2.0017e-01, -2.0015e-01, -2.0016e-01, -2.0017e-01,\n",
      "          -2.0017e-01, -2.0013e-01, -2.0016e-01, -2.0016e-01, -2.0019e-01,\n",
      "          -2.0019e-01, -2.0018e-01, -2.2800e-01, -2.0017e-01, -2.0016e-01,\n",
      "          -2.0017e-01, -2.0016e-01, -2.0014e-01, -2.0015e-01, -2.0020e-01,\n",
      "          -2.0016e-01, -2.0015e-01, -2.0020e-01, -2.0016e-01, -2.0014e-01],\n",
      "         [-2.0019e-01, -2.0021e-01, -2.0015e-01, -2.0016e-01, -2.0018e-01,\n",
      "          -2.0020e-01, -2.0018e-01, -2.0015e-01, -2.0017e-01, -2.0015e-01,\n",
      "          -2.0018e-01, -2.0019e-01, -2.0019e-01, -2.0017e-01, -2.0022e-01,\n",
      "          -2.0018e-01, -2.0020e-01, -2.0013e-01, -2.0014e-01, -2.0016e-01,\n",
      "          -2.0017e-01, -2.0017e-01, -2.0017e-01, -2.0016e-01, -2.0015e-01,\n",
      "          -2.0020e-01, -2.0017e-01, -2.0015e-01, -2.0017e-01, -2.0014e-01]],\n",
      "\n",
      "        [[-2.0023e-01, -2.0022e-01, -2.0023e-01, -2.0021e-01, -2.0024e-01,\n",
      "          -2.0026e-01, -2.0024e-01, -2.0023e-01, -2.0020e-01, -2.0019e-01,\n",
      "          -2.0026e-01, -2.0020e-01, -2.0024e-01, -2.0021e-01, -2.0023e-01,\n",
      "          -2.0024e-01, -2.0026e-01, -2.0022e-01, -2.0018e-01, -2.0024e-01,\n",
      "          -2.0016e-01, -2.0024e-01, -2.0023e-01, -2.0015e-01, -2.0020e-01,\n",
      "          -2.0019e-01, -2.0019e-01, -2.0025e-01, -2.0022e-01, -2.0019e-01],\n",
      "         [-2.0022e-01, -2.0019e-01, -2.0020e-01, -2.0023e-01, -2.0021e-01,\n",
      "          -2.0025e-01, -2.0022e-01, -2.0024e-01, -2.0024e-01, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04],\n",
      "         [-2.0019e-01, -2.0017e-01, -2.0018e-01, -2.0015e-01, -2.0021e-01,\n",
      "          -2.0021e-01, -2.0017e-01, -2.0014e-01, -2.0015e-01, -2.0019e-01,\n",
      "          -2.0016e-01, -2.0020e-01, -2.0018e-01, -2.0018e-01, -2.0020e-01,\n",
      "          -2.0015e-01, -2.0026e-01, -2.0023e-01, -2.0023e-01, -2.0022e-01,\n",
      "          -2.0023e-01, -2.0016e-01, -2.0023e-01, -2.0021e-01, -2.0023e-01,\n",
      "          -2.0024e-01, -2.0018e-01, -2.0022e-01, -2.0026e-01, -2.0016e-01],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04]]],\n",
      "       grad_fn=<MaskedFillBackward0>)}, 'wordnet': {'entity_attention_probs': tensor([[[[8.4762e-03, 1.6820e-01, 2.0467e-01, 5.1225e-01, 1.0641e-01],\n",
      "          [9.8893e-01, 5.9378e-03, 1.8649e-03, 7.5735e-04, 2.5123e-03],\n",
      "          [4.8485e-03, 9.5726e-01, 3.2697e-02, 2.6584e-03, 2.5387e-03],\n",
      "          [5.3835e-04, 1.1109e-01, 8.6249e-01, 2.3932e-02, 1.9538e-03],\n",
      "          [1.8464e-05, 1.0367e-03, 5.3576e-03, 9.9173e-01, 1.8562e-03],\n",
      "          [5.8487e-03, 3.6362e-03, 5.9090e-03, 2.9929e-02, 9.5468e-01],\n",
      "          [1.5182e-01, 1.4290e-01, 2.8698e-01, 1.4700e-01, 2.7130e-01],\n",
      "          [1.5868e-01, 1.4161e-01, 2.7393e-01, 1.3127e-01, 2.9451e-01],\n",
      "          [3.8138e-01, 4.1052e-01, 1.1162e-01, 4.8313e-02, 4.8166e-02]],\n",
      "\n",
      "         [[9.2532e-03, 1.0861e-01, 1.2241e-01, 3.9084e-01, 3.6890e-01],\n",
      "          [9.8243e-01, 6.1039e-03, 1.8757e-03, 6.7444e-03, 2.8460e-03],\n",
      "          [8.9766e-05, 9.8786e-01, 1.0941e-02, 9.9042e-04, 1.1857e-04],\n",
      "          [2.1689e-05, 1.0602e-01, 8.3819e-01, 5.2091e-02, 3.6851e-03],\n",
      "          [4.9775e-06, 6.4803e-05, 4.2080e-03, 9.9179e-01, 3.9373e-03],\n",
      "          [4.3622e-05, 5.3633e-05, 3.1203e-03, 2.9448e-02, 9.6733e-01],\n",
      "          [1.5824e-01, 1.0270e-01, 2.8777e-01, 2.6193e-01, 1.8936e-01],\n",
      "          [1.6555e-01, 9.5497e-02, 2.7889e-01, 2.5431e-01, 2.0575e-01],\n",
      "          [2.6353e-03, 7.3564e-01, 1.8334e-01, 7.6297e-02, 2.0800e-03]],\n",
      "\n",
      "         [[1.8188e-01, 8.2356e-02, 2.7258e-02, 2.3891e-01, 4.6960e-01],\n",
      "          [2.4110e-01, 2.1895e-01, 6.8505e-02, 1.6370e-01, 3.0774e-01],\n",
      "          [1.5804e-01, 2.6204e-01, 1.1492e-01, 2.4168e-01, 2.2331e-01],\n",
      "          [1.6265e-01, 2.8553e-01, 1.2239e-01, 1.5773e-01, 2.7169e-01],\n",
      "          [6.7932e-02, 1.7228e-01, 1.9387e-01, 3.1754e-01, 2.4838e-01],\n",
      "          [2.6843e-01, 1.6336e-01, 9.7949e-02, 2.4324e-01, 2.2703e-01],\n",
      "          [3.6899e-01, 1.8237e-03, 3.7754e-03, 1.7842e-01, 4.4698e-01],\n",
      "          [3.8482e-01, 1.6924e-03, 3.5088e-03, 1.6738e-01, 4.4260e-01],\n",
      "          [1.1610e-01, 2.2066e-01, 2.4867e-01, 2.9468e-01, 1.1989e-01]],\n",
      "\n",
      "         [[6.8068e-03, 5.5217e-02, 1.0124e-01, 7.9402e-01, 4.2718e-02],\n",
      "          [8.0930e-01, 2.0122e-02, 8.1160e-03, 1.4370e-01, 1.8767e-02],\n",
      "          [5.9356e-03, 9.1280e-01, 4.9063e-02, 2.6207e-02, 5.9903e-03],\n",
      "          [3.0424e-04, 1.8067e-01, 5.9013e-01, 2.2606e-01, 2.8413e-03],\n",
      "          [6.8961e-05, 6.9541e-04, 1.3556e-02, 9.8478e-01, 9.0133e-04],\n",
      "          [1.3058e-02, 9.2737e-03, 8.1889e-02, 3.7919e-01, 5.1659e-01],\n",
      "          [4.5107e-01, 8.1364e-02, 9.4276e-02, 1.1361e-01, 2.5968e-01],\n",
      "          [4.4864e-01, 8.0558e-02, 8.6504e-02, 1.0702e-01, 2.7728e-01],\n",
      "          [1.8036e-02, 2.2847e-01, 1.8125e-02, 6.9165e-01, 4.3721e-02]]],\n",
      "\n",
      "\n",
      "        [[[9.4132e-01, 3.0431e-02, 2.5768e-02, 2.4814e-03, 0.0000e+00],\n",
      "          [6.5655e-01, 5.3793e-02, 2.5868e-01, 3.0969e-02, 0.0000e+00],\n",
      "          [3.7655e-01, 1.5667e-01, 1.0420e-02, 4.5636e-01, 0.0000e+00],\n",
      "          [9.9779e-01, 1.7547e-03, 6.6224e-05, 3.9052e-04, 0.0000e+00],\n",
      "          [1.9106e-02, 8.6868e-01, 8.4489e-04, 1.1137e-01, 0.0000e+00],\n",
      "          [1.8042e-03, 1.7234e-03, 9.8728e-01, 9.1884e-03, 0.0000e+00],\n",
      "          [1.2002e-04, 5.5363e-04, 6.7183e-06, 9.9932e-01, 0.0000e+00],\n",
      "          [9.9376e-02, 1.4437e-01, 1.9476e-02, 7.3678e-01, 0.0000e+00],\n",
      "          [1.1780e-01, 5.3278e-01, 1.7193e-01, 1.7749e-01, 0.0000e+00]],\n",
      "\n",
      "         [[7.1078e-01, 2.8363e-01, 1.0991e-03, 4.4952e-03, 0.0000e+00],\n",
      "          [4.0589e-01, 5.3796e-01, 1.0250e-02, 4.5892e-02, 0.0000e+00],\n",
      "          [4.0338e-01, 2.4485e-01, 3.7362e-02, 3.1440e-01, 0.0000e+00],\n",
      "          [9.1117e-01, 8.8443e-02, 2.1181e-04, 1.7865e-04, 0.0000e+00],\n",
      "          [1.9036e-03, 9.8845e-01, 1.3520e-03, 8.2944e-03, 0.0000e+00],\n",
      "          [9.5366e-04, 3.0472e-01, 6.6289e-01, 3.1436e-02, 0.0000e+00],\n",
      "          [3.6819e-05, 2.0713e-02, 2.6302e-05, 9.7922e-01, 0.0000e+00],\n",
      "          [8.9611e-03, 4.5165e-01, 1.8006e-02, 5.2138e-01, 0.0000e+00],\n",
      "          [8.7883e-02, 1.1737e-01, 4.2608e-01, 3.6867e-01, 0.0000e+00]],\n",
      "\n",
      "         [[2.6343e-01, 6.6580e-01, 1.5593e-02, 5.5179e-02, 0.0000e+00],\n",
      "          [3.0621e-01, 4.9799e-01, 7.2446e-02, 1.2336e-01, 0.0000e+00],\n",
      "          [3.4612e-01, 5.8289e-01, 2.9621e-02, 4.1373e-02, 0.0000e+00],\n",
      "          [1.0315e-01, 8.6186e-01, 8.3581e-03, 2.6636e-02, 0.0000e+00],\n",
      "          [1.0790e-01, 8.6339e-01, 9.1230e-03, 1.9593e-02, 0.0000e+00],\n",
      "          [1.1201e-01, 6.5675e-01, 5.4759e-02, 1.7648e-01, 0.0000e+00],\n",
      "          [1.5842e-01, 3.3167e-01, 3.2771e-01, 1.8219e-01, 0.0000e+00],\n",
      "          [1.3582e-01, 9.3263e-02, 3.1533e-01, 4.5558e-01, 0.0000e+00],\n",
      "          [1.7567e-02, 2.7479e-01, 6.4161e-01, 6.6031e-02, 0.0000e+00]],\n",
      "\n",
      "         [[6.4812e-01, 3.3688e-01, 5.4045e-03, 9.5989e-03, 0.0000e+00],\n",
      "          [2.4289e-01, 3.1995e-01, 2.2391e-01, 2.1325e-01, 0.0000e+00],\n",
      "          [2.3355e-01, 1.8645e-01, 2.9726e-02, 5.5027e-01, 0.0000e+00],\n",
      "          [7.5784e-01, 2.3950e-01, 1.6312e-03, 1.0281e-03, 0.0000e+00],\n",
      "          [2.8698e-03, 9.9322e-01, 1.9460e-04, 3.7126e-03, 0.0000e+00],\n",
      "          [5.2900e-03, 4.1983e-01, 4.0962e-01, 1.6526e-01, 0.0000e+00],\n",
      "          [3.3008e-04, 2.9933e-02, 4.0818e-04, 9.6933e-01, 0.0000e+00],\n",
      "          [6.2094e-03, 5.7154e-01, 3.9392e-02, 3.8286e-01, 0.0000e+00],\n",
      "          [8.7708e-02, 1.7309e-01, 4.8691e-01, 2.5229e-01, 0.0000e+00]]]],\n",
      "       grad_fn=<SoftmaxBackward0>), 'linking_scores': tensor([[[ 1.6934e+01, -9.5893e+00, -1.3993e+01, -6.2944e+00, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04],\n",
      "         [-9.0264e+00, -2.1190e+00,  7.4283e+00,  9.3004e+00,  2.9629e+01,\n",
      "           5.4515e+00,  1.3541e+01,  1.0902e+01,  3.2923e+01,  1.1040e+01,\n",
      "           8.6585e+00,  7.9136e+00,  9.0164e+00,  2.7230e+01],\n",
      "         [ 2.6307e+01,  1.6650e+01,  1.3917e+01,  2.8120e+01, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0486e+01, -7.0833e+00, -1.2306e+01, -1.3690e+00, -1.1220e+01,\n",
      "          -6.8074e+00, -1.2718e+01, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04],\n",
      "         [ 1.2783e+01, -1.3950e+01, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 3.4952e+00,  2.3861e+01,  2.9450e+01,  2.0005e+01,  4.6937e+01,\n",
      "           2.0941e+01,  2.8764e+01,  2.7058e+01,  1.2196e+01,  3.0550e+01,\n",
      "           1.8765e+01,  1.2797e+01,  2.5067e+01,  8.5039e+00],\n",
      "         [ 4.4380e+01,  1.6824e+01,  1.6824e+01,  1.3446e+01,  2.5816e+01,\n",
      "           1.1266e+01,  7.9652e+00,  1.1175e+01, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04],\n",
      "         [ 3.5337e+01, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04],\n",
      "         [ 2.1234e+01,  1.9708e+01, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04]]],\n",
      "       grad_fn=<MaskedFillBackward0>)}, 'loss': 0.0, 'pooled_output': tensor([[-0.9785,  0.9612,  0.9892,  ..., -0.0881, -0.0983,  0.9725],\n",
      "        [ 0.7349,  0.8321,  0.9914,  ..., -0.3343, -0.7369,  0.3899]],\n",
      "       grad_fn=<TanhBackward0>), 'contextual_embeddings': tensor([[[-0.2191,  0.0469,  0.3313,  ..., -0.1035,  0.4215,  0.0816],\n",
      "         [-0.2557, -0.3025,  0.3482,  ..., -0.8384,  0.2088, -0.1212],\n",
      "         [-0.7448, -0.2799,  0.1577,  ..., -0.1018,  0.5554,  0.1610],\n",
      "         ...,\n",
      "         [-0.1899, -0.0831,  0.3375,  ..., -0.2673,  0.3587, -0.3385],\n",
      "         [-0.1916, -0.0494,  0.3349,  ..., -0.2962,  0.3412, -0.3320],\n",
      "         [-0.3173, -0.0397,  0.3969,  ..., -0.1223,  0.7033,  0.1718]],\n",
      "\n",
      "        [[ 0.9990, -0.0845,  0.7059,  ...,  0.8191,  0.0556,  0.1988],\n",
      "         [-0.1391, -0.1822,  0.2163,  ...,  0.1031,  0.7076, -0.1632],\n",
      "         [-0.8084,  0.1797, -0.0894,  ..., -0.3327,  0.2993,  0.1269],\n",
      "         ...,\n",
      "         [ 0.3399, -0.0032,  0.6638,  ..., -0.1124,  0.0432, -1.2237],\n",
      "         [ 0.0315,  0.1576,  0.2010,  ...,  0.0202,  0.0044, -0.5098],\n",
      "         [ 0.5316,  0.3982,  0.8043,  ...,  0.2626,  0.1034, -0.3791]]],\n",
      "       grad_fn=<AddBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "sentences = [\"Paris is located in France.\", \"KnowBert is a knowledge enhanced BERT\"]\n",
    "encoder.eval()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# batcher takes raw untokenized sentences\n",
    "# and yields batches of tensors needed to run KnowBert\n",
    "for batch in batcher.iter_batches(sentences, verbose=True):\n",
    "    # model_output['contextual_embeddings'] is (batch_size, seq_len, embed_dim) tensor of top layer activations\n",
    "    model_output = encoder(**batch)\n",
    "    logger.info(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"Batchifier.pkl\", \"wb\") as pickle_file:\n",
    "    pickle.dump(batcher, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"Batchifier.pkl\", \"rb\") as pickle_file:\n",
    "    batcher = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_cased = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example:\n",
    "    \"\"\"A single training/test example.\"\"\"\n",
    "\n",
    "    def __init__(self, idx, source, triples, target):\n",
    "        self.idx = idx\n",
    "        self.source = source\n",
    "        self.triples = triples\n",
    "        self.target = target\n",
    "\n",
    "\n",
    "def read_examples(source_file, triples_file, target_file):\n",
    "    \"\"\"Read examples from filename.\"\"\"\n",
    "    examples = []\n",
    "    with open(source_file, encoding=\"utf-8\") as source_f:\n",
    "        with open(triples_file, encoding=\"utf-8\") as triples_f:\n",
    "            with open(target_file, encoding=\"utf-8\") as target_f:\n",
    "                for idx, (source, triples, target) in enumerate(\n",
    "                    zip(source_f, triples_f, target_f)\n",
    "                ):\n",
    "                    examples.append(\n",
    "                        Example(\n",
    "                            idx=idx,\n",
    "                            source=source.strip(),\n",
    "                            triples=triples.strip(),\n",
    "                            target=target.strip(),\n",
    "                        )\n",
    "                    )\n",
    "    return examples\n",
    "\n",
    "class InputFeatures:\n",
    "    \"\"\"A single training/test features for a example.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        example_id,\n",
    "        triples_ids,\n",
    "        target_ids,\n",
    "        triples_mask,\n",
    "        target_mask,\n",
    "    ):\n",
    "        self.example_id = example_id\n",
    "        self.triples_ids = triples_ids\n",
    "        self.target_ids = target_ids\n",
    "        self.triples_mask = triples_mask\n",
    "        self.target_mask = target_mask\n",
    "\n",
    "def replace_mask(text):\n",
    "    return text.replace('[MASK]', ' [MASK] ')\n",
    "def convert_examples_to_features(examples, \n",
    "                                 tokenizer, \n",
    "                                 max_triple_length, \n",
    "                                 max_target_length, \n",
    "                                 stage=None):\n",
    "    features = []\n",
    "    for example_index, example in enumerate(examples):\n",
    "        # source handled elsewhere\n",
    "        \n",
    "\n",
    "        # triples\n",
    "        triples_tokens = tokenizer.tokenize(example.triples)[: max_triple_length]\n",
    "        triples_ids = tokenizer.convert_tokens_to_ids(triples_tokens)\n",
    "        triples_mask = [1] * (len(triples_tokens))\n",
    "        padding_length = max_triple_length - len(triples_ids)\n",
    "        triples_ids += [tokenizer.pad_token_id] * padding_length\n",
    "        triples_mask += [0] * padding_length\n",
    "\n",
    "        # target\n",
    "        if stage == \"test\" or stage == \"predict\":\n",
    "            target_tokens = tokenizer.tokenize(\"None\")\n",
    "        else:\n",
    "            target_tokens = tokenizer.tokenize(example.target)[\n",
    "                : max_target_length - 2\n",
    "            ]\n",
    "        target_tokens = [tokenizer.cls_token] + target_tokens + [tokenizer.sep_token]\n",
    "        target_ids = tokenizer.convert_tokens_to_ids(target_tokens)\n",
    "        target_mask = [1] * len(target_ids)\n",
    "        padding_length = max_target_length - len(target_ids)\n",
    "        target_ids += [tokenizer.pad_token_id] * padding_length\n",
    "        target_mask += [0] * padding_length\n",
    "\n",
    "        if example_index < 5:\n",
    "            if stage == \"train\":\n",
    "                logger.info(\"*** Example ***\")\n",
    "                logger.info(\"idx: {}\".format(example.idx))\n",
    "\n",
    "                logger.info(\n",
    "                    \"triples_tokens: {}\".format(\n",
    "                        [x.replace(\"\\u0120\", \"_\") for x in triples_tokens]\n",
    "                    )\n",
    "                )\n",
    "                logger.info(\"triples_ids: {}\".format(\" \".join(map(str, triples_ids))))\n",
    "                logger.info(\"triples_mask: {}\".format(\" \".join(map(str, triples_mask))))\n",
    "\n",
    "                logger.info(\n",
    "                    \"target_tokens: {}\".format(\n",
    "                        [x.replace(\"\\u0120\", \"_\") for x in target_tokens]\n",
    "                    )\n",
    "                )\n",
    "                logger.info(\"target_ids: {}\".format(\" \".join(map(str, target_ids))))\n",
    "                logger.info(\"target_mask: {}\".format(\" \".join(map(str, target_mask))))\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                example_index,\n",
    "                triples_ids,\n",
    "                target_ids,\n",
    "                triples_mask,\n",
    "                target_mask,\n",
    "            )\n",
    "        )\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = \"../bert_spbert_spbert_base/data/qald-9-small/preprocessed_data_files/qtq-qald-9-train-small\"\n",
    "\n",
    "train_examples = read_examples(\n",
    "            train_filename + \".\" + \"en\",\n",
    "            train_filename + \".triple\",\n",
    "            train_filename + \".\" + \"sparql\",\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all boardgames by GMT .\n"
     ]
    }
   ],
   "source": [
    "print(train_examples[0].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/07/2022 07:47:59 - INFO - __main__ -   *** Example ***\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   idx: 0\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_tokens: ['d', '##b', '##r', ':', 'Greenwich', '_', 'Mean', '_', 'Time', 'a', 'ya', '##go', ':', 'Time', '##P', '##eri', '##od', '##11', '##51', '##13', '##22', '##9', '.', 'd', '##b', '##r', ':', 'Greenwich', '_', 'Mean', '_', 'Time']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_ids: 173 1830 1197 131 14323 168 25030 168 2614 170 11078 2758 131 2614 2101 9866 5412 14541 24050 17668 20581 1580 119 173 1830 1197 131 14323 168 25030 168 2614\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_tokens: ['[CLS]', 'select', 'variable', ':', 'u', '##ri', 'where', 'bracket', 'open', 'variable', ':', 'u', '##ri', 'd', '##bo', ':', 'publisher', 'd', '##b', '##r', ':', 'GM', '##T', '_', 'Games', 'bracket', 'close', '[SEP]']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_ids: 101 8247 7898 131 190 2047 1187 26083 1501 7898 131 190 2047 173 4043 131 6654 173 1830 1197 131 14748 1942 168 2957 26083 1601 102 0 0 0 0\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   *** Example ***\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   idx: 1\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_tokens: ['d', '##b', '##r', ':', 'Sky', '##pe', 'd', '##bo', ':', 'developer', 'd', '##b', '##r', ':', 'Sky', '##pe', '_', 'Technologies', '.', 'd', '##b', '##r', ':', 'Sky', '##pe', 'a', 'ya', '##go', ':', 'Act', '##ivity', '##100']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_ids: 173 1830 1197 131 5751 3186 173 4043 131 9991 173 1830 1197 131 5751 3186 168 14164 119 173 1830 1197 131 5751 3186 170 11078 2758 131 2173 6366 20150\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_tokens: ['[CLS]', 'select', 'distinct', 'variable', ':', 'u', '##ri', 'where', 'bracket', 'open', 'd', '##b', '##r', ':', 'Sky', '##pe', 'd', '##bo', ':', 'author', 'variable', ':', 'u', '##ri', '.', 'bracket', 'close', '[SEP]']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_ids: 101 8247 4966 7898 131 190 2047 1187 26083 1501 173 1830 1197 131 5751 3186 173 4043 131 2351 7898 131 190 2047 119 26083 1601 102 0 0 0 0\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   *** Example ***\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   idx: 2\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_tokens: ['d', '##b', '##r', ':', 'Cyril', '_', 'Luca', '##ris', 'd', '##bo', ':', 'birth', '##P', '##lace', 'd', '##b', '##r', ':', 'Her', '##ak', '##lion', '.', 'd', '##b', '##r', ':', 'O', '##dy', '##sse', '##as', '_', 'Ely']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_ids: 173 1830 1197 131 17007 168 16730 4889 173 4043 131 3485 2101 17510 173 1830 1197 131 1430 3715 12489 119 173 1830 1197 131 152 3810 11553 2225 168 22925\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_tokens: ['[CLS]', 'select', 'distinct', 'variable', ':', 'u', '##ri', 'where', 'bracket', 'open', 'variable', ':', 'u', '##ri', 'd', '##bo', ':', 'birth', '##P', '##lace', 'd', '##b', '##r', ':', 'Her', '##ak', '##lion', '.', 'bracket', 'close', '[SEP]']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_ids: 101 8247 4966 7898 131 190 2047 1187 26083 1501 7898 131 190 2047 173 4043 131 3485 2101 17510 173 1830 1197 131 1430 3715 12489 119 26083 1601 102 0\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   *** Example ***\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   idx: 3\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_tokens: ['d', '##b', '##r', ':', 'Area', '_', '51', 'a', 'ya', '##go', ':', 'Geographic', '##al', '##A', '##rea', '##10', '##8', '##5', '##7', '##43', '##14', '.', 'd', '##b', '##r', ':', 'Area', '_', '51', 'a', 'ya', '##go']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_ids: 173 1830 1197 131 3894 168 4062 170 11078 2758 131 15472 1348 1592 11811 10424 1604 1571 1559 25631 17175 119 173 1830 1197 131 3894 168 4062 170 11078 2758\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_tokens: ['[CLS]', 'select', 'distinct', 'variable', ':', 'u', '##ri', 'where', 'bracket', 'open', 'd', '##b', '##r', ':', 'Area', '_', '51', 'd', '##b', '##p', ':', 'nearest', '##T', '##own', 'variable', ':', 'u', '##ri', '.', 'bracket', 'close', '[SEP]']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_ids: 101 8247 4966 7898 131 190 2047 1187 26083 1501 173 1830 1197 131 3894 168 4062 173 1830 1643 131 6830 1942 13798 7898 131 190 2047 119 26083 1601 102\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   *** Example ***\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   idx: 4\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_tokens: ['d', '##b', '##r', ':', 'New', '_', 'York', '_', 'City', 'a', '<', 'http', ':', '/', '/', 'www', '.', 'w', '##iki', '##data', '.', 'org', '/', 'entity', '/', 'Q', '##48', '##6', '##9', '##7', '##2', '>']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_ids: 173 1830 1197 131 1203 168 1365 168 1392 170 133 8413 131 120 120 7001 119 192 12635 27922 119 8916 120 9127 120 154 19203 1545 1580 1559 1477 135\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   triples_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_tokens: ['[CLS]', 'select', 'distinct', 'variable', ':', 'u', '##ri', 'where', 'bracket', 'open', 'd', '##b', '##r', ':', 'New', '_', 'York', '_', 'City', 'd', '##b', '##p', ':', 'leader', '##N', '##ame', 'variable', ':', 'u', '##ri', 'bracket', '[SEP]']\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_ids: 101 8247 4966 7898 131 190 2047 1187 26083 1501 173 1830 1197 131 1203 168 1365 168 1392 173 1830 1643 131 2301 2249 16470 7898 131 190 2047 26083 102\n",
      "06/07/2022 07:47:59 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "train_features = convert_examples_to_features(train_examples, \n",
    "                                            tokenizer_cased, \n",
    "                                            max_triple_length=32, \n",
    "                                            max_target_length=32, \n",
    "                                            stage=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offsets: [1, 2, 4, 5, 7, 8]\n",
      "word_piece_tokens: [['list'], ['all'], ['board', '##games'], ['by'], ['gm', '##t'], ['.']]\n",
      "tokens: ['List', 'all', 'boardgames', 'by', 'GMT', '.']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'list', 'all', 'board', '##games', 'by', 'gm', '##t', '.', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['List', 'all', 'boardgames', 'by', 'GMT', '.'], 'candidate_spans': [[1, 1], [3, 4], [6, 7], [8, 8]], 'candidate_entities': [['List_(abstract_data_type)', 'List,_Schleswig-Holstein', 'President_of_Iran', 'Sniper_rifle', 'Angle_of_list', 'Prime_Minister_of_Poland', 'Robert_List', 'Prime_Minister_of_Iraq', 'Friedrich_List', 'Party-list_proportional_representation', 'Vice_President_of_Iran', 'President_of_Israel', 'President_of_Rhodesia', 'President_of_Croatia', 'Premier_of_the_Eastern_Cape', 'List_MP', 'Premier_of_the_Northern_Cape', 'Wilhelm_List', 'Civic_and_Municipal_Affairs_Bureau', 'Emanuel_List', 'Premier_of_KwaZulu-Natal', 'Premier_of_Gauteng', 'Joel_Abraham_List', 'Hans_List', 'Spencer_List', 'Eugene_List', 'Administrative_divisions_of_the_Republic_of_China', 'Liesbeth_List', 'Sumerian_King_List', 'International_Best_Dressed_List'], ['Board_game'], ['Greenwich_Mean_Time', 'GMT_(programme)', 'Western_European_Time', 'Coordinated_Universal_Time', 'Giant_Magellan_Telescope', 'GMT_Games', 'Guy_McCoy_Tormé', 'Grosmont_railway_station', 'Transport_for_Greater_Manchester', 'GMT_Records', 'Generic_Mapping_Tools', 'Time_zone', 'Royal_Observatory,_Greenwich', 'Pacific_Time_Zone', 'GM_GMT_platform', 'Rolex_GMT_Master_II'], ['Full_stop', 'Names_of_Burma', 'University_of_Yangon', 'Ne_Win', 'Administrative_divisions_of_Burma', 'Wa_people', 'Yangon_River', 'U_Nu', 'Yangon_Technological_University', 'U_Thant', 'Yangon', 'Naypyidaw', 'Greater_Tokyo_Area', 'Allies_of_World_War_II', 'Shiva', '1991_Bangladesh_cyclone', 'Bhopal', 'Ba_Win', 'Doctor_of_Philosophy', 'Walter_Chit_Tun', 'Big_Brother_(UK)', 'Harlem', 'Combining_character', '8888_Uprising', 'Union_Solidarity_and_Development_Association', 'Uncanny', 'Yangon_Region', 'Derby', 'A_Coruña', 'Shwe_Mann']], 'candidate_entity_priors': [[0.10822699359784338, 0.06431557858978235, 0.04270284395278969, 0.04028570184225395, 0.03833130090152822, 0.03404141805670433, 0.0334970166804577, 0.032832847001436946, 0.031079874569922946, 0.03067701755150048, 0.03021427638169046, 0.029811419363267998, 0.02900570532642308, 0.028602848308000618, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489, 0.02664844736727489], [1.0], [0.5219893136046035, 0.05442291775754556, 0.05293087625064248, 0.05287457279754914, 0.05242414517282329, 0.05222708308700442, 0.05219893136046036, 0.05219893136046036, 0.05219893136046036, 0.05219893136046036, 0.0033500554589012987, 0.00033782071854466644, 0.00022521381236311445, 0.0001407586327269439, 0.0001407586327269439, 0.0001407586327269439], [0.4705882352941141, 0.11764705882353167, 0.08403361344537887, 0.025210084033613033, 0.025210084033613033, 0.025210084033613033, 0.025210084033613033, 0.016806722689075772, 0.016806722689075772, 0.016806722689075772, 0.016806722689075772, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886]], 'candidate_segment_ids': [0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['List', 'all', 'boardgames', 'by', 'GMT', '.'], 'candidate_spans': [[1, 1], [2, 2], [5, 5], [6, 7]], 'candidate_entities': [['tilt.n.04', 'list.n.01', 'list.v.01', 'number.v.03', 'list.v.04', 'list.v.03', 'list.v.02'], ['all.s.02', 'all.a.01', 'wholly.r.01'], ['aside.r.06', 'by.r.01'], ['greenwich_mean_time.n.01']], 'candidate_entity_priors': [[0.017543859649122806, 0.5701754385964912, 0.21052631578947367, 0.008771929824561403, 0.008771929824561403, 0.008771929824561403, 0.17543859649122806], [0.014336917562724014, 0.8888888888888888, 0.0967741935483871], [0.25, 0.75], [1.0]], 'candidate_segment_ids': [0, 0, 0, 0]}}, 'offsets_a': [2, 3, 5, 6, 8, 9], 'offsets_b': None}\n",
      "List all boardgames by GMT .\n",
      "['[CLS]', 'list', 'all', 'board', '##games', 'by', 'gm', '##t', '.', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e90164e40>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 10 with text: \n",
      " \t\t[[CLS], list, all, board, ##games, by, gm, ##t, ., [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([  101,  2862,  2035,  2604, 26393,  2011, 13938,  2102,  1012,   102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e90164e40>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7f9e9100b6d0>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e9100b8e0>}\n",
      "TextField of length 10 with text: \n",
      " \t\t[[CLS], list, all, board, ##games, by, gm, ##t, ., [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 10 with text: \n",
      " \t\t[[CLS], list, all, board, ##games, by, gm, ##t, ., [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([10]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "offsets: [1, 2, 4, 5]\n",
      "word_piece_tokens: [['who'], ['developed'], ['sky', '##pe'], ['?']]\n",
      "tokens: ['Who', 'developed', 'Skype', '?']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'who', 'developed', 'sky', '##pe', '?', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['Who', 'developed', 'Skype', '?'], 'candidate_spans': [[1, 1], [2, 2], [3, 4], [5, 5]], 'candidate_entities': [['The_Who', 'Doctor_Who', 'Who_(magazine)', 'Who_(pronoun)', 'Jim_Neidhart', 'Who?_(album)', 'William_Coventry', 'Who?_(song)', 'Bobby_Who', 'Doctor_Who_(film)', 'Who?_(novel)', 'Who_(Unix)', 'Who_Dat_(Young_Jeezy_song)', 'Guess_Who_(rapper)', 'Speak_Your_Language', 'Who_See', 'Horton_Hears_a_Who!', 'Alfred_Russel_Wallace', 'Casimir_Pulaski', 'Harold_Dieterle', 'Measuring_poverty', 'Ace_Young', 'Victor_Lustig', 'Saint_Patrick', 'Section_28', 'The_Girl_in_the_Fireplace', 'New_York_City_Hall', 'Ken_Jennings', 'Zen_and_the_Art_of_Motorcycle_Maintenance', 'Diana,_Princess_of_Wales'], ['Video_game_developer', 'Developed_country', 'Software_developer', 'Software_development', 'Photographic_processing', 'Subdivision_(land)', 'Musical_development', 'Suburbanization', 'Timeline_of_jet_power', 'Rolls-Royce_Thrust_Measuring_Rig', 'Power_Jets', 'Photographic_developer', 'Video_game_development', 'Economic_development', 'Research_and_development', 'Agricultural_subsidy', 'Developed_market', 'Drug_development', 'Visual_arts', 'History_of_Sesame_Street', 'Adobe_Photoshop', 'Research', 'Construction', 'Philips', 'Ice-minus_bacteria', 'Nile', 'Custom_software', 'Tropical_cyclogenesis', 'Director_of_National_Intelligence', 'Selective_breeding'], ['Skype', 'Skype_Technologies', 'Skype_security', 'Skype_protocol', 'Niklas_Zennström', 'FastTrack', 'Janus_Friis', 'Features_of_Skype'], ['Question_mark', '?_(Lost)', 'Rugby_league_positions', '?_(Neal_Morse_album)', 'Chess_annotation_symbols', \"The_Emperor's_New_School\", 'Michigan', 'Pinyin', '?_(EP)', 'Latin_alphabet', '?_(film)', 'Jyutping', 'Yale_romanization_of_Cantonese', 'January_2006_in_Malaysia_and_Singapore', 'Traditional_Chinese_characters', 'Pe̍h-ōe-jī', '?_(bistro)']], 'candidate_entity_priors': [[0.27126923076923193, 0.10634615384615292, 0.08480769230769412, 0.038038461538461195, 0.03342307692307671, 0.03342307692307671, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.01999999999999996, 0.01476923076923056, 0.011692307692307571, 0.008307692307692387, 0.007692307692307473, 0.006769230769230894, 0.0049230769230768886, 0.00461538461538459, 0.003999999999999991, 0.003999999999999991, 0.003999999999999991, 0.0036923076923076927, 0.0036923076923076927, 0.0033846153846153943], [0.18887262079062966, 0.1670262772597676, 0.08002620020035567, 0.059451336980810364, 0.05798720813747547, 0.05267010865377228, 0.05243893041535152, 0.051591276874468545, 0.051591276874468545, 0.051591276874468545, 0.05151421746166334, 0.03498497341450292, 0.016567773753564052, 0.0114818525082842, 0.011404793095476935, 0.008938891885644016, 0.006704168914232883, 0.005162980658087629, 0.004623564768436481, 0.004084148878785591, 0.0036217924019419125, 0.0035447329891346497, 0.0033906141635201242, 0.0033906141635201242, 0.00331355475071281, 0.003082376512291022, 0.0029282576866764454, 0.00277413886106192, 0.0026970794482546055, 0.0025429606226400805], [0.6570337153296778, 0.32964623816641897, 0.008071748878923955, 0.004417870785583811, 0.0002657365886065451, 0.00019930244145490556, 0.00019930244145490556, 0.00016608536787908904], [0.9163961038961033, 0.01785714285714306, 0.008928571428571432, 0.00811688311688313, 0.007305194805194826, 0.007305194805194826, 0.006493506493506523, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129]], 'candidate_segment_ids': [0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['Who', 'developed', 'Skype', '?'], 'candidate_spans': [[1, 1], [2, 2]], 'candidate_entities': [['world_health_organization.n.01'], ['grow.v.08', 'build_up.v.05', 'develop.v.21', 'develop.v.10', 'develop.v.12', 'break.v.53', 'develop.v.09', 'develop.v.19', 'modernize.v.02', 'develop.v.14', 'develop.v.03', 'train.v.01', 'explicate.v.02', 'develop.v.18', 'develop.v.17', 'develop.v.16', 'develop.v.13', 'evolve.v.01', 'develop.v.01', 'develop.v.15', 'originate.v.01']], 'candidate_entity_priors': [[1.0], [0.08968609865470852, 0.05829596412556054, 0.004484304932735426, 0.02242152466367713, 0.017937219730941704, 0.004484304932735426, 0.02242152466367713, 0.004484304932735426, 0.017937219730941704, 0.008968609865470852, 0.18834080717488788, 0.026905829596412557, 0.03139013452914798, 0.004484304932735426, 0.004484304932735426, 0.004484304932735426, 0.008968609865470852, 0.20179372197309417, 0.20179372197309417, 0.004484304932735426, 0.07174887892376682]], 'candidate_segment_ids': [0, 0]}}, 'offsets_a': [2, 3, 5, 6], 'offsets_b': None}\n",
      "Who developed Skype ?\n",
      "['[CLS]', 'who', 'developed', 'sky', '##pe', '?', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e90175780>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 7 with text: \n",
      " \t\t[[CLS], who, developed, sky, ##pe, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([ 101, 2040, 2764, 3712, 5051, 1029,  102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e90175780>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7f9e9100be80>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e7e6f3220>}\n",
      "TextField of length 7 with text: \n",
      " \t\t[[CLS], who, developed, sky, ##pe, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 7 with text: \n",
      " \t\t[[CLS], who, developed, sky, ##pe, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([7]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "offsets: [1, 2, 3, 4, 5, 8, 9]\n",
      "word_piece_tokens: [['which'], ['people'], ['were'], ['born'], ['in'], ['her', '##ak', '##lion'], ['?']]\n",
      "tokens: ['Which', 'people', 'were', 'born', 'in', 'Heraklion', '?']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'which', 'people', 'were', 'born', 'in', 'her', '##ak', '##lion', '?', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['Which', 'people', 'were', 'born', 'in', 'Heraklion', '?'], 'candidate_spans': [[1, 1], [2, 2], [4, 4], [6, 8], [9, 9]], 'candidate_entities': [['Wilhelm_Canaris', 'Gluten-sensitive_enteropathy_associated_conditions'], ['People_(magazine)', 'People', 'People_(1964_song)', 'People_(Australian_magazine)', 'People_(Hothouse_Flowers_album)', 'People_(King_Crimson_song)', 'People_(Barbra_Streisand_album)', 'People!', 'People_(Howard_Jones_album)', 'The_Sunday_People', 'People,_Places,_Pieces', 'Blues_People', 'People_Capability_Maturity_Model', 'Village_People', 'Bright_young_things', 'Go_Down_Moses', 'People_Like_Us_(musician)', 'The_Autumn_People', 'People_(The_Golden_Republic_EP)', 'Epic_Games_Poland', 'Malayali', 'Dead_Famous_People', 'The_Sky_People', 'People,_People', 'People_Telecom', 'The_People_(Common_song)', 'The_Forest_People', 'Brazilian_people', 'Tamil_people', 'Cumbria'], ['Nativity_of_Jesus', 'Michael_Savage', 'Richard_Nixon', 'Franklin_D._Roosevelt', 'Troy,_New_York', 'Ingvar_Kamprad', 'Anna_Jarvis', 'Bernadette_Soubirous', 'Thomas_A._Watson', 'William_McKinley', 'Leonard_Nimoy', 'Sirhan_Sirhan', 'James_Watson', 'Charles_Darwin', 'Ethel_Merman', 'Wacław_Sierpiński', 'Thomas_Jefferson', 'George_Plimpton', 'Warren_Beatty', 'Ulysses_S._Grant', 'Millard_Fillmore', 'Abraham_Lincoln', 'George_Washington', 'Neil_Diamond', 'William_Henry_Harrison', 'Dian_Fossey', 'Helge_von_Koch', 'Charles_Dickens', 'A._J._Foyt', 'Frank_Zamboni'], ['Heraklion'], ['Question_mark', '?_(Lost)', 'Rugby_league_positions', '?_(Neal_Morse_album)', 'Chess_annotation_symbols', \"The_Emperor's_New_School\", 'Michigan', 'Pinyin', '?_(EP)', 'Latin_alphabet', '?_(film)', 'Jyutping', 'Yale_romanization_of_Cantonese', 'January_2006_in_Malaysia_and_Singapore', 'Traditional_Chinese_characters', 'Pe̍h-ōe-jī', '?_(bistro)']], 'candidate_entity_priors': [[0.84444444444444, 0.15555555555556], [0.3179649761604218, 0.05377729553777278, 0.030802355788792823, 0.030395465784723984, 0.029717315777942198, 0.027343790754207384, 0.026258750743356755, 0.025004173230811114, 0.02391913321996049, 0.022935815710127216, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021986405700633063, 0.021226095212260866, 0.009629730096297447, 0.00725620507256206], [0.7025110495895812, 0.015930836854630655, 0.014716596240711189, 0.014279469619699505, 0.009762494535917038, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009713924911360652, 0.009665355286803564], [1.0], [0.9163961038961033, 0.01785714285714306, 0.008928571428571432, 0.00811688311688313, 0.007305194805194826, 0.007305194805194826, 0.006493506493506523, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129]], 'candidate_segment_ids': [0, 0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['Which', 'people', 'were', 'born', 'in', 'Heraklion', '?'], 'candidate_spans': [[2, 2], [3, 3], [4, 4], [5, 5]], 'candidate_entities': [['people.n.01', 'people.n.03', 'citizenry.n.01', 'multitude.n.03', 'people.v.01', 'people.v.02'], ['beryllium.n.01', 'be.v.10', 'be.v.08', 'exist.v.01', 'be.v.01', 'be.v.11', 'be.v.02', 'constitute.v.01', 'be.v.03', 'equal.v.01', 'embody.v.02', 'cost.v.01', 'be.v.12', 'be.v.05'], ['bear.n.01', 'bear.n.02', 'wear.v.02', 'give_birth.v.01', 'have_a_bun_in_the_oven.v.01', 'digest.v.03', 'bear.v.04', 'hold.v.14', 'bear.v.05', 'yield.v.10', 'bear.v.06', 'bear.v.11', 'behave.v.02', 'bear.v.01', 'hold.v.11'], ['in.s.03', 'in.s.02', 'in.s.01', 'in.r.01', 'indiana.n.01', 'inch.n.01', 'indium.n.01']], 'candidate_entity_priors': [[0.8716216216216216, 0.013513513513513514, 0.09797297297297297, 0.006756756756756757, 0.006756756756756757, 0.0033783783783783786], [5.994844433786943e-05, 0.0001798453330136083, 0.0052155146573946405, 0.04208380792518434, 0.6440261375217313, 0.00011989688867573886, 0.1810443019003657, 0.011390204424195192, 0.054073496792758226, 0.016246028415562615, 0.0035369582159342967, 5.994844433786943e-05, 5.994844433786943e-05, 0.04190396259217073], [0.020202020202020204, 0.010101010101010102, 0.020202020202020204, 0.18181818181818182, 0.010101010101010102, 0.1414141414141414, 0.1111111111111111, 0.010101010101010102, 0.0707070707070707, 0.050505050505050504, 0.06060606060606061, 0.010101010101010102, 0.010101010101010102, 0.24242424242424243, 0.050505050505050504], [0.034482758620689655, 0.034482758620689655, 0.034482758620689655, 0.6896551724137931, 0.034482758620689655, 0.13793103448275862, 0.034482758620689655]], 'candidate_segment_ids': [0, 0, 0, 0]}}, 'offsets_a': [2, 3, 4, 5, 6, 9, 10], 'offsets_b': None}\n",
      "Which people were born in Heraklion ?\n",
      "['[CLS]', 'which', 'people', 'were', 'born', 'in', 'her', '##ak', '##lion', '?', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7fa0451f6e40>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 11 with text: \n",
      " \t\t[[CLS], which, people, were, born, in, her, ##ak, ##lion, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([  101,  2029,  2111,  2020,  2141,  1999,  2014,  4817, 18964,  1029,\n",
      "          102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7fa0451f6e40>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7f9e7e6f3430>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e7e6f3280>}\n",
      "TextField of length 11 with text: \n",
      " \t\t[[CLS], which, people, were, born, in, her, ##ak, ##lion, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 11 with text: \n",
      " \t\t[[CLS], which, people, were, born, in, her, ##ak, ##lion, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([11]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "offsets: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "word_piece_tokens: [['in'], ['which'], ['u'], ['.'], ['s'], ['.'], ['state'], ['is'], ['area'], ['51'], ['located'], ['?']]\n",
      "tokens: ['In', 'which', 'U', '.', 'S', '.', 'state', 'is', 'Area', '51', 'located', '?']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'in', 'which', 'u', '.', 's', '.', 'state', 'is', 'area', '51', 'located', '?', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['In', 'which', 'U', '.', 'S', '.', 'state', 'is', 'Area', '51', 'located', '?'], 'candidate_spans': [[1, 1], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [9, 9], [9, 10], [10, 10], [11, 11], [12, 12]], 'candidate_entities': [['Indium', 'Cause_of_action', 'The_Vengeance_Trilogy', 'In_scale', 'In_The_Wings', 'In_the_City_(Joe_Walsh_song)', 'Song_In', 'In_My_Head_(Queens_of_the_Stone_Age_song)', 'Tak_Jae-in', 'In_Your_Arms_(Love_song_from_Neighbours)', 'In_Arabian_Nights', 'In_Flames', 'Kim_In', 'In_Private', 'Han_Ga-in', 'In_Tam', 'In_Case_of_Fire', 'In_the_Hunt', 'In_Reality', 'In_This_Moment', 'In_Your_Eyes_(George_Benson_song)', 'Preap_In', 'In_Excess_(horse)', 'Sitre_In', 'Han_Jong-In', 'In_R_Voice', 'In_Extremo', 'In_the_Fishtank', 'Ultimate_fate_of_the_universe', 'Troll_(Internet)'], ['U', 'Uranium', 'U_Khandi', 'U_Ottama', 'U_Thant', 'U_Razak', 'U_Saw', 'U_L_Washington', 'U_Pandita', 'U_Nu', 'U_Brown', 'U_(Super_Junior_song)', 'Soyuz-U', 'UK_railway_stations_–_U', 'Uniform_polyhedron', 'Haplogroup_U_(mtDNA)', 'U_engine', 'Index_of_World_War_II_articles_(U)', 'Neuromedin_U_receptor', 'University_of_Liverpool', 'Indoctrinate_U', 'Neuromedin_U', 'British_U-class_submarine', 'Rack_unit', 'Airline_codes-U', 'SJ_U', 'United_Kingdom', 'U_and_non-U_English', 'U_(album)', 'United_States'], ['Full_stop', 'Names_of_Burma', 'University_of_Yangon', 'Ne_Win', 'Administrative_divisions_of_Burma', 'Wa_people', 'Yangon_River', 'U_Nu', 'Yangon_Technological_University', 'U_Thant', 'Yangon', 'Naypyidaw', 'Greater_Tokyo_Area', 'Allies_of_World_War_II', 'Shiva', '1991_Bangladesh_cyclone', 'Bhopal', 'Ba_Win', 'Doctor_of_Philosophy', 'Walter_Chit_Tun', 'Big_Brother_(UK)', 'Harlem', 'Combining_character', '8888_Uprising', 'Union_Solidarity_and_Development_Association', 'Uncanny', 'Yangon_Region', 'Derby', 'A_Coruña', 'Shwe_Mann'], ['Sulfur', 'S', 'Silurian', 'Ś', 'Sat_Parashar', 'S_V_S_Rama_Rao', 'S_E_A_Holdings', 'S_G_Thakur_Singh', 'Š', 'S_John_Massoud', 'Ŝ', 'S._U._Hastings', 'S_Club', 'S._K._Venkataranga', 'S._B._Tambe', 'Sivaramakrishnan_Murali', 'S_(programming_language)', 'UK_railway_stations_–_S', 'Southern_Hemisphere', 'ATC_code_S', 'Simplified_Chinese_characters', 'Shot_(ice_hockey)', 'United_States_District_Court_for_the_Southern_District_of_Iowa', 'S-type_star', 'Sense_(molecular_biology)', 'S-type_asteroid', '1996_Italian_Indoor_–_Singles', '1996_Trofeo_Conde_de_Godó_–_Singles', \"1996_French_Open_–_Men's_Singles\", 'Haplogroup_S-M230'], ['Full_stop', 'Names_of_Burma', 'University_of_Yangon', 'Ne_Win', 'Administrative_divisions_of_Burma', 'Wa_people', 'Yangon_River', 'U_Nu', 'Yangon_Technological_University', 'U_Thant', 'Yangon', 'Naypyidaw', 'Greater_Tokyo_Area', 'Allies_of_World_War_II', 'Shiva', '1991_Bangladesh_cyclone', 'Bhopal', 'Ba_Win', 'Doctor_of_Philosophy', 'Walter_Chit_Tun', 'Big_Brother_(UK)', 'Harlem', 'Combining_character', '8888_Uprising', 'Union_Solidarity_and_Development_Association', 'Uncanny', 'Yangon_Region', 'Derby', 'A_Coruña', 'Shwe_Mann'], ['Political_divisions_of_the_United_States', 'U.S._state', 'States_of_Brazil', 'States_of_Germany', 'States_and_union_territories_of_India', 'States_of_Austria', 'State_pattern', 'Administrative_divisions_of_Mexico', 'United_States_Department_of_State', 'States_of_Nigeria', 'Federated_state', 'States_of_Venezuela', 'Michigan', 'State_(magazine)', 'United_States_Secretary_of_State', 'State_(computer_science)', 'State_school', 'State_government', 'Hawaii', 'States_and_federal_territories_of_Malaysia', 'States_of_the_German_Confederation', 'State_(MBTA_station)', 'New_York', 'State_Street_(Chicago)', 'Member_state_of_the_European_Union', 'Republic_of_Ireland', 'USSR_State_Prize', 'United_States', 'State_Border_Guard_Service_of_Ukraine', 'New_South_Wales'], ['Area', 'Area_(LDS_Church)', 'Area_(band)', 'Area_(country_subdivision)', 'Area_(nightclub)', 'Area_(EP)', 'Area_(journal)', 'Electric_Area', 'Ark_Area', 'Area_(travel_agency)', 'Miami_metropolitan_area', 'Geography_of_India', 'Surface_area', 'Ranked_list_of_states_and_territories_of_Australia', 'Geography_of_Scotland', 'Charlotte_metropolitan_area', 'Trilinear_filtering', 'Area_51', 'Catanduanes', 'East_Windsor,_Connecticut', 'Ancient_Roman_units_of_measurement', 'Central_Australia', 'Braj', 'Northeastern_Pennsylvania', 'Arnold_Arboretum', 'Tenderloin,_San_Francisco', 'Geography_of_the_United_States', 'Biblical_and_Talmudic_units_of_measurement', 'Recovered_Territories', 'English_units'], ['Area_51', 'Area_51_(1995_video_game)', 'Seattle'], ['No._51_Squadron_RAF', '51', \"Now_That's_What_I_Call_Music!_51_(UK_series)\", 'Saskatchewan_Highway_51', 'Route_51_(MTA_Maryland)', 'Adh-Dhariyat', 'Malaysia_Federal_Route_51', 'Bugatti_Type_51', 'National_Highway_51_(India)', 'Small_nucleolar_RNA_SNORA51', 'Small_nucleolar_RNA_SNORD51', 'London_Buses_route_51', 'UFC_51', 'U.S._Route_51', 'Pennsylvania_House_of_Representatives,_District_51', 'Parker_51', 'February_20', \"California's_51st_State_Assembly_district\", 'Jauchzet_Gott_in_allen_Landen,_BWV_51', '51_(number)', '51_(film)', 'Psalm_51', 'Mexican_Federal_Highway_51', 'Sonnet_51', 'Dick_Butkus', 'Symphony_No._51_(Haydn)', 'Ontario_Highway_51', 'The_Absolute_(Animorphs)', 'Fabric_51', 'FabricLive.51'], ['Locus_(genetics)', 'Space_Shuttle_Challenger_disaster', 'South_Padre_Island', 'Location_(geography)', 'Map_Room_(White_House)', 'Sderot', \"Shenzhen_Bao'an_International_Airport\", 'Rural_Khmer_house', 'Liver', 'Search_for_HMAS_Sydney_and_German_auxiliary_cruiser_Kormoran', 'Nazi_concentration_camps', 'Yellow_Sea', 'Battle_between_HMAS_Sydney_and_German_auxiliary_cruiser_Kormoran', 'Tallapoosa_County,_Alabama', 'Naypyidaw', 'Topkapı_Palace', 'Latvia', 'Drax_power_station', 'Palazzo_Malta', 'World_Geodetic_System', 'CBLFT-DT'], ['Question_mark', '?_(Lost)', 'Rugby_league_positions', '?_(Neal_Morse_album)', 'Chess_annotation_symbols', \"The_Emperor's_New_School\", 'Michigan', 'Pinyin', '?_(EP)', 'Latin_alphabet', '?_(film)', 'Jyutping', 'Yale_romanization_of_Cantonese', 'January_2006_in_Malaysia_and_Singapore', 'Traditional_Chinese_characters', 'Pe̍h-ōe-jī', '?_(bistro)']], 'candidate_entity_priors': [[0.2694610778443102, 0.054131736526946146, 0.0479041916167662, 0.0359281437125745, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.023602794411177744, 0.013413173652694624, 0.012694610778442875], [0.20981793918596725, 0.06200552854828033, 0.05444666857306266, 0.05444666857306266, 0.05444666857306266, 0.05444666857306266, 0.05444666857306266, 0.05444666857306266, 0.05444666857306266, 0.05444666857306266, 0.05444666857306266, 0.0538080259269851, 0.050281193403869814, 0.028691259174530814, 0.016776284434277016, 0.011009436659994225, 0.010675817367267242, 0.009055380802592472, 0.00891240110570987, 0.006529406157659219, 0.005242588885711541, 0.005242588885711541, 0.005147269087789514, 0.0044800305023353325, 0.00428939090649128, 0.004003431512725203, 0.003860451815842163, 0.003669812219998111, 0.0032408731293489938, 0.0032408731293489938], [0.4705882352941141, 0.11764705882353167, 0.08403361344537887, 0.025210084033613033, 0.025210084033613033, 0.025210084033613033, 0.025210084033613033, 0.016806722689075772, 0.016806722689075772, 0.016806722689075772, 0.016806722689075772, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886], [0.09842482461282503, 0.07561976438552914, 0.06253427377418072, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.050590636223070126, 0.021424654425807856, 0.011251252765539102, 0.008150067129323216, 0.007828602764593809, 0.0077718737590527455, 0.007280222377701462, 0.006032184255810027, 0.00597545525026949, 0.005332526520810084, 0.005237978178242566, 0.005029971824593906, 0.005029971824593906, 0.004708507459864236, 0.004689597791350745], [0.4705882352941141, 0.11764705882353167, 0.08403361344537887, 0.025210084033613033, 0.025210084033613033, 0.025210084033613033, 0.025210084033613033, 0.016806722689075772, 0.016806722689075772, 0.016806722689075772, 0.016806722689075772, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886, 0.008403361344537886], [0.49733649419169623, 0.10236499337592048, 0.03329344422907955, 0.031455804318718486, 0.025987785054905108, 0.025397520485207676, 0.023002660731060214, 0.020237750496679623, 0.016399012795120044, 0.014997512816813309, 0.013968585816900626, 0.01376703821382942, 0.011680427734968161, 0.011158775115252846, 0.010992794736252719, 0.010826814357252593, 0.010565988047394495, 0.010269594513465319, 0.010127325617179245, 0.009899544033232188, 0.009890210790036078, 0.009854643565965, 0.009724230411035952, 0.009724230411035952, 0.009617528738821837, 0.009581961514749876, 0.009570105773392852, 0.009570105773392852, 0.009368558170320765, 0.009368558170320765], [0.44163340657054684, 0.054259675762813986, 0.05354463786580836, 0.05318061857278422, 0.050723488344883785, 0.050437473186080536, 0.05017745940534757, 0.05011245596016433, 0.05007345389305639, 0.05007345389305639, 0.05007345389305639, 0.03433481974544642, 0.006929367256464794, 0.0014560771720901072, 0.0008320440983372112, 0.0002470130916938588, 0.00023401240265734098, 0.00023401240265734098, 0.000156008268438229, 0.000156008268438229, 0.00014300757940170615, 0.00013000689036518832, 0.00013000689036518832, 0.00011700620132867049, 0.00011700620132867049, 0.00010400551229215266, 0.00010400551229215266, 0.00010400551229215266, 9.100482325563483e-05, 9.100482325563483e-05], [0.8185938188455949, 0.18096556933341953, 0.00044061182098570893], [0.09255801547079186, 0.08802347292611305, 0.051080288076820926, 0.04547879434515865, 0.04361162976793788, 0.04321152307281988, 0.04201120298746331, 0.04067751400373493, 0.03841024273139488, 0.03654307815417411, 0.036409709255801025, 0.03560949586556374, 0.03320885569485187, 0.027473993064817775, 0.027473993064817775, 0.027207255268071585, 0.02667377967458049, 0.025606828487597013, 0.024806615097359725, 0.024406508402240443, 0.02400640170712244, 0.022405974926646584, 0.022005868231528582, 0.021205654841291294, 0.018805014670579438, 0.01720458789010358, 0.01707121899173049, 0.016137636703121388, 0.01533742331288282, 0.01533742331288282], [0.5045296167247405, 0.13937282229965112, 0.13937282229965112, 0.06480836236933663, 0.03972125435540094, 0.02299651567944281, 0.01742160278745626, 0.016724738675958133, 0.009059233449477195, 0.008362369337979066, 0.007665505226480937, 0.0055749128919860445, 0.0041811846689895835, 0.0041811846689895835, 0.0034843205574913026, 0.0034843205574913026, 0.0034843205574913026, 0.0034843205574913026, 0.0006968641114982807, 0.0006968641114982807, 0.0006968641114982807], [0.9163961038961033, 0.01785714285714306, 0.008928571428571432, 0.00811688311688313, 0.007305194805194826, 0.007305194805194826, 0.006493506493506523, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129]], 'candidate_segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['In', 'which', 'U', '.', 'S', '.', 'state', 'is', 'Area', '51', 'located', '?'], 'candidate_spans': [[1, 1], [3, 3], [5, 5], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11]], 'candidate_entities': [['in.s.03', 'in.s.02', 'in.s.01', 'in.r.01', 'indiana.n.01', 'inch.n.01', 'indium.n.01'], ['u.s.01', 'u.n.03', 'u.n.03', 'uranium.n.01', 'uracil.n.01'], ['randomness.n.01', 's.n.05', 's.n.05', 'mho.n.01', 'south.n.03', 'sulfur.n.01', 'second.n.01'], ['state.n.02', 'department_of_state.n.01', 'state.n.04', 'state.n.03', 'country.n.02', 'state.n.01', 'state.n.06', 'state_of_matter.n.01', 'submit.v.02', 'state.v.01', 'express.v.04'], ['beryllium.n.01', 'be.v.10', 'be.v.08', 'exist.v.01', 'be.v.01', 'be.v.11', 'be.v.02', 'constitute.v.01', 'be.v.03', 'equal.v.01', 'embody.v.02', 'cost.v.01', 'be.v.12', 'be.v.05'], ['area.n.05', 'area.n.06', 'area.n.03', 'area.n.02', 'area.n.01', 'sphere.n.01'], ['fifty-one.s.01'], ['settle.v.04', 'locate.v.01', 'locate.v.03', 'situate.v.01']], 'candidate_entity_priors': [[0.034482758620689655, 0.034482758620689655, 0.034482758620689655, 0.6896551724137931, 0.034482758620689655, 0.13793103448275862, 0.034482758620689655], [0.2, 0.2, 0.2, 0.2, 0.2], [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285], [0.13651877133105803, 0.0034129692832764505, 0.07508532423208192, 0.08532423208191127, 0.0034129692832764505, 0.3720136518771331, 0.0034129692832764505, 0.0034129692832764505, 0.05460750853242321, 0.2525597269624573, 0.010238907849829351], [5.994844433786943e-05, 0.0001798453330136083, 0.0052155146573946405, 0.04208380792518434, 0.6440261375217313, 0.00011989688867573886, 0.1810443019003657, 0.011390204424195192, 0.054073496792758226, 0.016246028415562615, 0.0035369582159342967, 5.994844433786943e-05, 5.994844433786943e-05, 0.04190396259217073], [0.04072398190045249, 0.027149321266968326, 0.09502262443438914, 0.12669683257918551, 0.665158371040724, 0.04524886877828054], [1.0], [0.125, 0.425, 0.125, 0.325]], 'candidate_segment_ids': [0, 0, 0, 0, 0, 0, 0, 0]}}, 'offsets_a': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], 'offsets_b': None}\n",
      "In which U . S . state is Area 51 located ?\n",
      "['[CLS]', 'in', 'which', 'u', '.', 's', '.', 'state', 'is', 'area', '51', 'located', '?', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e7eb2a180>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 14 with text: \n",
      " \t\t[[CLS], in, which, u, ., s, ., state, is, area, 51, located, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([ 101, 1999, 2029, 1057, 1012, 1055, 1012, 2110, 2003, 2181, 4868, 2284,\n",
      "        1029,  102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e7eb2a180>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7f9e901ee640>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e901eeb80>}\n",
      "TextField of length 14 with text: \n",
      " \t\t[[CLS], in, which, u, ., s, ., state, is, area, 51, located, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 14 with text: \n",
      " \t\t[[CLS], in, which, u, ., s, ., state, is, area, 51, located, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([14]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "offsets: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "word_piece_tokens: [['who'], ['is'], ['the'], ['mayor'], ['of'], ['new'], ['york'], ['city'], ['?']]\n",
      "tokens: ['Who', 'is', 'the', 'mayor', 'of', 'New', 'York', 'City', '?']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'who', 'is', 'the', 'mayor', 'of', 'new', 'york', 'city', '?', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['Who', 'is', 'the', 'mayor', 'of', 'New', 'York', 'City', '?'], 'candidate_spans': [[1, 1], [4, 4], [4, 7], [4, 8], [6, 6], [6, 7], [6, 8], [7, 7], [7, 8], [8, 8], [9, 9]], 'candidate_entities': [['The_Who', 'Doctor_Who', 'Who_(magazine)', 'Who_(pronoun)', 'Jim_Neidhart', 'Who?_(album)', 'William_Coventry', 'Who?_(song)', 'Bobby_Who', 'Doctor_Who_(film)', 'Who?_(novel)', 'Who_(Unix)', 'Who_Dat_(Young_Jeezy_song)', 'Guess_Who_(rapper)', 'Speak_Your_Language', 'Who_See', 'Horton_Hears_a_Who!', 'Alfred_Russel_Wallace', 'Casimir_Pulaski', 'Harold_Dieterle', 'Measuring_poverty', 'Ace_Young', 'Victor_Lustig', 'Saint_Patrick', 'Section_28', 'The_Girl_in_the_Fireplace', 'New_York_City_Hall', 'Ken_Jennings', 'Zen_and_the_Art_of_Motorcycle_Maintenance', 'Diana,_Princess_of_Wales'], ['Mayor', 'Burgomaster', 'Mayor_of_New_York_City', 'Mayor_of_Chicago', 'Mayor_of_San_Francisco', 'Mayor_of_London', 'Mayor_of_Mumbai', 'Mayor_of_Gibraltar', 'Michel_Mayor', 'Mayors_in_England', 'Mayor_of_Los_Angeles', 'Mayor_(musical)', 'Mayor_(Buffy_the_Vampire_Slayer)', 'Lord_Mayor_of_Liverpool', 'Mayor_of_Cape_Town', 'Burgemeester', 'Danny_Mayor', 'Mayor_of_Castile', 'Mayor_of_Honolulu', 'Governing_Mayor_of_Berlin', 'Mayor_of_Dunedin', 'Mayor_of_the_Palace', 'Lord_Mayor_of_London', 'Directly_elected_mayor_of_Doncaster', 'Mayor_of_Hamilton,_New_Zealand', 'Mayor_of_Wellington', 'Mayor_of_Raleigh,_North_Carolina', 'Mayor_of_Derry', 'Mayor_of_Kilkenny', 'Mayor_of_Kiev'], ['Mayor_of_New_York_City'], ['Mayor_of_New_York_City'], ['Harry_Stewart_New', 'New_feminism', 'New_(film)', 'New_Testament', 'New_antisemitism', 'New_(song)', 'New_South_Wales', 'New_Delhi', 'French_New_Wave', 'New_Island', 'New_World', 'New_York_City', 'New_Latin', 'New_Zealand', 'USS_New_(DD-818)', 'New_River_(Kanawha_River)', 'New_River_(North_Carolina)', 'Northeast_blackout_of_1965', 'New_Journalism', 'New_York', 'New_England_Patriots', 'New_South', 'New_Gate', 'New_College,_Toronto', 'New_Jersey', 'Tom_New', 'John_C._New', 'New_Orleans_Pelicans', 'New_Town,_Edinburgh', 'New_Order'], ['New_York', 'New_York_City', 'New_York_(magazine)', 'United_States_congressional_delegations_from_New_York', 'New_York_(film)', 'Province_of_New_York', 'Manhattan', 'New_York_Knicks', 'New_York_metropolitan_area', 'New_York_GAA', 'New_York_Liberty', 'New_York_Yankees', 'New_York_Stock_Exchange', 'Miss_New_York_USA', 'New_York_(album)', 'New_York_Republican_State_Committee', 'New_York_Mets', 'New_York-class_battleship', 'John_F._Kennedy_International_Airport', 'New_York_(Paloma_Faith_song)', 'New_York_(Ja_Rule_song)', 'Miss_New_York_Teen_USA', 'Tiffany_Pollard', 'New_York_Harbor', 'Federal_Reserve_Bank_of_New_York', 'Pennsylvania_Station_(New_York_City)', 'Miss_New_York', 'USS_New_York_(ACR-2)', 'Roman_Catholic_Archdiocese_of_New_York', 'New_York_(U2_song)'], ['New_York_City', 'New_York', 'Manhattan', 'New_York_City_(Brazilian_Girls_album)', 'Pennsylvania_Station_(New_York_City)', 'New_York_metropolitan_area', 'USS_New_York_City_(SSN-696)', 'New_York_City_(band)', 'New_York_City_(Emigrate_song)', 'New_York_Fashion_Week', 'New_York_City_Marathon', 'New_York_City_bid_for_the_2012_Summer_Olympics', 'New_York_City_(album)', 'New_York_City_Subway', 'The_Real_Housewives_of_New_York_City', 'New_York_City_Police_Department', 'New_York_City_water_supply_system', 'WNBC', 'WABC-TV', 'WCBS-TV', 'Bus_depots_of_MTA_Regional_Bus_Operations', 'New_York_City_Department_of_Transportation', 'Labor_Day_Carnival', 'New_York_City_Fire_Department', 'New_York_City_(video_game)', 'Midtown_Manhattan', 'Congestion_pricing_in_New_York_City', 'New_Jersey_Generals', 'Evacuation_Day_(New_York)', 'Greenwich_Village'], ['York', 'York,_Pennsylvania', 'York,_Upper_Canada', 'York_railway_station', 'York,_South_Carolina', 'York_County,_Maine', 'York,_Maine', 'York,_Ontario', 'York_County,_Pennsylvania', 'York_County,_South_Carolina', 'Province_of_York', 'York,_Nebraska', 'York_County,_Virginia', 'National_Register_of_Historic_Places_listings_in_York_County,_Pennsylvania', 'York,_Western_Australia', 'Archbishop_of_York', 'York_Racecourse', 'House_of_York', 'York_City_Knights', 'York_(explorer)', 'MV_York', 'Regional_Municipality_of_York', 'University_of_York', 'City_of_York_(UK_Parliament_constituency)', 'York,_Dane_County,_Wisconsin', 'York,_Clark_County,_Wisconsin', 'Maryland_Route_45', 'York_County,_New_Brunswick', 'Diocese_of_York', 'York_River_(Virginia)'], ['York_City_F.C.', 'York_City_School_District', 'York,_Pennsylvania', '2010–11_York_City_F.C._season', '2007–08_York_City_F.C._season', '2009–10_York_City_F.C._season', '2006–07_York_City_F.C._season', '2008–09_York_City_F.C._season', 'New_York_City', 'History_of_York_City_F.C.'], ['City', 'City_of_London', 'Administrative_divisions_of_New_York', 'City_(New_Jersey)', 'Cities_of_the_Philippines', 'City_(novel)', 'City_status_in_the_United_Kingdom', 'Honda_City', 'London_City_Airport', 'City-state', 'Types_of_inhabited_localities_in_Russia', 'Lego_City', 'Manchester_City_F.C.', 'Central_railway_station,_Brisbane', 'City_University_London', 'GWR_3700_Class', 'Cities_of_Japan', 'City_(typeface)', 'City_(Strapping_Young_Lad_album)', 'Adelaide', 'City_(band)', 'City_(artwork)', 'City_(newspaper)', 'Bowen_Hills_railway_station', 'City_(Client_album)', 'City_Township,_Barton_County,_Missouri', 'City,_Australian_Capital_Territory', 'San_Diego', 'City_car', 'City_(magazine)'], ['Question_mark', '?_(Lost)', 'Rugby_league_positions', '?_(Neal_Morse_album)', 'Chess_annotation_symbols', \"The_Emperor's_New_School\", 'Michigan', 'Pinyin', '?_(EP)', 'Latin_alphabet', '?_(film)', 'Jyutping', 'Yale_romanization_of_Cantonese', 'January_2006_in_Malaysia_and_Singapore', 'Traditional_Chinese_characters', 'Pe̍h-ōe-jī', '?_(bistro)']], 'candidate_entity_priors': [[0.27126923076923193, 0.10634615384615292, 0.08480769230769412, 0.038038461538461195, 0.03342307692307671, 0.03342307692307671, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.03311538461538452, 0.01999999999999996, 0.01476923076923056, 0.011692307692307571, 0.008307692307692387, 0.007692307692307473, 0.006769230769230894, 0.0049230769230768886, 0.00461538461538459, 0.003999999999999991, 0.003999999999999991, 0.003999999999999991, 0.0036923076923076927, 0.0036923076923076927, 0.0033846153846153943], [0.5183833817864864, 0.04969671475144521, 0.039559875441826806, 0.02561927051119103, 0.024972238214832555, 0.016874530990708306, 0.016796102833573464, 0.016443176126469096, 0.014776577787363201, 0.014541293315960057, 0.013678583587482323, 0.013639369508915247, 0.013502120233930139, 0.013482513194646254, 0.013423692076795295, 0.013345263919661144, 0.013345263919661144, 0.013286442801810187, 0.013090372408974116, 0.013070765369690925, 0.01303155129112385, 0.012894302016138047, 0.012894302016138047, 0.012855087937570972, 0.012815873859003896, 0.012815873859003896, 0.012815873859003896, 0.012796266819720705, 0.012776659780436822, 0.012776659780436822], [1.0], [1.0], [0.09425606588183326, 0.08752279887249212, 0.08326286409108523, 0.06257668711656397, 0.05327474713977803, 0.04795777372464469, 0.044818438069971295, 0.0395332449013427, 0.037841983087381834, 0.037207759907146205, 0.03633034875366226, 0.03488227491294972, 0.033613828552478464, 0.026605593323384268, 0.025791742662908585, 0.024068700602442983, 0.0234662576687121, 0.023043442215221276, 0.021140772674515616, 0.018815287680317906, 0.016880837893107504, 0.016278394959376618, 0.015823799259382272, 0.01543276405239619, 0.015221356325651388, 0.015189576079146644, 0.012684463604708878, 0.012441275631459333, 0.012229867904714533, 0.011807052451224195], [0.6740615113811484, 0.15013833239867524, 0.017392424509258934, 0.008614759966229736, 0.008589453684598267, 0.00810863433360035, 0.007721809742947918, 0.007569972053159102, 0.006886702449109431, 0.005975676310376626, 0.005769610874234674, 0.005657540198438116, 0.005541854339551451, 0.00537194073431156, 0.0053538648188604845, 0.0053249433541388185, 0.005317712987958424, 0.00521287267834235, 0.005202027129071669, 0.005198411945981472, 0.0051586449319892145, 0.005151414565808731, 0.005151414565808731, 0.0051261082841772615, 0.005108032368726275, 0.0050971868194555955, 0.0050899564532752, 0.005075495720914322, 0.005057419805463337, 0.004974270594388446], [0.588712368028073, 0.015109064634840257, 0.014789874967088817, 0.014615771511951401, 0.014563012889182663, 0.014404737020876458, 0.014317685293308043, 0.014175237011831867, 0.014162047356139683, 0.014159409425001246, 0.014154133562724372, 0.014146219769309062, 0.014138305975893752, 0.01413039218247844, 0.014088185284263453, 0.01403278873035628, 0.014030150799217843, 0.014027512868079406, 0.014027512868079406, 0.014022237005802532, 0.014019599074664095, 0.014019599074664095, 0.014019599074664095, 0.014019599074664095, 0.014019599074664095, 0.014019599074664095, 0.014019599074664095, 0.014019599074664095, 0.014019599074664095, 0.014016961143525658], [0.49189032148069056, 0.05068771688537083, 0.02506277120317958, 0.023316646585897542, 0.02145713725320706, 0.021321075594717936, 0.021185013936227792, 0.02095824450541292, 0.020595413416106892, 0.018985350457315, 0.018980601359286454, 0.017738118587827114, 0.017035133352297758, 0.016554168449557777, 0.016377502002931782, 0.01630947117368773, 0.0157425475966475, 0.01510759319036322, 0.015016885418037473, 0.014835469873383952, 0.014467889686051406, 0.014313900182508119, 0.014223192410181358, 0.01306666831302023, 0.01261312945138947, 0.012545098622144398, 0.010164019598578084, 0.00995992711084348, 0.009801188509272462, 0.009687803793864518], [0.58903182125931, 0.1979237192507348, 0.19634394041976802, 0.0036109230422026566, 0.0029338749717896695, 0.0028210336267208086, 0.0025953509365831467, 0.0022568269013766825, 0.002143985556307822, 0.00033852403520649943], [0.5270548578263492, 0.06026662317185873, 0.0397712173109331, 0.03585733703039179, 0.027791659870602888, 0.021848529331810876, 0.021132169847224512, 0.019619855379764312, 0.017895286250203896, 0.015706844995378253, 0.013809384004784167, 0.013782852172021971, 0.013437938346109887, 0.012774642527047915, 0.011448050888924857, 0.011288859892349913, 0.011129668895775853, 0.010997009731963107, 0.010864350568151243, 0.010519436742239157, 0.010519436742239157, 0.010280650247376741, 0.010227586581851465, 0.009962268254226853, 0.009007122274778075, 0.009007122274778075, 0.008954058609253683, 0.008396890121241734, 0.008384059152938616, 0.008264230957429427], [0.9163961038961033, 0.01785714285714306, 0.008928571428571432, 0.00811688311688313, 0.007305194805194826, 0.007305194805194826, 0.006493506493506523, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129]], 'candidate_segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['Who', 'is', 'the', 'mayor', 'of', 'New', 'York', 'City', '?'], 'candidate_spans': [[1, 1], [2, 2], [4, 4], [6, 6], [6, 7], [6, 8], [7, 7], [8, 8]], 'candidate_entities': [['world_health_organization.n.01'], ['beryllium.n.01', 'be.v.10', 'be.v.08', 'exist.v.01', 'be.v.01', 'be.v.11', 'be.v.02', 'constitute.v.01', 'be.v.03', 'equal.v.01', 'embody.v.02', 'cost.v.01', 'be.v.12', 'be.v.05'], ['mayor.n.01'], ['new.s.11', 'new.s.04', 'new.s.10', 'modern.s.05', 'new.s.08', 'raw.s.12', 'new.a.01', 'fresh.s.04', 'newfangled.s.01', 'new.s.05', 'new.a.06', 'newly.r.01'], ['new_york.n.02', 'new_york.n.03', 'new_york.n.01'], ['new_york.n.01'], ['york.n.01'], ['city.n.03', 'city.n.01', 'city.n.02']], 'candidate_entity_priors': [[1.0], [5.994844433786943e-05, 0.0001798453330136083, 0.0052155146573946405, 0.04208380792518434, 0.6440261375217313, 0.00011989688867573886, 0.1810443019003657, 0.011390204424195192, 0.054073496792758226, 0.016246028415562615, 0.0035369582159342967, 5.994844433786943e-05, 5.994844433786943e-05, 0.04190396259217073], [1.0], [0.0026455026455026454, 0.015873015873015872, 0.0026455026455026454, 0.0026455026455026454, 0.0026455026455026454, 0.031746031746031744, 0.8227513227513228, 0.09788359788359788, 0.0026455026455026454, 0.010582010582010581, 0.0026455026455026454, 0.005291005291005291], [0.26153846153846155, 0.015384615384615385, 0.7230769230769231], [1.0], [1.0], [0.016666666666666666, 0.8666666666666667, 0.11666666666666667]], 'candidate_segment_ids': [0, 0, 0, 0, 0, 0, 0, 0]}}, 'offsets_a': [2, 3, 4, 5, 6, 7, 8, 9, 10], 'offsets_b': None}\n",
      "Who is the mayor of New York City ?\n",
      "['[CLS]', 'who', 'is', 'the', 'mayor', 'of', 'new', 'york', 'city', '?', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7fa03a6adec0>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 11 with text: \n",
      " \t\t[[CLS], who, is, the, mayor, of, new, york, city, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([ 101, 2040, 2003, 1996, 3664, 1997, 2047, 2259, 2103, 1029,  102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7fa03a6adec0>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7f9e901ee1c0>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e901c8ca0>}\n",
      "TextField of length 11 with text: \n",
      " \t\t[[CLS], who, is, the, mayor, of, new, york, city, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 11 with text: \n",
      " \t\t[[CLS], who, is, the, mayor, of, new, york, city, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([11]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "offsets: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "word_piece_tokens: [['which'], ['countries'], ['have'], ['places'], ['with'], ['more'], ['than'], ['two'], ['caves'], ['?']]\n",
      "tokens: ['Which', 'countries', 'have', 'places', 'with', 'more', 'than', 'two', 'caves', '?']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'which', 'countries', 'have', 'places', 'with', 'more', 'than', 'two', 'caves', '?', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['Which', 'countries', 'have', 'places', 'with', 'more', 'than', 'two', 'caves', '?'], 'candidate_spans': [[1, 1], [2, 2], [4, 4], [9, 9], [10, 10]], 'candidate_entities': [['Wilhelm_Canaris', 'Gluten-sensitive_enteropathy_associated_conditions'], ['Country', 'Communist_state', 'Eurozone', 'Brazil', 'ABC_nations', 'Dadao_government_(Shanghai_1937–40)', 'Nation', 'Countries_of_the_United_Kingdom', 'Israel', 'National_service', 'Lists_of_countries_and_territories', 'ISO_3166-1_alpha-2', 'Abortion_in_Nicaragua', 'Yugoslavia', 'Sovereignty', 'Surrogacy', 'Robert_Mugabe', 'Australia', 'Constituent_country', 'Hemp', 'Corruption_Perceptions_Index', 'Spain', 'War_in_Darfur', 'Ethiopia', 'Incitement_to_ethnic_or_racial_hatred', 'Ninja_World', 'American_exceptionalism', 'Switzerland', 'Whaling', 'Country_code_top-level_domain'], ['Lists_of_places_in_Kansas', 'Places_(Jan_Garbarek_album)', 'Places_(Béla_Fleck_album)', 'People,_Places,_Pieces', 'Places_(Casiopea_album)', 'African-American_historic_places', 'High_Places', 'Places_in_Harry_Potter', 'Nottinghamshire', 'Sites_and_places_associated_with_Arthurian_legend', 'Places_of_interest_in_Dorset', 'The_Dark_Tower_(series)', 'Places_of_interest_in_the_Death_Valley_area', \"Places_in_The_Hitchhiker's_Guide_to_the_Galaxy\", 'Location_(geography)', 'Tobias', 'Cranbourne,_Victoria', 'Bender,_Moldova', 'COPS_(1988_TV_series)', 'Satomi', 'Akiyama', 'Tappahannock,_Virginia', 'El_Cerrito,_California', 'Gustavo', 'Roman_Catholic_Archdiocese_of_Cambrai', 'Theophilus', 'Delaware,_Ohio', 'Buddhism_by_country', 'Lists_of_places', 'Roscoe'], ['Cave', 'Qumran_Caves', 'Caves_of_the_Mendip_Hills', 'Wookey_Hole_Caves', 'Caves_of_Han-sur-Lesse', 'Cave_diving', 'Batcave', 'Analogy_of_the_Cave', 'Mogao_Caves', 'Elephanta_Caves', 'Carlsbad_Caverns_National_Park', 'Near_Caves', 'Wine_cave', 'Speleology', 'Ajanta_Caves', 'Caving', 'Aggtelek_National_Park', 'Caves_of_Nerja', 'Chauvet_Cave', 'Cave_insect', 'Pertosa_Caves', 'Maya_cave_sites', 'Sea_cave', 'Glacier_cave', 'Nidderdale_Caves', 'Yagura_(tombs)'], ['Question_mark', '?_(Lost)', 'Rugby_league_positions', '?_(Neal_Morse_album)', 'Chess_annotation_symbols', \"The_Emperor's_New_School\", 'Michigan', 'Pinyin', '?_(EP)', 'Latin_alphabet', '?_(film)', 'Jyutping', 'Yale_romanization_of_Cantonese', 'January_2006_in_Malaysia_and_Singapore', 'Traditional_Chinese_characters', 'Pe̍h-ōe-jī', '?_(bistro)']], 'candidate_entity_priors': [[0.84444444444444, 0.15555555555556], [0.4070281885981535, 0.10446214132221003, 0.10338768802932652, 0.10300846922007353, 0.10294526608519804, 0.10294526608519804, 0.02275312855517642, 0.008785235747692964, 0.0054354695992919755, 0.004929844520288233, 0.0047402351156617326, 0.0041714069017823345, 0.002654531664770591, 0.0024649222601440903, 0.0020857034508911933, 0.001769687776513693, 0.001769687776513693, 0.0014536721021362442, 0.0013904689672607953, 0.0012640626975097954, 0.0012640626975097954, 0.0012008595626342954, 0.001137656427758795, 0.0010744532928833467, 0.0010744532928833467, 0.0010744532928833467, 0.0010112501580078464, 0.0009480470231323464, 0.0008848438882568465, 0.0008848438882568465], [0.22349168169973865, 0.10085521480590347, 0.09905124607469755, 0.0932384579408043, 0.0932384579408043, 0.0932384579408043, 0.0932384579408043, 0.035678492683904106, 0.025856885147324135, 0.022649829625175415, 0.021046301864101054, 0.016837041491280506, 0.011024253357386158, 0.010022048506714894, 0.007817197835237438, 0.006013229104028713, 0.004008819402685901, 0.0038083784325515925, 0.0038083784325515925, 0.0038083784325515925, 0.0036079374624172836, 0.0036079374624172836, 0.0034074964922829742, 0.0034074964922829742, 0.0032070555221487213, 0.0030066145520144124, 0.0030066145520144124, 0.0028061735818801035, 0.00260573261174585, 0.00260573261174585], [0.4547101449275345, 0.13687600644122486, 0.12650966183574985, 0.12630837359097985, 0.12510064412238486, 0.007347020933977492, 0.005535426731078994, 0.0030193236714975966, 0.002717391304347847, 0.0018115942028985481, 0.0016103059581320483, 0.0014090177133655485, 0.0013083735909822985, 0.001006441223832549, 0.000905797101449299, 0.000905797101449299, 0.0006038647342994993, 0.0006038647342994993, 0.0006038647342994993, 0.0005032206119162494, 0.00010064412238325489, 0.00010064412238325489, 0.00010064412238325489, 0.00010064412238325489, 0.00010064412238325489, 0.00010064412238325489], [0.9163961038961033, 0.01785714285714306, 0.008928571428571432, 0.00811688311688313, 0.007305194805194826, 0.007305194805194826, 0.006493506493506523, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129]], 'candidate_segment_ids': [0, 0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['Which', 'countries', 'have', 'places', 'with', 'more', 'than', 'two', 'caves', '?'], 'candidate_spans': [[2, 2], [3, 3], [4, 4], [6, 6], [6, 7], [8, 8], [9, 9]], 'candidate_entities': [['nation.n.02', 'state.n.04', 'area.n.01', 'country.n.02', 'country.n.04'], ['rich_person.n.01', 'give_birth.v.01', 'have.v.12', 'suffer.v.02', 'get.v.03', 'have.v.11', 'induce.v.02', 'consume.v.02', 'take.v.35', 'hold.v.03', 'experience.v.03', 'have.v.01', 'own.v.01', 'have.v.09', 'receive.v.01', 'accept.v.02', 'have.v.17', 'have.v.07', 'have.v.02', 'have.v.10'], ['put.v.01', 'topographic_point.n.01', 'place.n.02', 'place.n.03', 'place.n.04', 'place.v.02', 'stead.n.01', 'place.n.06', 'rate.v.01', 'home.n.01', 'position.n.06', 'place.v.05', 'locate.v.03', 'position.n.01', 'place.v.06', 'place.n.12', 'seat.n.01', 'place.n.10', 'identify.v.01', 'target.v.01', 'space.n.07', 'place.n.15', 'plaza.n.01', 'place.n.13', 'place.v.11', 'set.v.09', 'place.v.09', 'place.v.16', 'place.v.15', 'station.v.01'], ['more.a.01', 'more.a.02', 'more.r.01', 'more.r.02', 'more.n.01'], ['more.a.01'], ['two.s.01', 'deuce.n.04', 'two.n.01'], ['cave.n.01', 'cave.v.02', 'cave.v.01']], 'candidate_entity_priors': [[0.1015625, 0.5390625, 0.03125, 0.234375, 0.09375], [0.0004438526409232135, 0.001775410563692854, 0.005326231691078562, 0.002663115845539281, 0.02885042166000888, 0.01154016866400355, 0.0039946737683089215, 0.01908566355969818, 0.0013315579227696406, 0.013759431868619618, 0.09809143364403018, 0.5339547270306259, 0.06391478029294274, 0.01287172658677319, 0.003550821127385708, 0.003550821127385708, 0.001775410563692854, 0.014203284509542832, 0.1677762982689747, 0.01154016866400355], [0.3434343434343434, 0.19696969696969696, 0.09848484848484848, 0.05808080808080808, 0.045454545454545456, 0.03535353535353535, 0.025252525252525252, 0.020202020202020204, 0.020202020202020204, 0.017676767676767676, 0.012626262626262626, 0.012626262626262626, 0.012626262626262626, 0.010101010101010102, 0.010101010101010102, 0.007575757575757576, 0.007575757575757576, 0.007575757575757576, 0.007575757575757576, 0.007575757575757576, 0.005050505050505051, 0.005050505050505051, 0.005050505050505051, 0.005050505050505051, 0.005050505050505051, 0.005050505050505051, 0.005050505050505051, 0.0025252525252525255, 0.0025252525252525255, 0.0025252525252525255], [0.21986970684039087, 0.11074918566775244, 0.6107491856677525, 0.057003257328990226, 0.0016286644951140066], [1.0], [0.9356617647058824, 0.001838235294117647, 0.0625], [0.7142857142857143, 0.14285714285714285, 0.14285714285714285]], 'candidate_segment_ids': [0, 0, 0, 0, 0, 0, 0]}}, 'offsets_a': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'offsets_b': None}\n",
      "Which countries have places with more than two caves ?\n",
      "['[CLS]', 'which', 'countries', 'have', 'places', 'with', 'more', 'than', 'two', 'caves', '?', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e88fc03c0>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 12 with text: \n",
      " \t\t[[CLS], which, countries, have, places, with, more, than, two, caves, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([  101,  2029,  3032,  2031,  3182,  2007,  2062,  2084,  2048, 10614,\n",
      "         1029,   102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e88fc03c0>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7f9e90180dc0>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e7e6f34c0>}\n",
      "TextField of length 12 with text: \n",
      " \t\t[[CLS], which, countries, have, places, with, more, than, two, caves, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 12 with text: \n",
      " \t\t[[CLS], which, countries, have, places, with, more, than, two, caves, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([12]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "offsets: [1, 2, 3, 4, 5, 6]\n",
      "word_piece_tokens: [['where'], ['did'], ['abraham'], ['lincoln'], ['die'], ['?']]\n",
      "tokens: ['Where', 'did', 'Abraham', 'Lincoln', 'die', '?']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'where', 'did', 'abraham', 'lincoln', 'die', '?', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['Where', 'did', 'Abraham', 'Lincoln', 'die', '?'], 'candidate_spans': [[1, 1], [3, 3], [3, 4], [4, 4], [5, 5], [6, 6]], 'candidate_entities': [['Himeji,_Hyōgo', 'Torah', 'Where_No_Man_Has_Gone_Before', 'Where_Once_We_Walked', 'Where_I_Come_From_(album)', 'Where.com', 'Wonder_Where', 'Where_(SQL)', 'Detroit', 'Peter_Popoff', 'Arnhem', \"Galileo's_Leaning_Tower_of_Pisa_experiment\", 'The_Little_Mermaid_(1989_film)', \"I've_fallen_and_I_can't_get_up!\", 'Cheshunt', 'University_of_Kent', 'Sandy,_Bedfordshire', 'Santander,_Spain', 'Catholic_sex_abuse_cases', 'Geographic_coordinate_system', 'Where_the_Wild_Things_Are', 'Chinese_economic_stimulus_program', 'Darth_Vader', 'Give-away_shop', 'Where_the_Red_Fern_Grows', 'Idealism', 'Sun_Wukong', \"Saint_Patrick's_Day\", 'Where_Is_the_Love?', 'Joe_Arpaio'], ['Abraham', 'Abraham_in_Islam', 'Pope_Abraham_of_Alexandria', 'Abraham_Lake', 'Abraham,_West_Virginia', 'Alan_Abraham', 'Hérard_Abraham', 'Abraham_Lincoln', 'Abraham_(film)', 'John_Abraham_(American_football)', 'Spencer_Abraham', 'Abraham_González_Casanova', 'William_Abraham_(trade_unionist)', 'Winston_Abraham', 'Abraham_(name)', 'Grampa_Simpson', 'Abraham_of_Strathearn', 'Binding_of_Isaac', 'Martin_Abraham', 'Mount_Abraham_(Vermont)', 'Mount_Abraham_(Maine)', 'Abraham_Maslow', 'Esther_Hicks', 'Abraham_Gneki_Guié', 'Ralph_Abraham', 'Abraham_Mendelssohn_Bartholdy', 'Max_Abraham', 'Karel_Abraham', 'Abraham_of_Makuria', 'John_Abraham_(actor)'], ['Abraham_Lincoln', 'Abraham_Lincoln_(1930_film)', 'Abraham_Lincoln_(train)', 'USS_Abraham_Lincoln_(CVN-72)', 'Abraham_Lincoln_(captain)', 'Abraham_Lincoln_(Pullman_car)', 'Abraham_Lincoln_(French_1920)', 'Lincoln_Memorial', 'USS_Abraham_Lincoln_(SSBN-602)', 'Abraham_Lincoln_Brigade', 'Abraham_Lincoln_High_School_(Philadelphia)', 'Abraham_Lincoln_(French_1912)', 'Fort_Abraham_Lincoln', 'Abraham_Lincoln_cultural_depictions', 'Abraham_Lincoln,_Friend_of_the_People', 'Abraham_Lincoln_(Morse_books)', 'Lincoln_High_School_(Tacoma,_Washington)', 'Abraham_Lincoln_II', 'Carrier_Strike_Group_Nine', 'Abraham_Lincoln_High_School_(Brooklyn)', 'Abraham_Lincoln_in_the_Black_Hawk_War', 'Sexuality_of_Abraham_Lincoln', 'Gettysburg_Address', 'Assassination_of_Abraham_Lincoln', 'Abraham_Lincoln_(Cecere)', 'Lincoln–Douglas_debates', \"Lincoln's_House_Divided_Speech\", 'United_States_presidential_election,_1860', 'Republican_Party_(United_States)', 'Abraham_Lincoln_and_slavery'], ['Lincoln,_England', 'Abraham_Lincoln', 'Lincoln_Motor_Company', 'Lincoln,_Nebraska', 'Lincoln,_Illinois', 'Lincoln_County,_Montana', 'Lincoln,_Massachusetts', 'Lincoln,_Rhode_Island', 'Lincoln_County,_Oklahoma', 'Lincoln_County,_Kansas', 'Lincoln,_California', 'Lincoln_County,_Nevada', 'Lincoln_County,_Tennessee', 'Lincoln,_New_Hampshire', 'Lincoln_(UK_Parliament_constituency)', 'Lincoln_County,_North_Carolina', 'National_Register_of_Historic_Places_listings_in_West_Virginia', 'Lincoln_County,_Kentucky', 'Lincoln,_Pennsylvania', 'Lincoln_County,_Colorado', 'Lincoln,_Montana', 'Lincoln,_Alabama', 'Lincoln_County,_Wyoming', 'Lincoln_County,_Nebraska', 'Lincoln_County,_South_Dakota', 'Lincoln_County,_Missouri', 'Lincoln_Parish,_Louisiana', 'Lincoln_County,_Maine', 'Lincoln,_Maine', 'Lincoln_(electoral_district)'], ['Die_(manufacturing)', 'Die_(integrated_circuit)', 'Integrated_circuit', 'Coining_(mint)', 'Bill_Oddie', 'Dice', 'Death', 'Masjid_al-Haram', 'Per_\"Dead\"_Ohlin', 'Tap_and_die', 'Thunderbirds_Are_Go', 'Coining_(metalworking)', 'Rabbit_starvation', 'Galveston,_Texas', 'Death_of_Ian_Tomlinson', 'Delirium_tremens', 'Percy_Bysshe_Shelley', 'Iraq_War_troop_surge_of_2007', 'June_2011_lunar_eclipse', 'Air_New_Zealand', 'David_Icke', 'Pindar', 'CD-i_games_from_The_Legend_of_Zelda_series', 'German_grammar', 'Shalwar_kameez', 'Nintendo', 'Honor_killing', 'Hyponatremia', 'Yotsuba&!', 'Snow_Crash'], ['Question_mark', '?_(Lost)', 'Rugby_league_positions', '?_(Neal_Morse_album)', 'Chess_annotation_symbols', \"The_Emperor's_New_School\", 'Michigan', 'Pinyin', '?_(EP)', 'Latin_alphabet', '?_(film)', 'Jyutping', 'Yale_romanization_of_Cantonese', 'January_2006_in_Malaysia_and_Singapore', 'Traditional_Chinese_characters', 'Pe̍h-ōe-jī', '?_(bistro)']], 'candidate_entity_priors': [[0.13333333333333486, 0.11414141414141488, 0.0999999999999999, 0.0999999999999999, 0.0999999999999999, 0.0999999999999999, 0.0999999999999999, 0.04545454545454545, 0.03939393939393946, 0.020202020202019978, 0.014141414141413984, 0.011111111111110988, 0.00909090909090899, 0.00909090909090899, 0.00808080808080799, 0.00808080808080799, 0.00808080808080799, 0.00808080808080799, 0.00808080808080799, 0.007070707070706992, 0.007070707070706992, 0.007070707070706992, 0.006060606060605993, 0.006060606060605993, 0.0050505050505049946, 0.0050505050505049946, 0.0050505050505049946, 0.0050505050505049946, 0.0050505050505049946, 0.0050505050505049946], [0.7848134873224473, 0.0797578374450665, 0.018291447455756525, 0.012995451591942897, 0.010116889196307991, 0.006710823254871574, 0.0058689136221677, 0.005820006008649662, 0.005453198907264175, 0.004300376588624099, 0.004300376588624099, 0.004090772530689549, 0.004038371516205837, 0.003933569487238612, 0.003933569487238612, 0.0036715644148204484, 0.003619163400336737, 0.003510867970403937, 0.0034619603568858, 0.003406065941436613, 0.0033012639124693865, 0.0031475542699840237, 0.0029903512265330866, 0.0028855491975657626, 0.0028331481830821494, 0.0028331481830821494, 0.0026759451396312127, 0.002620050724182025, 0.0023615390527294356, 0.0022567370237621116], [0.5047071811677979, 0.02683075368589862, 0.026738711688157852, 0.02654440080403777, 0.026329636142642637, 0.025900106819851863, 0.025889879931213833, 0.025889879931213833, 0.0254398968311475, 0.025337627944768695, 0.025245585947027926, 0.025245585947027926, 0.025235359058389896, 0.025235359058389896, 0.025235359058389896, 0.025235359058389896, 0.025235359058389896, 0.025235359058389896, 0.025235359058389896, 0.025235359058389896, 0.0017692517343524921, 0.0015851677388706964, 0.0014113106320268315, 0.0008590586455815453, 0.0007670166478406726, 0.00048066376598015413, 0.0003374873250498949, 0.00032726043641201965, 0.00027612599322264313, 0.00020453777275751103], [0.18493280618963148, 0.12523893346580373, 0.1065235418452411, 0.09765429718989187, 0.034721222070194215, 0.027754366123527892, 0.026289012658731042, 0.02356396937331901, 0.022715606841068395, 0.021995784086431325, 0.020504722666111766, 0.01844808622429139, 0.018370962357723262, 0.01752259982547265, 0.017316936181290977, 0.017239812314722852, 0.01712149837815344, 0.017085564581585378, 0.016931316848449122, 0.016879900937403707, 0.016442865693517654, 0.01631432591590289, 0.016134370227243927, 0.01608295431619851, 0.014977512228720803, 0.014694724717969785, 0.014360521296174569, 0.01433481334065186, 0.014231981518561023, 0.01361499058601479], [0.2551850718874254, 0.2060365045375734, 0.10529213826858419, 0.10243703477108299, 0.10202916284286707, 0.09258692770470153, 0.06179259712450453, 0.020393596410726886, 0.008157438564290754, 0.006016110941164597, 0.005608239012949702, 0.004996431120628125, 0.003568879371877218, 0.003059039461609058, 0.002447231569287226, 0.0020393596410726886, 0.0019373916590190669, 0.0017334556949117725, 0.0017334556949117725, 0.001631487712858151, 0.001223615784643613, 0.001223615784643613, 0.001223615784643613, 0.001223615784643613, 0.001223615784643613, 0.0011216478025899914, 0.0011216478025899914, 0.0010196798205363699, 0.0010196798205363699, 0.0009177118384826971], [0.9163961038961033, 0.01785714285714306, 0.008928571428571432, 0.00811688311688313, 0.007305194805194826, 0.007305194805194826, 0.006493506493506523, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129]], 'candidate_segment_ids': [0, 0, 0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['Where', 'did', 'Abraham', 'Lincoln', 'die', '?'], 'candidate_spans': [[2, 2], [3, 3], [3, 4], [4, 4], [5, 5]], 'candidate_entities': [['doctor_of_osteopathy.n.01', 'do.n.02', 'bash.n.02', 'act.v.02', 'dress.v.16', 'do.v.08', 'cause.v.01', 'perform.v.01', 'do.v.13', 'do.v.11', 'make.v.01', 'do.v.03', 'practice.v.01', 'do.v.04', 'suffice.v.01', 'serve.v.09'], ['abraham.n.01'], ['lincoln.n.01'], ['lincoln.n.03', 'lincoln.n.02', 'lincoln.n.01'], ['die.n.01', 'die.n.02', 'die.n.03', 'die.v.11', 'die.v.10', 'die.v.01', 'fail.v.04', 'die.v.09', 'die.v.08', 'die.v.07', 'die.v.03', 'die.v.06', 'die.v.05', 'die.v.02']], 'candidate_entity_priors': [[0.0010080645161290322, 0.0010080645161290322, 0.0010080645161290322, 0.004032258064516129, 0.0030241935483870967, 0.010080645161290322, 0.036290322580645164, 0.17540322580645162, 0.0020161290322580645, 0.0030241935483870967, 0.53125, 0.13608870967741934, 0.021169354838709676, 0.059475806451612906, 0.012096774193548387, 0.0030241935483870967], [1.0], [1.0], [0.25, 0.25, 0.5], [0.04242424242424243, 0.012121212121212121, 0.006060606060606061, 0.006060606060606061, 0.006060606060606061, 0.8606060606060606, 0.012121212121212121, 0.006060606060606061, 0.006060606060606061, 0.006060606060606061, 0.012121212121212121, 0.006060606060606061, 0.006060606060606061, 0.012121212121212121]], 'candidate_segment_ids': [0, 0, 0, 0, 0]}}, 'offsets_a': [2, 3, 4, 5, 6, 7], 'offsets_b': None}\n",
      "Where did Abraham Lincoln die ?\n",
      "['[CLS]', 'where', 'did', 'abraham', 'lincoln', 'die', '?', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7fa03a6add80>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 8 with text: \n",
      " \t\t[[CLS], where, did, abraham, lincoln, die, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([ 101, 2073, 2106, 8181, 5367, 3280, 1029,  102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7fa03a6add80>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7fa0448b60d0>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e7e6f3cd0>}\n",
      "TextField of length 8 with text: \n",
      " \t\t[[CLS], where, did, abraham, lincoln, die, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 8 with text: \n",
      " \t\t[[CLS], where, did, abraham, lincoln, die, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([8]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "offsets: [1, 2, 3, 4, 5, 6, 7]\n",
      "word_piece_tokens: [['which'], ['airports'], ['does'], ['air'], ['china'], ['serve'], ['?']]\n",
      "tokens: ['Which', 'airports', 'does', 'Air', 'China', 'serve', '?']\n",
      "name wiki\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wiki_linking_util.WikiCandidateMentionGenerator object at 0x7fa0448b64f0>\n",
      "name wordnet\n",
      "mention_generator <KBQA.appB.transformer_architectures.kb.wordnet.WordNetCandidateMentionGenerator object at 0x7fa03a5db280>\n",
      "token_candidates: {'tokens': ['[CLS]', 'which', 'airports', 'does', 'air', 'china', 'serve', '?', '[SEP]'], 'segment_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'candidates': {'wiki': {'tokenized_text': ['Which', 'airports', 'does', 'Air', 'China', 'serve', '?'], 'candidate_spans': [[1, 1], [2, 2], [4, 4], [4, 5], [5, 5], [6, 6], [7, 7]], 'candidate_entities': [['Wilhelm_Canaris', 'Gluten-sensitive_enteropathy_associated_conditions'], ['Airport', 'Adnan_Menderes_Airport', 'Larry_Craig', 'Airport_security', 'Rome_and_Vienna_airport_attacks', 'Kobe_Airport', 'Ronald_Reagan_Washington_National_Airport', \"World's_busiest_airports_by_aircraft_movements\", 'LaGuardia_Airport', 'Logan_International_Airport', 'Airport_novel', 'Airport_bus', 'Long_Island_MacArthur_Airport', 'Detroit_Metropolitan_Wayne_County_Airport', 'International_airport'], ['Air_(visual_novel)', 'Air_(classical_element)', 'Air_(music)', 'Aerial_warfare', 'Air_(novel)', 'MacBook_Air', 'Air_(roller_coaster)', 'Air_(free_jazz_trio)', 'Air_(comics)', 'Air_(film)', 'Air_(Stargate_Universe)', 'Atmosphere_of_Earth', 'Air_(Japanese_band)', 'Air_(1977_video_game)', 'Railway_air_brake', 'Air-cooled_engine', 'Air_(Cecil_Taylor_album)', 'Michael_Jordan', 'Air_Force_Amy', 'Giulio_Douhet', 'Air_Attack_(video_game)', 'Air_Pirates', 'Air_Zonk', 'Air_Transport_Auxiliary', 'Don_Coryell', 'Lee_Payne_(bassist)', 'Air_Buster', 'Air_commodore', 'Ethiopian_Air_Force', 'Air_Fortress'], ['Air_China'], ['China', 'China_national_football_team', 'Taiwan', 'Second_Sino-Japanese_War', 'China_at_the_2008_Summer_Olympics', 'Qing_Dynasty', 'China,_Texas', \"People's_Liberation_Army\", \"China_women's_national_football_team\", 'China_national_badminton_team', 'Cinema_of_China', 'History_of_China', 'China_national_cricket_team', 'China_at_the_2004_Summer_Olympics', 'China_at_the_Olympics', 'Chinese_rock', 'Mainland_China', 'A1_Team_China', 'China,_Maine', \"China_women's_national_basketball_team\", 'China_at_the_2010_Winter_Olympics', \"China_women's_national_volleyball_team\", 'China_national_baseball_team', 'China_at_the_2008_Summer_Paralympics', 'China_at_the_2000_Summer_Olympics', \"People's_Bank_of_China\", \"China_men's_national_ice_hockey_team\", 'China_at_the_1992_Summer_Olympics', 'China_(Epcot)', 'China_Baseball_League'], ['Serve_(tennis)', 'Service_of_process', 'United_States_Postal_Service', 'Public_service', 'Domestic_worker', 'Works_of_mercy', 'Military_service', 'Civil_service', 'Server_(computing)', 'Summons', 'Service_of_process_in_Virginia', 'Web_server'], ['Question_mark', '?_(Lost)', 'Rugby_league_positions', '?_(Neal_Morse_album)', 'Chess_annotation_symbols', \"The_Emperor's_New_School\", 'Michigan', 'Pinyin', '?_(EP)', 'Latin_alphabet', '?_(film)', 'Jyutping', 'Yale_romanization_of_Cantonese', 'January_2006_in_Malaysia_and_Singapore', 'Traditional_Chinese_characters', 'Pe̍h-ōe-jī', '?_(bistro)']], 'candidate_entity_priors': [[0.84444444444444, 0.15555555555556], [0.9482636428065195, 0.014410583510512992, 0.008977084809827496, 0.008977084809827496, 0.006142215922513597, 0.005905976848570797, 0.0021261516654854993, 0.0016536735175997994, 0.0011811953697141995, 0.0011811953697141995, 0.0002362390739428299, 0.0002362390739428299, 0.0002362390739428299, 0.0002362390739428299, 0.0002362390739428299], [0.13787489420636073, 0.0838624297914907, 0.04561360313918569, 0.04401015618988943, 0.04073247672539818, 0.03857197814880328, 0.03841194121720427, 0.03521120258521227, 0.03241055628221898, 0.029689928445025188, 0.02832961452642888, 0.02664922674463337, 0.02664922674463337, 0.02544894975763608, 0.024808802031237677, 0.024248672770638784, 0.024088635839039772, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276, 0.022568284988843276], [1.0], [0.7867279459025556, 0.014421681978380927, 0.011689092318318389, 0.01057875245644538, 0.007965127781583654, 0.00753973783450268, 0.00735227785782296, 0.0073450678587198455, 0.007283782866343775, 0.007161212881591637, 0.007020617899081847, 0.0069468341358055515, 0.006876417917020453, 0.006861997918814314, 0.00685478791971129, 0.006847577920608174, 0.00684036792150515, 0.006825947923299012, 0.006634882947067688, 0.006548362957830943, 0.006537547959176316, 0.0064618429685941075, 0.006440212971284944, 0.006422187973527201, 0.006386137978011898, 0.006332062984738852, 0.00631043298742969, 0.006267172992811271, 0.006263567993259759, 0.006256357994156644], [0.5379959650302623, 0.16139878950907866, 0.140551445864156, 0.13449899125756556, 0.00605245460659045, 0.00605245460659045, 0.0040349697377269666, 0.0040349697377269666, 0.0033624747814391394, 0.0006724949562878278, 0.0006724949562878278, 0.0006724949562878278], [0.9163961038961033, 0.01785714285714306, 0.008928571428571432, 0.00811688311688313, 0.007305194805194826, 0.007305194805194826, 0.006493506493506523, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.00568181818181822, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129, 0.0008116883116883129]], 'candidate_segment_ids': [0, 0, 0, 0, 0, 0, 0]}, 'wordnet': {'tokenized_text': ['Which', 'airports', 'does', 'Air', 'China', 'serve', '?'], 'candidate_spans': [[2, 2], [3, 3], [4, 4], [5, 5], [6, 6]], 'candidate_entities': [['airport.n.01'], ['doctor_of_osteopathy.n.01', 'do.n.02', 'bash.n.02', 'act.v.02', 'dress.v.16', 'do.v.08', 'cause.v.01', 'perform.v.01', 'do.v.13', 'do.v.11', 'make.v.01', 'do.v.03', 'practice.v.01', 'do.v.04', 'suffice.v.01', 'serve.v.09'], ['air_travel.n.01', 'air.n.03', 'air.n.08', 'tune.n.01', 'atmosphere.n.03', 'air.n.02', 'breeze.n.01', 'air.n.01', 'air.n.06', 'vent.v.02', 'air.v.05', 'publicize.v.01', 'air.v.03', 'air.v.02', 'air_out.v.01'], ['china.n.02', 'chinaware.n.01', 'china.n.01', 'taiwan.n.01'], ['serve.n.01', 'serve.v.15', 'serve.v.02', 'serve.v.06', 'serve.v.05', 'serve.v.14', 'serve.v.11', 'serve.v.13', 'serve.v.10', 'service.v.01', 'serve.v.07', 'suffice.v.01', 'serve.v.03', 'serve.v.08', 'serve.v.01', 'serve.v.09']], 'candidate_entity_priors': [[1.0], [0.0010080645161290322, 0.0010080645161290322, 0.0010080645161290322, 0.004032258064516129, 0.0030241935483870967, 0.010080645161290322, 0.036290322580645164, 0.17540322580645162, 0.0020161290322580645, 0.0030241935483870967, 0.53125, 0.13608870967741934, 0.021169354838709676, 0.059475806451612906, 0.012096774193548387, 0.0030241935483870967], [0.01, 0.1, 0.01, 0.01, 0.02, 0.3, 0.04, 0.43, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.02], [0.38461538461538464, 0.07692307692307693, 0.46153846153846156, 0.07692307692307693], [0.004347826086956522, 0.004347826086956522, 0.1608695652173913, 0.09130434782608696, 0.09565217391304348, 0.004347826086956522, 0.017391304347826087, 0.004347826086956522, 0.017391304347826087, 0.10434782608695652, 0.08695652173913043, 0.004347826086956522, 0.10869565217391304, 0.034782608695652174, 0.24347826086956523, 0.017391304347826087]], 'candidate_segment_ids': [0, 0, 0, 0, 0]}}, 'offsets_a': [2, 3, 4, 5, 6, 7, 8], 'offsets_b': None}\n",
      "Which airports does Air China serve ?\n",
      "['[CLS]', 'which', 'airports', 'does', 'air', 'china', 'serve', '?', '[SEP]']\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e7e511080>}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 9 with text: \n",
      " \t\t[[CLS], which, airports, does, air, china, serve, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n",
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'tokens'}\n",
      " \tNamespace: tokens, Size: 30522 \n",
      "\n",
      "{'tokens': {'tokens': {'tokens': tensor([  101,  2029, 13586,  2515,  2250,  2859,  3710,  1029,   102])}}}\n",
      "{'tokens': <allennlp.data.fields.text_field.TextField object at 0x7f9e7e511080>, 'segment_ids': <allennlp.data.fields.tensor_field.TensorField object at 0x7f9e8ff43880>, 'candidates': <KBQA.appB.transformer_architectures.kb.dict_field.DictField object at 0x7f9e8ff436d0>}\n",
      "TextField of length 9 with text: \n",
      " \t\t[[CLS], which, airports, does, air, china, serve, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'}\n",
      "Instance with fields:\n",
      " \t tokens: TextField of length 9 with text: \n",
      " \t\t[[CLS], which, airports, does, air, china, serve, ?, [SEP]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t segment_ids: TensorField with shape: torch.Size([9]) and dtype: torch.int64. \n",
      " \t candidates:  \n",
      "\n",
      "tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)\n",
      "{'tokens': {'tokens': tensor([[  101,  2862,  2035,  2604, 26393,  2011, 13938,  2102,  1012,   102,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2040,  2764,  3712,  5051,  1029,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2029,  2111,  2020,  2141,  1999,  2014,  4817, 18964,  1029,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  1999,  2029,  1057,  1012,  1055,  1012,  2110,  2003,  2181,\n",
      "          4868,  2284,  1029,   102],\n",
      "        [  101,  2040,  2003,  1996,  3664,  1997,  2047,  2259,  2103,  1029,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  2029,  3032,  2031,  3182,  2007,  2062,  2084,  2048, 10614,\n",
      "          1029,   102,     0,     0],\n",
      "        [  101,  2073,  2106,  8181,  5367,  3280,  1029,   102,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2029, 13586,  2515,  2250,  2859,  3710,  1029,   102,     0,\n",
      "             0,     0,     0,     0]])}, 'segment_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'candidates': {'wiki': {'candidate_entity_priors': tensor([[[1.0823e-01, 6.4316e-02, 4.2703e-02,  ..., 2.6648e-02,\n",
      "          2.6648e-02, 2.6648e-02],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [5.2199e-01, 5.4423e-02, 5.2931e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[2.7127e-01, 1.0635e-01, 8.4808e-02,  ..., 3.6923e-03,\n",
      "          3.6923e-03, 3.3846e-03],\n",
      "         [1.8887e-01, 1.6703e-01, 8.0026e-02,  ..., 2.7741e-03,\n",
      "          2.6971e-03, 2.5430e-03],\n",
      "         [6.5703e-01, 3.2965e-01, 8.0717e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[8.4444e-01, 1.5556e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.1796e-01, 5.3777e-02, 3.0802e-02,  ..., 2.1226e-02,\n",
      "          9.6297e-03, 7.2562e-03],\n",
      "         [7.0251e-01, 1.5931e-02, 1.4717e-02,  ..., 9.7139e-03,\n",
      "          9.7139e-03, 9.6654e-03],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[8.4444e-01, 1.5556e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [4.0703e-01, 1.0446e-01, 1.0339e-01,  ..., 9.4805e-04,\n",
      "          8.8484e-04, 8.8484e-04],\n",
      "         [2.2349e-01, 1.0086e-01, 9.9051e-02,  ..., 2.8062e-03,\n",
      "          2.6057e-03, 2.6057e-03],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.3333e-01, 1.1414e-01, 1.0000e-01,  ..., 5.0505e-03,\n",
      "          5.0505e-03, 5.0505e-03],\n",
      "         [7.8481e-01, 7.9758e-02, 1.8291e-02,  ..., 2.6201e-03,\n",
      "          2.3615e-03, 2.2567e-03],\n",
      "         [5.0471e-01, 2.6831e-02, 2.6739e-02,  ..., 3.2726e-04,\n",
      "          2.7613e-04, 2.0454e-04],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[8.4444e-01, 1.5556e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [9.4826e-01, 1.4411e-02, 8.9771e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.3787e-01, 8.3862e-02, 4.5614e-02,  ..., 2.2568e-02,\n",
      "          2.2568e-02, 2.2568e-02],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]]), 'candidate_entities': {'ids': tensor([[[184845, 145312, 437595,  ..., 295929, 260022,  13536],\n",
      "         [212329,      0,      0,  ...,      0,      0,      0],\n",
      "         [224175, 436989, 260228,  ...,      0,      0,      0],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[ 53720, 226298, 468574,  ..., 422535, 437179,  17870],\n",
      "         [463935,  13060, 142421,  ..., 431870, 162728, 457156],\n",
      "         [222373,  79308, 368272,  ...,      0,      0,      0],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[397844, 292749,      0,  ...,      0,      0,      0],\n",
      "         [191092, 379501,  18700,  ..., 395964, 131562, 216689],\n",
      "         [203057,  51328, 117464,  ..., 331303, 389967, 144977],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[397844, 292749,      0,  ...,      0,      0,      0],\n",
      "         [180714,  34518, 365532,  ..., 268304,  57654,  82790],\n",
      "         [250672, 447330, 243182,  ..., 228556,  14420, 413021],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[362417, 235345,  41805,  ...,  40643,  51518, 382851],\n",
      "         [410770, 231636,  13620,  ..., 321163, 345244, 351034],\n",
      "         [222932, 316497, 117282,  ..., 131406, 455905, 335828],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[397844, 292749,      0,  ...,      0,      0,      0],\n",
      "         [  7271, 105620,  57907,  ...,      0,      0,      0],\n",
      "         [325198,  61398, 376909,  ..., 153924, 133085, 438218],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]]])}, 'candidate_spans': tensor([[[ 1,  1],\n",
      "         [ 3,  4],\n",
      "         [ 6,  7],\n",
      "         [ 8,  8],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 3,  4],\n",
      "         [ 5,  5],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 4,  4],\n",
      "         [ 6,  8],\n",
      "         [ 9,  9],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5],\n",
      "         [ 6,  6],\n",
      "         [ 7,  7],\n",
      "         [ 9,  9],\n",
      "         [ 9, 10],\n",
      "         [10, 10],\n",
      "         [11, 11],\n",
      "         [12, 12]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 4,  4],\n",
      "         [ 4,  7],\n",
      "         [ 4,  8],\n",
      "         [ 6,  6],\n",
      "         [ 6,  7],\n",
      "         [ 6,  8],\n",
      "         [ 7,  7],\n",
      "         [ 7,  8],\n",
      "         [ 8,  8],\n",
      "         [ 9,  9]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 4,  4],\n",
      "         [ 9,  9],\n",
      "         [10, 10],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 3,  3],\n",
      "         [ 3,  4],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5],\n",
      "         [ 6,  6],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 4,  4],\n",
      "         [ 4,  5],\n",
      "         [ 5,  5],\n",
      "         [ 6,  6],\n",
      "         [ 7,  7],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]]]), 'candidate_segment_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}, 'wordnet': {'candidate_entity_priors': tensor([[[1.7544e-02, 5.7018e-01, 2.1053e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.4337e-02, 8.8889e-01, 9.6774e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.5000e-01, 7.5000e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [8.9686e-02, 5.8296e-02, 4.4843e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[8.7162e-01, 1.3514e-02, 9.7973e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [5.9948e-05, 1.7985e-04, 5.2155e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.0202e-02, 1.0101e-02, 2.0202e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0156e-01, 5.3906e-01, 3.1250e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [4.4385e-04, 1.7754e-03, 5.3262e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.4343e-01, 1.9697e-01, 9.8485e-02,  ..., 2.5253e-03,\n",
      "          2.5253e-03, 2.5253e-03],\n",
      "         ...,\n",
      "         [9.3566e-01, 1.8382e-03, 6.2500e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.1429e-01, 1.4286e-01, 1.4286e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.0081e-03, 1.0081e-03, 1.0081e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0081e-03, 1.0081e-03, 1.0081e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e-02, 1.0000e-01, 1.0000e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]]), 'candidate_entities': {'ids': tensor([[[ 49863,  56747, 108447,  ...,      0,      0,      0],\n",
      "         [  2925,  12562,  18198,  ...,      0,      0,      0],\n",
      "         [ 19751,  21009,      0,  ...,      0,      0,      0],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[ 67002,      0,      0,  ...,      0,      0,      0],\n",
      "         [104359, 104685, 105005,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[ 65293,  65436,  66268,  ...,      0,      0,      0],\n",
      "         [100139, 115193, 116069,  ...,      0,      0,      0],\n",
      "         [ 32892,  74736, 104125,  ...,      0,      0,      0],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 66300,  66313,  67944,  ...,      0,      0,      0],\n",
      "         [ 78805, 104174, 104219,  ...,      0,      0,      0],\n",
      "         [111313,  68735,  68021,  ..., 108936, 109141, 109154],\n",
      "         ...,\n",
      "         [ 12008,  39063,  95331,  ...,      0,      0,      0],\n",
      "         [ 71414, 107098, 110198,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[ 57960,  58811,  62085,  ...,      0,      0,      0],\n",
      "         [ 80475,      0,      0,  ...,      0,      0,      0],\n",
      "         [ 82206,      0,      0,  ...,      0,      0,      0],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]],\n",
      "\n",
      "        [[ 36137,      0,      0,  ...,      0,      0,      0],\n",
      "         [ 57960,  58811,  62085,  ...,      0,      0,      0],\n",
      "         [ 23215,  48108,  55610,  ...,      0,      0,      0],\n",
      "         ...,\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0],\n",
      "         [     0,      0,      0,  ...,      0,      0,      0]]])}, 'candidate_spans': tensor([[[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 5,  5],\n",
      "         [ 6,  7],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 3,  3],\n",
      "         [ 5,  5],\n",
      "         [ 7,  7],\n",
      "         [ 8,  8],\n",
      "         [ 9,  9],\n",
      "         [10, 10],\n",
      "         [11, 11]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 4,  4],\n",
      "         [ 6,  6],\n",
      "         [ 6,  7],\n",
      "         [ 6,  8],\n",
      "         [ 7,  7],\n",
      "         [ 8,  8]],\n",
      "\n",
      "        [[ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 6,  6],\n",
      "         [ 6,  7],\n",
      "         [ 8,  8],\n",
      "         [ 9,  9],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 3,  4],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5],\n",
      "         [ 6,  6],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]]]), 'candidate_segment_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0]])}}}\n",
      "tensor([[  101,  2862,  2035,  2604, 26393,  2011, 13938,  2102,  1012,   102,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2040,  2764,  3712,  5051,  1029,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2029,  2111,  2020,  2141,  1999,  2014,  4817, 18964,  1029,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  1999,  2029,  1057,  1012,  1055,  1012,  2110,  2003,  2181,\n",
      "          4868,  2284,  1029,   102],\n",
      "        [  101,  2040,  2003,  1996,  3664,  1997,  2047,  2259,  2103,  1029,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  2029,  3032,  2031,  3182,  2007,  2062,  2084,  2048, 10614,\n",
      "          1029,   102,     0,     0],\n",
      "        [  101,  2073,  2106,  8181,  5367,  3280,  1029,   102,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2029, 13586,  2515,  2250,  2859,  3710,  1029,   102,     0,\n",
      "             0,     0,     0,     0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[  101,  2862,  2035,  2604, 26393,  2011, 13938,  2102,  1012,   102,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2040,  2764,  3712,  5051,  1029,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2029,  2111,  2020,  2141,  1999,  2014,  4817, 18964,  1029,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  1999,  2029,  1057,  1012,  1055,  1012,  2110,  2003,  2181,\n",
      "          4868,  2284,  1029,   102],\n",
      "        [  101,  2040,  2003,  1996,  3664,  1997,  2047,  2259,  2103,  1029,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  2029,  3032,  2031,  3182,  2007,  2062,  2084,  2048, 10614,\n",
      "          1029,   102,     0,     0],\n",
      "        [  101,  2073,  2106,  8181,  5367,  3280,  1029,   102,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2029, 13586,  2515,  2250,  2859,  3710,  1029,   102,     0,\n",
      "             0,     0,     0,     0]])\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False, False, False, False]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "batch = batcher.iter_batches([train_example.source for train_example in train_examples])\n",
    "source_fields = next(batch)\n",
    "\n",
    "source_fields['tokens']['tokens'] = source_fields['tokens']['tokens']['tokens']\n",
    "source_fields['candidates']['wiki']['candidate_entities']['ids'] = \\\n",
    "    source_fields['candidates']['wiki']['candidate_entities']['ids']['token_characters']\n",
    "\n",
    "candidate_mask = (source_fields['candidates']['wiki']['candidate_entities']['ids'] > 0).type(torch.uint8)\n",
    "source_fields['candidates']['wiki']['candidate_entities']['ids'] -= candidate_mask\n",
    "print(candidate_mask)\n",
    "\n",
    "source_fields['candidates']['wordnet']['candidate_entities']['ids'] = \\\n",
    "    source_fields['candidates']['wordnet']['candidate_entities']['ids']['token_characters']\n",
    "\n",
    "candidate_mask = (source_fields['candidates']['wordnet']['candidate_entities']['ids'] > 0).type(torch.uint8)\n",
    "source_fields['candidates']['wordnet']['candidate_entities']['ids'] -= candidate_mask\n",
    "\n",
    "print(source_fields)\n",
    "all_source_ids = source_fields['tokens']['tokens']\n",
    "all_source_segment_ids = source_fields['segment_ids']\n",
    "print(all_source_ids)\n",
    "print(all_source_segment_ids)\n",
    "max_source_length = 32\n",
    "padding_length = max(max_source_length - len(all_source_ids[0]), 0)\n",
    "num_examples = len(all_source_ids)\n",
    "if padding_length > 0:\n",
    "    source_ids = torch.cat((all_source_ids, torch.full((num_examples,padding_length), fill_value=tokenizer_uncased.pad_token_id)), dim=1)\n",
    "    source_segment_ids = torch.cat((all_source_segment_ids, torch.full((num_examples,padding_length), fill_value=0)), dim=1)\n",
    "source_candidates = source_fields['candidates']\n",
    "all_source_mask = all_source_ids > 0\n",
    "\n",
    "print(all_source_ids)\n",
    "print(all_source_mask)\n",
    "print(all_source_segment_ids)\n",
    "\n",
    "all_source_wiki_candidate_priors = source_fields['candidates']['wiki']['candidate_entity_priors']\n",
    "all_source_wiki_candidate_ids = source_fields['candidates']['wiki']['candidate_entities']['ids']\n",
    "all_source_wiki_candidate_spans = source_fields['candidates']['wiki']['candidate_spans']\n",
    "all_source_wiki_candidate_segment_ids = source_fields['candidates']['wiki']['candidate_segment_ids']\n",
    "\n",
    "all_source_wordnet_candidate_priors = source_fields['candidates']['wordnet']['candidate_entity_priors']\n",
    "all_source_wordnet_candidate_ids = source_fields['candidates']['wordnet']['candidate_entities']['ids']\n",
    "all_source_wordnet_candidate_spans = source_fields['candidates']['wordnet']['candidate_spans']\n",
    "all_source_wordnet_candidate_segment_ids = source_fields['candidates']['wordnet']['candidate_segment_ids']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_triples_ids = torch.tensor(\n",
    "    [f.triples_ids for f in train_features], dtype=torch.long\n",
    ")\n",
    "all_triples_mask = torch.tensor(\n",
    "    [f.triples_mask for f in train_features], dtype=torch.long\n",
    ")\n",
    "all_target_ids = torch.tensor(\n",
    "    [f.target_ids for f in train_features], dtype=torch.long\n",
    ")\n",
    "all_target_mask = torch.tensor(\n",
    "    [f.target_mask for f in train_features], dtype=torch.long\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "train_data = TensorDataset(\n",
    "    all_source_ids,\n",
    "    all_source_mask,\n",
    "    all_source_wiki_candidate_priors,\n",
    "    all_source_wiki_candidate_ids,\n",
    "    all_source_wiki_candidate_spans,\n",
    "    all_source_wiki_candidate_segment_ids,\n",
    "    all_source_wordnet_candidate_priors,\n",
    "    all_source_wordnet_candidate_ids,\n",
    "    all_source_wordnet_candidate_spans,\n",
    "    all_source_wordnet_candidate_segment_ids,\n",
    "    all_triples_ids,\n",
    "    all_triples_mask,\n",
    "    all_target_ids,\n",
    "    all_target_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "06/07/2022 07:55:51 - INFO - __main__ -   ***** Running training *****\n",
      "06/07/2022 07:55:51 - INFO - __main__ -     Num examples = 8\n",
      "06/07/2022 07:55:51 - INFO - __main__ -     Batch size = 2\n",
      "06/07/2022 07:55:51 - INFO - __main__ -     Num epoch = 2\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=2 // 1\n",
    ")\n",
    "\n",
    "num_train_optimization_steps = -1\n",
    "\n",
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p\n",
    "            for n, p in model.named_parameters()\n",
    "            if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.01,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p\n",
    "            for n, p in model.named_parameters()\n",
    "            if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "t_total = (\n",
    "    len(train_dataloader)\n",
    "    // 1\n",
    "    * 2\n",
    ")\n",
    "optimizer = AdamW(\n",
    "    optimizer_grouped_parameters, lr=5e-5, eps=1e-8\n",
    ")\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=int(t_total * 0.1), num_training_steps=t_total\n",
    ")\n",
    "\n",
    "# Start training\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "logger.info(\"  Batch size = %d\", 2)\n",
    "logger.info(\"  Num epoch = %d\", 2)\n",
    "\n",
    "model.train()\n",
    "dev_dataset = {}\n",
    "nb_tr_examples, nb_tr_steps, tr_loss, global_step, best_bleu, best_loss = (\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    -1,\n",
    "    1e6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In forward\n",
      "tokens tensor([[  101,  2029, 13586,  2515,  2250,  2859,  3710,  1029,   102,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2040,  2003,  1996,  3664,  1997,  2047,  2259,  2103,  1029,\n",
      "           102,     0,     0,     0]], device='cuda:0')\n",
      "candidates {'wiki': {'candidate_entity_priors': tensor([[[8.4444e-01, 1.5556e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [9.4826e-01, 1.4411e-02, 8.9771e-03, 8.9771e-03, 6.1422e-03,\n",
      "          5.9060e-03, 2.1262e-03, 1.6537e-03, 1.1812e-03, 1.1812e-03,\n",
      "          2.3624e-04, 2.3624e-04, 2.3624e-04, 2.3624e-04, 2.3624e-04,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.3787e-01, 8.3862e-02, 4.5614e-02, 4.4010e-02, 4.0732e-02,\n",
      "          3.8572e-02, 3.8412e-02, 3.5211e-02, 3.2411e-02, 2.9690e-02,\n",
      "          2.8330e-02, 2.6649e-02, 2.6649e-02, 2.5449e-02, 2.4809e-02,\n",
      "          2.4249e-02, 2.4089e-02, 2.2568e-02, 2.2568e-02, 2.2568e-02,\n",
      "          2.2568e-02, 2.2568e-02, 2.2568e-02, 2.2568e-02, 2.2568e-02,\n",
      "          2.2568e-02, 2.2568e-02, 2.2568e-02, 2.2568e-02, 2.2568e-02],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [7.8673e-01, 1.4422e-02, 1.1689e-02, 1.0579e-02, 7.9651e-03,\n",
      "          7.5397e-03, 7.3523e-03, 7.3451e-03, 7.2838e-03, 7.1612e-03,\n",
      "          7.0206e-03, 6.9468e-03, 6.8764e-03, 6.8620e-03, 6.8548e-03,\n",
      "          6.8476e-03, 6.8404e-03, 6.8259e-03, 6.6349e-03, 6.5484e-03,\n",
      "          6.5375e-03, 6.4618e-03, 6.4402e-03, 6.4222e-03, 6.3861e-03,\n",
      "          6.3321e-03, 6.3104e-03, 6.2672e-03, 6.2636e-03, 6.2564e-03],\n",
      "         [5.3800e-01, 1.6140e-01, 1.4055e-01, 1.3450e-01, 6.0525e-03,\n",
      "          6.0525e-03, 4.0350e-03, 4.0350e-03, 3.3625e-03, 6.7249e-04,\n",
      "          6.7249e-04, 6.7249e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [9.1640e-01, 1.7857e-02, 8.9286e-03, 8.1169e-03, 7.3052e-03,\n",
      "          7.3052e-03, 6.4935e-03, 5.6818e-03, 5.6818e-03, 5.6818e-03,\n",
      "          5.6818e-03, 8.1169e-04, 8.1169e-04, 8.1169e-04, 8.1169e-04,\n",
      "          8.1169e-04, 8.1169e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[2.7127e-01, 1.0635e-01, 8.4808e-02, 3.8038e-02, 3.3423e-02,\n",
      "          3.3423e-02, 3.3115e-02, 3.3115e-02, 3.3115e-02, 3.3115e-02,\n",
      "          3.3115e-02, 3.3115e-02, 3.3115e-02, 3.3115e-02, 3.3115e-02,\n",
      "          3.3115e-02, 2.0000e-02, 1.4769e-02, 1.1692e-02, 8.3077e-03,\n",
      "          7.6923e-03, 6.7692e-03, 4.9231e-03, 4.6154e-03, 4.0000e-03,\n",
      "          4.0000e-03, 4.0000e-03, 3.6923e-03, 3.6923e-03, 3.3846e-03],\n",
      "         [5.1838e-01, 4.9697e-02, 3.9560e-02, 2.5619e-02, 2.4972e-02,\n",
      "          1.6875e-02, 1.6796e-02, 1.6443e-02, 1.4777e-02, 1.4541e-02,\n",
      "          1.3679e-02, 1.3639e-02, 1.3502e-02, 1.3483e-02, 1.3424e-02,\n",
      "          1.3345e-02, 1.3345e-02, 1.3286e-02, 1.3090e-02, 1.3071e-02,\n",
      "          1.3032e-02, 1.2894e-02, 1.2894e-02, 1.2855e-02, 1.2816e-02,\n",
      "          1.2816e-02, 1.2816e-02, 1.2796e-02, 1.2777e-02, 1.2777e-02],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [9.4256e-02, 8.7523e-02, 8.3263e-02, 6.2577e-02, 5.3275e-02,\n",
      "          4.7958e-02, 4.4818e-02, 3.9533e-02, 3.7842e-02, 3.7208e-02,\n",
      "          3.6330e-02, 3.4882e-02, 3.3614e-02, 2.6606e-02, 2.5792e-02,\n",
      "          2.4069e-02, 2.3466e-02, 2.3043e-02, 2.1141e-02, 1.8815e-02,\n",
      "          1.6881e-02, 1.6278e-02, 1.5824e-02, 1.5433e-02, 1.5221e-02,\n",
      "          1.5190e-02, 1.2684e-02, 1.2441e-02, 1.2230e-02, 1.1807e-02],\n",
      "         [6.7406e-01, 1.5014e-01, 1.7392e-02, 8.6148e-03, 8.5895e-03,\n",
      "          8.1086e-03, 7.7218e-03, 7.5700e-03, 6.8867e-03, 5.9757e-03,\n",
      "          5.7696e-03, 5.6575e-03, 5.5419e-03, 5.3719e-03, 5.3539e-03,\n",
      "          5.3249e-03, 5.3177e-03, 5.2129e-03, 5.2020e-03, 5.1984e-03,\n",
      "          5.1586e-03, 5.1514e-03, 5.1514e-03, 5.1261e-03, 5.1080e-03,\n",
      "          5.0972e-03, 5.0900e-03, 5.0755e-03, 5.0574e-03, 4.9743e-03],\n",
      "         [5.8871e-01, 1.5109e-02, 1.4790e-02, 1.4616e-02, 1.4563e-02,\n",
      "          1.4405e-02, 1.4318e-02, 1.4175e-02, 1.4162e-02, 1.4159e-02,\n",
      "          1.4154e-02, 1.4146e-02, 1.4138e-02, 1.4130e-02, 1.4088e-02,\n",
      "          1.4033e-02, 1.4030e-02, 1.4028e-02, 1.4028e-02, 1.4022e-02,\n",
      "          1.4020e-02, 1.4020e-02, 1.4020e-02, 1.4020e-02, 1.4020e-02,\n",
      "          1.4020e-02, 1.4020e-02, 1.4020e-02, 1.4020e-02, 1.4017e-02],\n",
      "         [4.9189e-01, 5.0688e-02, 2.5063e-02, 2.3317e-02, 2.1457e-02,\n",
      "          2.1321e-02, 2.1185e-02, 2.0958e-02, 2.0595e-02, 1.8985e-02,\n",
      "          1.8981e-02, 1.7738e-02, 1.7035e-02, 1.6554e-02, 1.6378e-02,\n",
      "          1.6309e-02, 1.5743e-02, 1.5108e-02, 1.5017e-02, 1.4835e-02,\n",
      "          1.4468e-02, 1.4314e-02, 1.4223e-02, 1.3067e-02, 1.2613e-02,\n",
      "          1.2545e-02, 1.0164e-02, 9.9599e-03, 9.8012e-03, 9.6878e-03],\n",
      "         [5.8903e-01, 1.9792e-01, 1.9634e-01, 3.6109e-03, 2.9339e-03,\n",
      "          2.8210e-03, 2.5954e-03, 2.2568e-03, 2.1440e-03, 3.3852e-04,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [5.2705e-01, 6.0267e-02, 3.9771e-02, 3.5857e-02, 2.7792e-02,\n",
      "          2.1849e-02, 2.1132e-02, 1.9620e-02, 1.7895e-02, 1.5707e-02,\n",
      "          1.3809e-02, 1.3783e-02, 1.3438e-02, 1.2775e-02, 1.1448e-02,\n",
      "          1.1289e-02, 1.1130e-02, 1.0997e-02, 1.0864e-02, 1.0519e-02,\n",
      "          1.0519e-02, 1.0281e-02, 1.0228e-02, 9.9623e-03, 9.0071e-03,\n",
      "          9.0071e-03, 8.9541e-03, 8.3969e-03, 8.3841e-03, 8.2642e-03],\n",
      "         [9.1640e-01, 1.7857e-02, 8.9286e-03, 8.1169e-03, 7.3052e-03,\n",
      "          7.3052e-03, 6.4935e-03, 5.6818e-03, 5.6818e-03, 5.6818e-03,\n",
      "          5.6818e-03, 8.1169e-04, 8.1169e-04, 8.1169e-04, 8.1169e-04,\n",
      "          8.1169e-04, 8.1169e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n",
      "       device='cuda:0'), 'candidate_entities': {'ids': tensor([[[397844, 292749,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [  7271, 105620,  57907, 465936,  11856, 420907,  31244, 137415,\n",
      "          429912, 128647, 454144, 238142, 153484, 299430,  20440,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [325198,  61398, 376909, 250478, 197057, 309405, 340090,  96994,\n",
      "          288214, 106413, 257665,  89570, 134161, 270126,  49853, 379350,\n",
      "          303872, 194147, 403275,  83402, 282951,  12304, 195461, 328513,\n",
      "           38736,  69495, 325403, 153924, 133085, 438218],\n",
      "         [ 24746,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [328870, 385128,  68616,  11199,  48435,  32718, 105666,  34804,\n",
      "          231663,  19760, 117124,  27063, 296930, 287376, 163846, 150541,\n",
      "          236720,  29061, 406874, 295880, 274467, 283858, 381711, 111884,\n",
      "          410548, 413299,  98678, 381038,   8158, 409901],\n",
      "         [ 20415, 258341, 160331, 308763, 229433, 295590, 117218,   1720,\n",
      "          317104, 371576, 333624, 290683,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [413109, 145638, 183720, 387203, 192984,  76998, 430493,  75479,\n",
      "          395961, 205293, 166167, 235561, 112265, 391338, 279010, 353056,\n",
      "          394274,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0]],\n",
      "\n",
      "        [[ 53720, 226298, 468574, 335640, 132908, 317347, 361399, 328227,\n",
      "          205744, 131527,  68235, 407378, 110900, 418763, 111529, 230968,\n",
      "          310778, 146298, 257953,  18157, 279844, 192144, 295141, 178261,\n",
      "          142573, 403517,  29577, 422535, 437179,  17870],\n",
      "         [245750,   7727, 277772, 328758, 450840, 289174,  17143, 216632,\n",
      "           44577, 416518, 390139,  42541, 434856,  83967, 437466, 438647,\n",
      "          164963, 461527, 275377, 228301, 402072, 277702, 462105, 448575,\n",
      "          224552, 463298, 451436,  20924, 261393,  85468],\n",
      "         [277772,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [277772,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [100504,  30964, 131137, 356623,  96573, 192563, 237848, 117209,\n",
      "          429412, 309029, 212877,  37968,   9651, 445762, 240883,  25800,\n",
      "          118386, 302592, 376597,  99912, 452501, 115008, 186997, 149142,\n",
      "          174906, 246136, 420517,  35666,  36045, 118428],\n",
      "         [ 99912,  37968, 340260,  69097, 319026, 331761, 223521, 316824,\n",
      "          348051, 101128, 101825, 295839, 209667, 451819,  86149, 277553,\n",
      "          263613,  85352,  25594, 325133, 151120, 386591, 181344,  53602,\n",
      "           48485, 358470, 427191,  63691, 213393, 257881],\n",
      "         [ 37968,  99912, 223521, 184052, 358470, 348051,  84944, 308120,\n",
      "          447937,  56968, 254718, 226421, 197806, 182942, 383093, 315175,\n",
      "          302780, 163156, 328077, 464750, 316217, 142303,  30090, 329178,\n",
      "           58523, 154491, 436575, 135444, 398517, 103982],\n",
      "         [128519,   5807, 288555, 229414, 261355,  34156, 207714, 410195,\n",
      "          245124,  97140, 460620,  75967, 423394, 315443,  70502, 286498,\n",
      "          278557, 355589, 398274, 469282, 393728, 315934, 150058, 148738,\n",
      "          329155,  19133, 141238, 326374, 141440, 326611],\n",
      "         [351622, 136650,   5807, 380774, 180350, 120504, 282700, 159030,\n",
      "           37968,   2000,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [143921,  21622, 330430, 266167, 198360, 375684, 321248, 359684,\n",
      "          383841, 200862, 434733, 175939,    111, 379575, 104881, 179793,\n",
      "           39633, 339030, 375023, 392434,  72806, 309122, 419457, 155842,\n",
      "          366565,  53585, 240904, 198062, 365272, 236161],\n",
      "         [413109, 145638, 183720, 387203, 192984,  76998, 430493,  75479,\n",
      "          395961, 205293, 166167, 235561, 112265, 391338, 279010, 353056,\n",
      "          394274,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0]]], device='cuda:0')}, 'candidate_spans': tensor([[[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 4,  4],\n",
      "         [ 4,  5],\n",
      "         [ 5,  5],\n",
      "         [ 6,  6],\n",
      "         [ 7,  7],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 4,  4],\n",
      "         [ 4,  7],\n",
      "         [ 4,  8],\n",
      "         [ 6,  6],\n",
      "         [ 6,  7],\n",
      "         [ 6,  8],\n",
      "         [ 7,  7],\n",
      "         [ 7,  8],\n",
      "         [ 8,  8],\n",
      "         [ 9,  9]]], device='cuda:0'), 'candidate_segment_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}, 'wordnet': {'candidate_entity_priors': tensor([[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0081e-03, 1.0081e-03, 1.0081e-03, 4.0323e-03, 3.0242e-03,\n",
      "          1.0081e-02, 3.6290e-02, 1.7540e-01, 2.0161e-03, 3.0242e-03,\n",
      "          5.3125e-01, 1.3609e-01, 2.1169e-02, 5.9476e-02, 1.2097e-02,\n",
      "          3.0242e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e-02, 1.0000e-01, 1.0000e-02, 1.0000e-02, 2.0000e-02,\n",
      "          3.0000e-01, 4.0000e-02, 4.3000e-01, 1.0000e-02, 1.0000e-02,\n",
      "          1.0000e-02, 1.0000e-02, 1.0000e-02, 1.0000e-02, 2.0000e-02,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [3.8462e-01, 7.6923e-02, 4.6154e-01, 7.6923e-02, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [4.3478e-03, 4.3478e-03, 1.6087e-01, 9.1304e-02, 9.5652e-02,\n",
      "          4.3478e-03, 1.7391e-02, 4.3478e-03, 1.7391e-02, 1.0435e-01,\n",
      "          8.6957e-02, 4.3478e-03, 1.0870e-01, 3.4783e-02, 2.4348e-01,\n",
      "          1.7391e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [5.9948e-05, 1.7985e-04, 5.2155e-03, 4.2084e-02, 6.4403e-01,\n",
      "          1.1990e-04, 1.8104e-01, 1.1390e-02, 5.4073e-02, 1.6246e-02,\n",
      "          3.5370e-03, 5.9948e-05, 5.9948e-05, 4.1904e-02, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [2.6455e-03, 1.5873e-02, 2.6455e-03, 2.6455e-03, 2.6455e-03,\n",
      "          3.1746e-02, 8.2275e-01, 9.7884e-02, 2.6455e-03, 1.0582e-02,\n",
      "          2.6455e-03, 5.2910e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [2.6154e-01, 1.5385e-02, 7.2308e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.6667e-02, 8.6667e-01, 1.1667e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n",
      "       device='cuda:0'), 'candidate_entities': {'ids': tensor([[[ 36137,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 57960,  58811,  62085, 103935, 104076, 111970, 112082, 112425,\n",
      "          113034, 116441, 116609, 116616, 116649, 116878, 117130, 117322,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 23215,  48108,  55610,  59821,  67951,  68680,  83891, 101279,\n",
      "          101287, 106268, 106269, 108488, 108573, 108575, 114439,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 38086,  38088,  68972,  69005,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 24615, 109093, 109185, 109636, 109641, 110986, 111038, 115912,\n",
      "          116521, 116523, 116766, 117130, 117132, 117133, 117134, 117322,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [     0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0]],\n",
      "\n",
      "        [[ 67002,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [100139, 115193, 116069, 116824, 116829, 116859, 116872, 116893,\n",
      "          117059, 117105, 117260, 117283, 117513, 117542,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 77511,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [   120,    683,   4503,   4515,   4516,   5136,   8984,   9240,\n",
      "            9243,  11347,  14345,  18854,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 70779,  70780,  70786,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 70786,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 66266,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0],\n",
      "         [ 66575,  68081,  68100,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0,      0,      0,\n",
      "               0,      0,      0,      0,      0,      0]]], device='cuda:0')}, 'candidate_spans': tensor([[[ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5],\n",
      "         [ 6,  6],\n",
      "         [-1, -1],\n",
      "         [-1, -1],\n",
      "         [-1, -1]],\n",
      "\n",
      "        [[ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 4,  4],\n",
      "         [ 6,  6],\n",
      "         [ 6,  7],\n",
      "         [ 6,  8],\n",
      "         [ 7,  7],\n",
      "         [ 8,  8]]], device='cuda:0'), 'candidate_segment_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}}\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False]], device='cuda:0')\n",
      "None\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=4'>5</a>\u001b[0m (\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=5'>6</a>\u001b[0m     source_ids,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=6'>7</a>\u001b[0m     source_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=18'>19</a>\u001b[0m     target_mask\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=19'>20</a>\u001b[0m ) \u001b[39m=\u001b[39m batch\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=21'>22</a>\u001b[0m source_candidates \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=22'>23</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mwiki\u001b[39m\u001b[39m'\u001b[39m : {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=23'>24</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcandidate_entity_priors\u001b[39m\u001b[39m'\u001b[39m : source_wiki_candidate_priors,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=33'>34</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=34'>35</a>\u001b[0m }\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=37'>38</a>\u001b[0m loss, _, _ \u001b[39m=\u001b[39m model(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=38'>39</a>\u001b[0m     source_ids\u001b[39m=\u001b[39;49msource_ids,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=39'>40</a>\u001b[0m     source_mask\u001b[39m=\u001b[39;49msource_mask,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=40'>41</a>\u001b[0m     source_candidates\u001b[39m=\u001b[39;49msource_candidates,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=41'>42</a>\u001b[0m     triples_ids\u001b[39m=\u001b[39;49mtriples_ids,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=42'>43</a>\u001b[0m     triples_mask\u001b[39m=\u001b[39;49mtriples_mask,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=43'>44</a>\u001b[0m     target_ids\u001b[39m=\u001b[39;49mtarget_ids,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=44'>45</a>\u001b[0m     target_mask\u001b[39m=\u001b[39;49mtarget_mask,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=45'>46</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=47'>48</a>\u001b[0m tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=48'>49</a>\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=49'>50</a>\u001b[0m     tr_loss \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (nb_tr_steps \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m4\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/seq2seq_model.ipynb#ch0000016?line=50'>51</a>\u001b[0m )\n",
      "File \u001b[0;32m~/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py:95\u001b[0m, in \u001b[0;36mBertSeq2Seq.forward\u001b[0;34m(self, source_ids, source_mask, source_candidates, triples_ids, triples_mask, target_ids, target_mask)\u001b[0m\n\u001b[1;32m     <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=84'>85</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m     <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=85'>86</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=86'>87</a>\u001b[0m     source_ids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=92'>93</a>\u001b[0m     target_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=93'>94</a>\u001b[0m ):\n\u001b[0;32m---> <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=94'>95</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(tokens\u001b[39m=\u001b[39;49msource_ids, segment_ids\u001b[39m=\u001b[39;49msource_mask, candidates\u001b[39m=\u001b[39;49msource_candidates)\n\u001b[1;32m     <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=95'>96</a>\u001b[0m     question_encoder_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/model.py?line=96'>97</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtriple_encoder(triples_ids, attention_mask\u001b[39m=\u001b[39mtriples_mask)\n",
      "File \u001b[0;32m~/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jmenzel/python-envs/allennlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/knowbert.py:889\u001b[0m, in \u001b[0;36mKnowBert.forward\u001b[0;34m(self, tokens, segment_ids, candidates, lm_label_ids, next_sentence_label, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/knowbert.py?line=884'>885</a>\u001b[0m \u001b[39mprint\u001b[39m(kwargs)\n\u001b[1;32m    <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/knowbert.py?line=886'>887</a>\u001b[0m \u001b[39massert\u001b[39;00m candidates\u001b[39m.\u001b[39mkeys() \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoldered_kgs\u001b[39m.\u001b[39mkeys()\n\u001b[0;32m--> <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/knowbert.py?line=888'>889</a>\u001b[0m mask \u001b[39m=\u001b[39m tokens[\u001b[39m'\u001b[39;49m\u001b[39mtokens\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/knowbert.py?line=889'>890</a>\u001b[0m attention_mask \u001b[39m=\u001b[39m extend_attention_mask_for_bert(mask, get_dtype_for_module(\u001b[39mself\u001b[39m))\n\u001b[1;32m    <a href='file:///home/jmenzel/Programs/KBQA-PG/KBQA/appB/transformer_architectures/kb/knowbert.py?line=890'>891</a>\u001b[0m contextual_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpretrained_bert\u001b[39m.\u001b[39mbert\u001b[39m.\u001b[39membeddings(tokens[\u001b[39m'\u001b[39m\u001b[39mtokens\u001b[39m\u001b[39m'\u001b[39m], segment_ids)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    bar = tqdm(train_dataloader, total=len(train_dataloader))\n",
    "    for batch in bar:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        (\n",
    "            source_ids,\n",
    "            source_mask,\n",
    "            source_wiki_candidate_priors,\n",
    "            source_wiki_candidate_ids,\n",
    "            source_wiki_candidate_spans,\n",
    "            source_wiki_candidate_segment_ids,\n",
    "            source_wordnet_candidate_priors,\n",
    "            source_wordnet_candidate_ids,\n",
    "            source_wordnet_candidate_spans,\n",
    "            source_wordnet_candidate_segment_ids,\n",
    "            triples_ids,\n",
    "            triples_mask,\n",
    "            target_ids,\n",
    "            target_mask\n",
    "        ) = batch\n",
    "\n",
    "        source_candidates = {\n",
    "            'wiki' : {\n",
    "                'candidate_entity_priors' : source_wiki_candidate_priors,\n",
    "                'candidate_entities' : {'ids' : source_wiki_candidate_ids},\n",
    "                'candidate_spans' : source_wiki_candidate_spans,\n",
    "                'candidate_segment_ids' : source_wiki_candidate_segment_ids\n",
    "            },\n",
    "            'wordnet' : {\n",
    "                'candidate_entity_priors' : source_wordnet_candidate_priors,\n",
    "                'candidate_entities' : {'ids' : source_wordnet_candidate_ids},\n",
    "                'candidate_spans' : source_wordnet_candidate_spans,\n",
    "                'candidate_segment_ids' : source_wordnet_candidate_segment_ids\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "        loss, _, _ = model(\n",
    "            source_ids=source_ids,\n",
    "            source_mask=source_mask,\n",
    "            source_candidates=source_candidates,\n",
    "            triples_ids=triples_ids,\n",
    "            triples_mask=triples_mask,\n",
    "            target_ids=target_ids,\n",
    "            target_mask=target_mask,\n",
    "        )\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        train_loss = round(\n",
    "            tr_loss * -1 / (nb_tr_steps + 1), 4\n",
    "        )\n",
    "        bar.set_description(\"epoch {} loss {}\".format(epoch, train_loss))\n",
    "        nb_tr_examples += source_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        loss.backward()\n",
    "\n",
    "        if (nb_tr_steps + 1) % -1 == 0:\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            global_step += 1\n",
    "\n",
    "    if False and (epoch + 1) % 1 == 0:\n",
    "        # Eval model with dev dataset\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        eval_flag = False\n",
    "\n",
    "        # Calculate bleu\n",
    "        if \"dev_bleu\" in dev_dataset:\n",
    "            eval_examples, eval_data = dev_dataset[\"dev_bleu\"]\n",
    "        else:\n",
    "            eval_examples = read_examples(\n",
    "                args.dev_filename + \".\" + args.source,\n",
    "                args.dev_filename + \".triple\",\n",
    "                args.dev_filename + \".\" + args.target,\n",
    "            )\n",
    "            eval_examples = random.sample(\n",
    "                eval_examples, min(1000, len(eval_examples))\n",
    "            )\n",
    "            eval_features = convert_examples_to_features(\n",
    "                eval_examples, tokenizer, args, stage=\"test\"\n",
    "            )\n",
    "            all_source_ids = torch.tensor(\n",
    "                [f.source_ids for f in eval_features], dtype=torch.long\n",
    "            )\n",
    "            all_source_mask = torch.tensor(\n",
    "                [f.source_mask for f in eval_features], dtype=torch.long\n",
    "            )\n",
    "            all_triples_ids = torch.tensor(\n",
    "                [f.triples_ids for f in eval_features], dtype=torch.long\n",
    "            )\n",
    "            all_triples_mask = torch.tensor(\n",
    "                [f.triples_mask for f in eval_features], dtype=torch.long\n",
    "            )\n",
    "            eval_data = TensorDataset(\n",
    "                all_source_ids,\n",
    "                all_source_mask,\n",
    "                all_triples_ids,\n",
    "                all_triples_mask,\n",
    "            )\n",
    "            dev_dataset[\"dev_bleu\"] = eval_examples, eval_data\n",
    "\n",
    "        eval_sampler = SequentialSampler(eval_data)\n",
    "        eval_dataloader = DataLoader(\n",
    "            eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size\n",
    "        )\n",
    "\n",
    "        model.eval()\n",
    "        p = []\n",
    "        for batch in eval_dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            source_ids, source_mask, triples_ids, triples_mask = batch\n",
    "            with torch.no_grad():\n",
    "                preds = model(\n",
    "                    source_ids=source_ids,\n",
    "                    source_mask=source_mask,\n",
    "                    triples_ids=triples_ids,\n",
    "                    triples_mask=triples_mask,\n",
    "                )\n",
    "                for pred in preds:\n",
    "                    t = pred[0].cpu().numpy()\n",
    "                    t = list(t)\n",
    "                    if 0 in t:\n",
    "                        t = t[: t.index(0)]\n",
    "                    text = tokenizer.decode(\n",
    "                        t, clean_up_tokenization_spaces=False\n",
    "                    )\n",
    "                    p.append(text)\n",
    "        model.train()\n",
    "        predictions = []\n",
    "        pred_str = []\n",
    "        label_str = []\n",
    "        with open(os.path.join(args.output_dir, \"dev.output\"), \"w\") as f, open(\n",
    "            os.path.join(args.output_dir, \"dev.gold\"), \"w\"\n",
    "        ) as f1:\n",
    "            for ref, gold in zip(p, eval_examples):\n",
    "                ref = ref.strip().replace(\"< \", \"<\").replace(\" >\", \">\")\n",
    "                ref = re.sub(\n",
    "                    r' ?([!\"#$%&\\'(’)*+,-./:;=?@\\\\^_`{|}~]) ?', r\"\\1\", ref\n",
    "                )\n",
    "                ref = ref.replace(\"attr_close>\", \"attr_close >\").replace(\n",
    "                    \"_attr_open\", \"_ attr_open\"\n",
    "                )\n",
    "                ref = ref.replace(\" [ \", \" [\").replace(\" ] \", \"] \")\n",
    "                ref = ref.replace(\"_obd_\", \" _obd_ \").replace(\n",
    "                    \"_oba_\", \" _oba_ \"\n",
    "                )\n",
    "\n",
    "                pred_str.append(ref.split())\n",
    "                label_str.append([gold.target.strip().split()])\n",
    "                predictions.append(str(gold.idx) + \"\\t\" + ref)\n",
    "                f.write(str(gold.idx) + \"\\t\" + ref + \"\\n\")\n",
    "                f1.write(str(gold.idx) + \"\\t\" + gold.target + \"\\n\")\n",
    "\n",
    "        bl_score = corpus_bleu(label_str, pred_str) * 100\n",
    "\n",
    "        logger.info(\"  {} = {} \".format(\"BLEU\", str(round(bl_score, 4))))\n",
    "        logger.info(\"  \" + \"*\" * 20)\n",
    "        if bl_score > best_bleu:\n",
    "            logger.info(\"  Best bleu:%s\", bl_score)\n",
    "            logger.info(\"  \" + \"*\" * 20)\n",
    "            best_bleu = bl_score\n",
    "            # Save best checkpoint for best bleu\n",
    "            output_dir = os.path.join(args.output_dir, \"checkpoint-best-bleu\")\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            model_to_save = (\n",
    "                model.module if hasattr(model, \"module\") else model\n",
    "            )  # Only save the model it-self\n",
    "            output_model_file = os.path.join(output_dir, \"pytorch_model.bin\")\n",
    "            torch.save(model_to_save.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a2cfeb9246a79e14cff750d6c31ddf53a672c28bf2fc0b5b4eabcb8d601b798"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('allennlp-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
